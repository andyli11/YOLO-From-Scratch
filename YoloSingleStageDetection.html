<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>b84e4ed497694e6289f51f0b858c6198</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section
id="eecs-498-007598-005-assignment-5-1-single-stage-object-detector---yolo"
class="cell markdown" id="DDJwQPZcupab">
<h1>EECS 498-007/598-005 Assignment 5-1: Single-Stage Object Detector -
YOLO</h1>
</section>
<section id="single-stage-object-detector" class="cell markdown"
id="BRIqwJUr2HuN">
<h1>Single-Stage Object Detector</h1>
<p>In this exercise you will implement a <strong>single-stage</strong>
object detector, based on YOLO (<a
href="https://arxiv.org/pdf/1506.02640.pdf">v1</a> and <a
href="https://arxiv.org/pdf/1612.08242.pdf">v2</a>) and use it to train
a model that can detect objects on novel images. We will also evaluate
the detection accuracy using the classic metric mean Average Precision
(<a href="https://github.com/Cartucho/mAP">mAP</a>). The main difference
between single-stage and two-stage detectors is that single-stage
detectors perform region proposal and classification simultaneously
while two-stage detectors have them decoupled.</p>
</section>
<section id="getting-started" class="cell markdown" id="LfBk3NtRgqaV">
<h1>Getting Started</h1>
</section>
<section id="install-starter-code" class="cell markdown"
id="ubB_0e-UAOVK">
<h2>Install starter code</h2>
<p>We will use the utility functions in the following package: <a
href="https://github.com/deepvision-class/starter-code"><code>coutils</code>
package</a>. Run this cell to download and install it.</p>
</section>
<div class="cell code" data-execution_count="3"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:0}"
id="ASkY27ZtA7Is" data-outputId="5f79412b-c72f-4dc6-fe9b-81770e76b15f">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install git<span class="op">+</span>https:<span class="op">//</span>github.com<span class="op">/</span>deepvision<span class="op">-</span><span class="kw">class</span><span class="op">/</span>starter<span class="op">-</span>code</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Collecting git+https://github.com/deepvision-class/starter-code
  Cloning https://github.com/deepvision-class/starter-code to /tmp/pip-req-build-o_64kigk
  Running command git clone --filter=blob:none --quiet https://github.com/deepvision-class/starter-code /tmp/pip-req-build-o_64kigk
  Resolved https://github.com/deepvision-class/starter-code to commit e8d9fe711870a39796a2f8ad95538e57942d756f
  Preparing metadata (setup.py) ... ent already satisfied: pydrive in /usr/local/lib/python3.11/dist-packages (from Colab-Utils==0.1.dev0) (1.3.1)
Requirement already satisfied: google-api-python-client&gt;=1.2 in /usr/local/lib/python3.11/dist-packages (from pydrive-&gt;Colab-Utils==0.1.dev0) (2.160.0)
Requirement already satisfied: oauth2client&gt;=4.0.0 in /usr/local/lib/python3.11/dist-packages (from pydrive-&gt;Colab-Utils==0.1.dev0) (4.1.3)
Requirement already satisfied: PyYAML&gt;=3.0 in /usr/local/lib/python3.11/dist-packages (from pydrive-&gt;Colab-Utils==0.1.dev0) (6.0.2)
Requirement already satisfied: httplib2&lt;1.dev0,&gt;=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client&gt;=1.2-&gt;pydrive-&gt;Colab-Utils==0.1.dev0) (0.22.0)
Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,&lt;3.0.0.dev0,&gt;=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client&gt;=1.2-&gt;pydrive-&gt;Colab-Utils==0.1.dev0) (2.38.0)
Requirement already satisfied: google-auth-httplib2&lt;1.0.0,&gt;=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client&gt;=1.2-&gt;pydrive-&gt;Colab-Utils==0.1.dev0) (0.2.0)
Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,&lt;3.0.0.dev0,&gt;=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client&gt;=1.2-&gt;pydrive-&gt;Colab-Utils==0.1.dev0) (2.24.1)
Requirement already satisfied: uritemplate&lt;5,&gt;=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client&gt;=1.2-&gt;pydrive-&gt;Colab-Utils==0.1.dev0) (4.1.1)
Requirement already satisfied: pyasn1&gt;=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client&gt;=4.0.0-&gt;pydrive-&gt;Colab-Utils==0.1.dev0) (0.6.1)
Requirement already satisfied: pyasn1-modules&gt;=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client&gt;=4.0.0-&gt;pydrive-&gt;Colab-Utils==0.1.dev0) (0.4.1)
Requirement already satisfied: rsa&gt;=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client&gt;=4.0.0-&gt;pydrive-&gt;Colab-Utils==0.1.dev0) (4.9)
Requirement already satisfied: six&gt;=1.6.1 in /usr/local/lib/python3.11/dist-packages (from oauth2client&gt;=4.0.0-&gt;pydrive-&gt;Colab-Utils==0.1.dev0) (1.17.0)
Requirement already satisfied: googleapis-common-protos&lt;2.0.dev0,&gt;=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,&lt;3.0.0.dev0,&gt;=1.31.5-&gt;google-api-python-client&gt;=1.2-&gt;pydrive-&gt;Colab-Utils==0.1.dev0) (1.69.0)
Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,&lt;6.0.0.dev0,&gt;=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,&lt;3.0.0.dev0,&gt;=1.31.5-&gt;google-api-python-client&gt;=1.2-&gt;pydrive-&gt;Colab-Utils==0.1.dev0) (4.25.6)
Requirement already satisfied: proto-plus&lt;2.0.0dev,&gt;=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,&lt;3.0.0.dev0,&gt;=1.31.5-&gt;google-api-python-client&gt;=1.2-&gt;pydrive-&gt;Colab-Utils==0.1.dev0) (1.26.0)
Requirement already satisfied: requests&lt;3.0.0.dev0,&gt;=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,&lt;3.0.0.dev0,&gt;=1.31.5-&gt;google-api-python-client&gt;=1.2-&gt;pydrive-&gt;Colab-Utils==0.1.dev0) (2.32.3)
Requirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,&lt;3.0.0.dev0,&gt;=1.32.0-&gt;google-api-python-client&gt;=1.2-&gt;pydrive-&gt;Colab-Utils==0.1.dev0) (5.5.2)
Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,&lt;4,&gt;=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2&lt;1.dev0,&gt;=0.19.0-&gt;google-api-python-client&gt;=1.2-&gt;pydrive-&gt;Colab-Utils==0.1.dev0) (3.2.1)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.11/dist-packages (from requests&lt;3.0.0.dev0,&gt;=2.18.0-&gt;google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,&lt;3.0.0.dev0,&gt;=1.31.5-&gt;google-api-python-client&gt;=1.2-&gt;pydrive-&gt;Colab-Utils==0.1.dev0) (3.4.1)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.11/dist-packages (from requests&lt;3.0.0.dev0,&gt;=2.18.0-&gt;google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,&lt;3.0.0.dev0,&gt;=1.31.5-&gt;google-api-python-client&gt;=1.2-&gt;pydrive-&gt;Colab-Utils==0.1.dev0) (3.10)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests&lt;3.0.0.dev0,&gt;=2.18.0-&gt;google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,&lt;3.0.0.dev0,&gt;=1.31.5-&gt;google-api-python-client&gt;=1.2-&gt;pydrive-&gt;Colab-Utils==0.1.dev0) (2.3.0)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests&lt;3.0.0.dev0,&gt;=2.18.0-&gt;google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,&lt;3.0.0.dev0,&gt;=1.31.5-&gt;google-api-python-client&gt;=1.2-&gt;pydrive-&gt;Colab-Utils==0.1.dev0) (2025.1.31)
</code></pre>
</div>
</div>
<section id="setup-code" class="cell markdown" id="MzqbYcKdz6ew">
<h2>Setup code</h2>
<p>Run some setup code for this notebook: Import some useful packages
and increase the default figure size.</p>
</section>
<div class="cell code" data-execution_count="4"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:0}"
id="HzRdJ3uhe1CR" data-outputId="ddae9796-77eb-41ba-8bc9-1f900da9b3e8"
data-tags="[&quot;pdf-ignore&quot;]">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> coutils</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> coutils <span class="im">import</span> extract_drive_file_id, register_colab_notebooks, <span class="op">\</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>                    fix_random_seed, rel_error</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> copy</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shutil</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="co"># for plotting</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">&#39;figure.figsize&#39;</span>] <span class="op">=</span> (<span class="fl">10.0</span>, <span class="fl">8.0</span>) <span class="co"># set default size of plots</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">&#39;image.interpolation&#39;</span>] <span class="op">=</span> <span class="st">&#39;nearest&#39;</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">&#39;image.cmap&#39;</span>] <span class="op">=</span> <span class="st">&#39;gray&#39;</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="co"># data type and device for torch.tensor</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>to_float <span class="op">=</span> {<span class="st">&#39;dtype&#39;</span>: torch.<span class="bu">float</span>, <span class="st">&#39;device&#39;</span>: <span class="st">&#39;cpu&#39;</span>}</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>to_float_cuda <span class="op">=</span> {<span class="st">&#39;dtype&#39;</span>: torch.<span class="bu">float</span>, <span class="st">&#39;device&#39;</span>: <span class="st">&#39;cuda&#39;</span>}</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>to_double <span class="op">=</span> {<span class="st">&#39;dtype&#39;</span>: torch.double, <span class="st">&#39;device&#39;</span>: <span class="st">&#39;cpu&#39;</span>}</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>to_double_cuda <span class="op">=</span> {<span class="st">&#39;dtype&#39;</span>: torch.double, <span class="st">&#39;device&#39;</span>: <span class="st">&#39;cuda&#39;</span>}</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>to_long <span class="op">=</span> {<span class="st">&#39;dtype&#39;</span>: torch.<span class="bu">long</span>, <span class="st">&#39;device&#39;</span>: <span class="st">&#39;cpu&#39;</span>}</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>to_long_cuda <span class="op">=</span> {<span class="st">&#39;dtype&#39;</span>: torch.<span class="bu">long</span>, <span class="st">&#39;device&#39;</span>: <span class="st">&#39;cuda&#39;</span>}</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="co"># for mAP evaluation</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>rm <span class="op">-</span>rf mAP</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>git clone https:<span class="op">//</span>github.com<span class="op">/</span>Cartucho<span class="op">/</span>mAP.git</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>rm <span class="op">-</span>rf mAP<span class="op">/</span><span class="bu">input</span><span class="op">/*</span></span></code></pre></div>
<div class="output stream stderr">
<pre><code>WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Cloning into &#39;mAP&#39;...
remote: Enumerating objects: 908, done.ote: Counting objects: 100% (150/150), done.ote: Compressing objects: 100% (25/25), done.ote: Total 908 (delta 135), reused 125 (delta 125), pack-reused 758 (from 1)</code></pre>
</div>
</div>
<div class="cell markdown" id="OvUDZWGU3VLV">
<p>We will use GPUs to accelerate our computation in this notebook. Run
the following to make sure GPUs are enabled:</p>
</div>
<div class="cell code" data-execution_count="5"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:0}"
id="RrAX9FOLpr9k" data-outputId="c560b3b6-d650-4c96-ac55-3e5af4738878">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available:</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">&#39;Good to go!&#39;</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">&#39;Please set GPU via Edit -&gt; Notebook Settings.&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Good to go!
</code></pre>
</div>
</div>
<section id="load-pascal-voc-2007-data" class="cell markdown"
id="MjJ3uyYBg3Lw">
<h2>Load PASCAL VOC 2007 data</h2>
<p>In order to train and evaluate object detection models, we need a
dataset where each image is annotated with a <em>set</em> of
<em>bounding boxes</em>, where each box gives the category label and
spatial extent of some object in the image.</p>
<p>We will use the <a
href="http://host.robots.ox.ac.uk/pascal/VOC/">PASCAL VOC 2007</a>
dataset, which provides annotations of this form. PASCAL VOC ran a
series of yearly computer vision competitions from 2005 to 2012,
predating the ImageNet challenge which we have discussed in class.</p>
<p>The data from the 2007 challenge used to be one of the most popular
datasets for evaluating object detection. It is much smaller than more
recent object detection datasets such as <a
href="http://cocodataset.org/#home">COCO</a>, and thus easier to manage
in an homework assignment.</p>
<p>The following function will download the PASCAL VOC 2007 dataset and
return it as a PyTorch Dataset object:</p>
</section>
<div class="cell code" data-execution_count="6" id="fmD9Qrs2g7fI">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_pascal_voc2007_data(image_root, split<span class="op">=</span><span class="st">&#39;train&#39;</span>):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">  Use torchvision.datasets</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co">  https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.VOCDetection</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">  &quot;&quot;&quot;</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>  <span class="im">from</span> torchvision <span class="im">import</span> datasets</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>  train_dataset <span class="op">=</span> datasets.VOCDetection(image_root, year<span class="op">=</span><span class="st">&#39;2007&#39;</span>, image_set<span class="op">=</span>split,</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>                                    download<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> train_dataset</span></code></pre></div>
</div>
<div class="cell markdown" id="XXc_Hw3JhVxw">
<p>Run the following cell to download the training and validation sets
for the PASCAL VOC 2007 dataset:</p>
<p>The <a
href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset"><code>Dataset</code></a>
objects returned from the above function returns annotations for each
image as a nested set of dictionary objects:</p>
</div>
<div class="cell code" data-execution_count="7"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:0}"
id="MmEP5KQJzk0d" data-outputId="aa3d878b-e073-44c9-900d-5cd2e35c26ed">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># uncomment below to use the mirror link if the original link is broken</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># !wget http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> get_pascal_voc2007_data(<span class="st">&#39;/content&#39;</span>, <span class="st">&#39;train&#39;</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>val_dataset <span class="op">=</span> get_pascal_voc2007_data(<span class="st">&#39;/content&#39;</span>, <span class="st">&#39;val&#39;</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># an example on the raw annotation</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(json.dumps(train_dataset[<span class="dv">1</span>][<span class="dv">1</span>][<span class="st">&#39;annotation&#39;</span>], indent<span class="op">=</span><span class="dv">2</span>))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Using downloaded and verified file: /content/VOCtrainval_06-Nov-2007.tar
Extracting /content/VOCtrainval_06-Nov-2007.tar to /content
Using downloaded and verified file: /content/VOCtrainval_06-Nov-2007.tar
Extracting /content/VOCtrainval_06-Nov-2007.tar to /content
{
  &quot;folder&quot;: &quot;VOC2007&quot;,
  &quot;filename&quot;: &quot;000017.jpg&quot;,
  &quot;source&quot;: {
    &quot;database&quot;: &quot;The VOC2007 Database&quot;,
    &quot;annotation&quot;: &quot;PASCAL VOC2007&quot;,
    &quot;image&quot;: &quot;flickr&quot;,
    &quot;flickrid&quot;: &quot;228217974&quot;
  },
  &quot;owner&quot;: {
    &quot;flickrid&quot;: &quot;genewolf&quot;,
    &quot;name&quot;: &quot;whiskey kitten&quot;
  },
  &quot;size&quot;: {
    &quot;width&quot;: &quot;480&quot;,
    &quot;height&quot;: &quot;364&quot;,
    &quot;depth&quot;: &quot;3&quot;
  },
  &quot;segmented&quot;: &quot;0&quot;,
  &quot;object&quot;: [
    {
      &quot;name&quot;: &quot;person&quot;,
      &quot;pose&quot;: &quot;Left&quot;,
      &quot;truncated&quot;: &quot;0&quot;,
      &quot;difficult&quot;: &quot;0&quot;,
      &quot;bndbox&quot;: {
        &quot;xmin&quot;: &quot;185&quot;,
        &quot;ymin&quot;: &quot;62&quot;,
        &quot;xmax&quot;: &quot;279&quot;,
        &quot;ymax&quot;: &quot;199&quot;
      }
    },
    {
      &quot;name&quot;: &quot;horse&quot;,
      &quot;pose&quot;: &quot;Left&quot;,
      &quot;truncated&quot;: &quot;0&quot;,
      &quot;difficult&quot;: &quot;0&quot;,
      &quot;bndbox&quot;: {
        &quot;xmin&quot;: &quot;90&quot;,
        &quot;ymin&quot;: &quot;78&quot;,
        &quot;xmax&quot;: &quot;403&quot;,
        &quot;ymax&quot;: &quot;336&quot;
      }
    }
  ]
}
</code></pre>
</div>
</div>
<div class="cell markdown" id="J5MjBX9bkBtA">
<p>In order to use these annotations to train our model, we need to
convert this nested dictionary data structure into a set of PyTorch
tensors.</p>
<p>We also need to preprocess the image, converting it to a PyTorch
tensor and resizing it to 224x224. Real object detection systems
typically work with much higher-resolution images, but we will use a low
resolution for computational efficiency in this assignment.</p>
<p>We also want to train our models using minibatches of data, so we
need to group the annotations from several images into minibatches.</p>
<p>We perform both of these functions by using a customized PyTorch <a
href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">DataLoader</a>
object, which we have written for you:</p>
</div>
<div class="cell code" data-execution_count="8" id="OfwTGpZn1L5U">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> pascal_voc2007_loader(dataset, batch_size, num_workers<span class="op">=</span><span class="dv">0</span>):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co">  Data loader for Pascal VOC 2007.</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co">  https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co">  &quot;&quot;&quot;</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>  <span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># turn off shuffle so we can index the original image</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>  train_loader <span class="op">=</span> DataLoader(dataset,</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>                            batch_size<span class="op">=</span>batch_size,</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>                            shuffle<span class="op">=</span><span class="va">False</span>, pin_memory<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>                            num_workers<span class="op">=</span>num_workers,</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>                            collate_fn<span class="op">=</span>voc_collate_fn)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> train_loader</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>class_to_idx <span class="op">=</span> {<span class="st">&#39;aeroplane&#39;</span>:<span class="dv">0</span>, <span class="st">&#39;bicycle&#39;</span>:<span class="dv">1</span>, <span class="st">&#39;bird&#39;</span>:<span class="dv">2</span>, <span class="st">&#39;boat&#39;</span>:<span class="dv">3</span>, <span class="st">&#39;bottle&#39;</span>:<span class="dv">4</span>,</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;bus&#39;</span>:<span class="dv">5</span>, <span class="st">&#39;car&#39;</span>:<span class="dv">6</span>, <span class="st">&#39;cat&#39;</span>:<span class="dv">7</span>, <span class="st">&#39;chair&#39;</span>:<span class="dv">8</span>, <span class="st">&#39;cow&#39;</span>:<span class="dv">9</span>, <span class="st">&#39;diningtable&#39;</span>:<span class="dv">10</span>,</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;dog&#39;</span>:<span class="dv">11</span>, <span class="st">&#39;horse&#39;</span>:<span class="dv">12</span>, <span class="st">&#39;motorbike&#39;</span>:<span class="dv">13</span>, <span class="st">&#39;person&#39;</span>:<span class="dv">14</span>, <span class="st">&#39;pottedplant&#39;</span>:<span class="dv">15</span>,</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;sheep&#39;</span>:<span class="dv">16</span>, <span class="st">&#39;sofa&#39;</span>:<span class="dv">17</span>, <span class="st">&#39;train&#39;</span>:<span class="dv">18</span>, <span class="st">&#39;tvmonitor&#39;</span>:<span class="dv">19</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>idx_to_class <span class="op">=</span> {i:c <span class="cf">for</span> c, i <span class="kw">in</span> class_to_idx.items()}</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> voc_collate_fn(batch_lst, reshape_size<span class="op">=</span><span class="dv">224</span>):</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>    preprocess <span class="op">=</span> transforms.Compose([</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>      transforms.Resize((reshape_size, reshape_size)),</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>      transforms.ToTensor(),</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>      transforms.Normalize(mean<span class="op">=</span>[<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>], std<span class="op">=</span>[<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>]),</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>      ])</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>    batch_size <span class="op">=</span> <span class="bu">len</span>(batch_lst)</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>    img_batch <span class="op">=</span> torch.zeros(batch_size, <span class="dv">3</span>, reshape_size, reshape_size)</span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>    max_num_box <span class="op">=</span> <span class="bu">max</span>(<span class="bu">len</span>(batch_lst[i][<span class="dv">1</span>][<span class="st">&#39;annotation&#39;</span>][<span class="st">&#39;object&#39;</span>]) <span class="op">\</span></span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>                      <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(batch_size))</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>    box_batch <span class="op">=</span> torch.Tensor(batch_size, max_num_box, <span class="dv">5</span>).fill_(<span class="op">-</span><span class="fl">1.</span>)</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>    w_list <span class="op">=</span> []</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>    h_list <span class="op">=</span> []</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>    img_id_list <span class="op">=</span> []</span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(batch_size):</span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a>      img, ann <span class="op">=</span> batch_lst[i]</span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>      w_list.append(img.size[<span class="dv">0</span>]) <span class="co"># image width</span></span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>      h_list.append(img.size[<span class="dv">1</span>]) <span class="co"># image height</span></span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a>      img_id_list.append(ann[<span class="st">&#39;annotation&#39;</span>][<span class="st">&#39;filename&#39;</span>])</span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a>      img_batch[i] <span class="op">=</span> preprocess(img)</span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>      all_bbox <span class="op">=</span> ann[<span class="st">&#39;annotation&#39;</span>][<span class="st">&#39;object&#39;</span>]</span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> <span class="bu">type</span>(all_bbox) <span class="op">==</span> <span class="bu">dict</span>: <span class="co"># inconsistency in the annotation file</span></span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a>        all_bbox <span class="op">=</span> [all_bbox]</span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> bbox_idx, one_bbox <span class="kw">in</span> <span class="bu">enumerate</span>(all_bbox):</span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a>        bbox <span class="op">=</span> one_bbox[<span class="st">&#39;bndbox&#39;</span>]</span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a>        obj_cls <span class="op">=</span> one_bbox[<span class="st">&#39;name&#39;</span>]</span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a>        box_batch[i][bbox_idx] <span class="op">=</span> torch.Tensor([<span class="bu">float</span>(bbox[<span class="st">&#39;xmin&#39;</span>]), <span class="bu">float</span>(bbox[<span class="st">&#39;ymin&#39;</span>]),</span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a>          <span class="bu">float</span>(bbox[<span class="st">&#39;xmax&#39;</span>]), <span class="bu">float</span>(bbox[<span class="st">&#39;ymax&#39;</span>]), class_to_idx[obj_cls]])</span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a>    h_batch <span class="op">=</span> torch.tensor(h_list)</span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a>    w_batch <span class="op">=</span> torch.tensor(w_list)</span>
<span id="cb11-62"><a href="#cb11-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-63"><a href="#cb11-63" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> img_batch, box_batch, w_batch, h_batch, img_id_list</span></code></pre></div>
</div>
<div class="cell markdown" id="0ad8hHvAlGdA">
<p>Training with the entire PASCAL VOC will be too computationally
expensive for this homework assignment, so we can subsample the dataset
by wrapping each <code>Dataset</code> object in a <a
href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset"><code>Subset</code></a>
object:</p>
</div>
<div class="cell code" data-execution_count="9" id="XL-7Em_A1kdS">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> torch.utils.data.Subset(train_dataset, torch.arange(<span class="dv">0</span>, <span class="dv">2500</span>)) <span class="co"># use 2500 samples for training</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> pascal_voc2007_loader(train_dataset, <span class="dv">10</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>val_loader <span class="op">=</span> pascal_voc2007_loader(val_dataset, <span class="dv">10</span>)</span></code></pre></div>
</div>
<div class="cell markdown" id="HTyRHqwlC1Au">
<p>The <code>DataLoader</code> objects return batches of data.</p>
<p>The first output from the <code>DataLoader</code> is a Tensor
<code>img</code> of shape <code>(B, 3, 224, 224)</code>. This is a batch
of <code>B</code> images, similar to what we have seen in classification
datasets.</p>
<p>The second output from the <code>DataLoader</code> is a Tensor
<code>ann</code> of shape <code>(B, N, 5)</code> giving information
about all objects in all images of the batch.
<code>ann[i, j] = (x_tl, y_tl, x_br, y_br, class)</code> gives
information about the <code>j</code>th object in <code>img[i]</code>.
The position of the top-left corner of the box is
<code>(x_tl, y_tl)</code> and the position of the bottom-right corner of
the box is <code>(x_br, y_br)</code>. These positions are in the
coordinate system of the original image (before it was resized to 224 x
224). <code>class</code> is an integer giving the category label for
this bounding box.</p>
<p>Each image can have different numbers of objects. If
<code>img[i]</code> has <span
class="math inline"><em>N</em><sub><em>i</em></sub></span> objects, then
<span
class="math inline"><em>N</em> = max<sub><em>i</em></sub><em>N</em><sub><em>i</em></sub></span>
is the maximum number of objects per image among all objects in the
batch; this value can vary from batch to batch. For the images that have
fewer than <span class="math inline"><em>N</em></span> annotated
objects, only the first <span
class="math inline"><em>N</em><sub><em>i</em></sub></span> rows of <span
class="math inline"><em>a</em><em>n</em><em>n</em><em>s</em>[<em>i</em>]</span>
contain annotations; the remaining rows are padded with -1.</p>
</div>
<div class="cell code" data-execution_count="10"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:0}"
id="nZVYFJD32I_l" data-outputId="e0d1eab7-4674-4934-a41e-19d1f6ad9e78">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>train_loader_iter <span class="op">=</span> <span class="bu">iter</span>(train_loader)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>img, ann, _, _, _ <span class="op">=</span> <span class="bu">next</span>(train_loader_iter)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;img has shape: &#39;</span>, img.shape)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;ann has shape: &#39;</span>, ann.shape)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Image 1 has only two annotated objects, so ann[1] is padded with -1:&#39;</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ann[<span class="dv">1</span>])</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Image 2 has six annotated objects:, so ann[2] is not padded:&#39;</span>)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ann[<span class="dv">2</span>])</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Each row in the annotation tensor indicates (x_tl, y_tl, x_br, y_br, class).&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>img has shape:  torch.Size([10, 3, 224, 224])
ann has shape:  torch.Size([10, 6, 5])
Image 1 has only two annotated objects, so ann[1] is padded with -1:
tensor([[185.,  62., 279., 199.,  14.],
        [ 90.,  78., 403., 336.,  12.],
        [ -1.,  -1.,  -1.,  -1.,  -1.],
        [ -1.,  -1.,  -1.,  -1.,  -1.],
        [ -1.,  -1.,  -1.,  -1.,  -1.],
        [ -1.,  -1.,  -1.,  -1.,  -1.]])

Image 2 has six annotated objects:, so ann[2] is not padded:
tensor([[  9., 230., 245., 500.,   1.],
        [230., 220., 334., 500.,   1.],
        [  2., 178.,  90., 500.,   1.],
        [  2.,   1., 117., 369.,  14.],
        [  3.,   2., 243., 462.,  14.],
        [225.,   1., 334., 486.,  14.]])

Each row in the annotation tensor indicates (x_tl, y_tl, x_br, y_br, class).
</code></pre>
</div>
</div>
<section id="coordinate-transformation" class="cell markdown"
id="GqISg-cs6vKM">
<h1>Coordinate transformation</h1>
<p>It's a good practice to use a consistent coordinate system for all
the spatial-related computations (e.g., anchors, proposals). <strong>In
this assignment, we use the coordinate system defined by the CNN
activation map (of shape 7x7), where the top-left corner is (0, 0) and
the bottom-right corner is (7, 7). The horizontal axis is the x axis and
the vertical axis is the y axis.</strong></p>
<p>The following function defines the transformation from the original
image coordinate system (pixels, and the top-left corner is (0, 0)) to
the activation map coordinate system and vice versa.</p>
<p>Notes: All the coordinates are in float precision. In later sections,
we use the activation map coordinate system for all computations except
for visualization.</p>
</section>
<div class="cell code" data-execution_count="11" id="ggnqmAXh6vJv">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> coord_trans(bbox, w_pixel, h_pixel, w_amap<span class="op">=</span><span class="dv">7</span>, h_amap<span class="op">=</span><span class="dv">7</span>, mode<span class="op">=</span><span class="st">&#39;a2p&#39;</span>):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co">  Coordinate transformation function. It converts the box coordinate from</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co">  the image coordinate system to the activation map coordinate system and vice versa.</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co">  In our case, the input image will have a few hundred of pixels in</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co">  width/height while the activation map is of size 7x7.</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co">  Input:</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co">  - bbox: Could be either bbox, anchor, or proposal, of shape Bx*x4</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co">  - w_pixel: Number of pixels in the width side of the original image, of shape B</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co">  - h_pixel: Number of pixels in the height side of the original image, of shape B</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="co">  - w_amap: Number of pixels in the width side of the activation map, scalar</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="co">  - h_amap: Number of pixels in the height side of the activation map, scalar</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="co">  - mode: Whether transfer from the original image to activation map (&#39;p2a&#39;) or</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="co">          the opposite (&#39;a2p&#39;)</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="co">  Output:</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="co">  - resized_bbox: Resized box coordinates, of the same shape as the input bbox</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="co">  &quot;&quot;&quot;</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>  <span class="cf">assert</span> mode <span class="kw">in</span> (<span class="st">&#39;p2a&#39;</span>, <span class="st">&#39;a2p&#39;</span>), <span class="st">&#39;invalid coordinate transformation mode!&#39;</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">assert</span> bbox.shape[<span class="op">-</span><span class="dv">1</span>] <span class="op">&gt;=</span> <span class="dv">4</span>, <span class="st">&#39;the transformation is applied to the first 4 values of dim -1&#39;</span></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> bbox.shape[<span class="dv">0</span>] <span class="op">==</span> <span class="dv">0</span>: <span class="co"># corner cases</span></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> bbox</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>  resized_bbox <span class="op">=</span> bbox.clone()</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>  <span class="co"># could still work if the first dim of bbox is not batch size</span></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>  <span class="co"># in that case, w_pixel and h_pixel will be scalars</span></span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>  resized_bbox <span class="op">=</span> resized_bbox.view(bbox.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>, bbox.shape[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a>  invalid_bbox_mask <span class="op">=</span> (resized_bbox <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>) <span class="co"># indicating invalid bbox</span></span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> mode <span class="op">==</span> <span class="st">&#39;p2a&#39;</span>:</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># pixel to activation</span></span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>    width_ratio <span class="op">=</span> w_pixel <span class="op">*</span> <span class="fl">1.</span> <span class="op">/</span> w_amap</span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a>    height_ratio <span class="op">=</span> h_pixel <span class="op">*</span> <span class="fl">1.</span> <span class="op">/</span> h_amap</span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a>    resized_bbox[:, :, [<span class="dv">0</span>, <span class="dv">2</span>]] <span class="op">/=</span> width_ratio.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a>    resized_bbox[:, :, [<span class="dv">1</span>, <span class="dv">3</span>]] <span class="op">/=</span> height_ratio.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span>:</span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># activation to pixel</span></span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a>    width_ratio <span class="op">=</span> w_pixel <span class="op">*</span> <span class="fl">1.</span> <span class="op">/</span> w_amap</span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a>    height_ratio <span class="op">=</span> h_pixel <span class="op">*</span> <span class="fl">1.</span> <span class="op">/</span> h_amap</span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a>    resized_bbox[:, :, [<span class="dv">0</span>, <span class="dv">2</span>]] <span class="op">*=</span> width_ratio.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a>    resized_bbox[:, :, [<span class="dv">1</span>, <span class="dv">3</span>]] <span class="op">*=</span> height_ratio.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb15-45"><a href="#cb15-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-46"><a href="#cb15-46" aria-hidden="true" tabindex="-1"></a>  resized_bbox <span class="op">=</span> resized_bbox.masked_fill(invalid_bbox_mask, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb15-47"><a href="#cb15-47" aria-hidden="true" tabindex="-1"></a>  resized_bbox <span class="op">=</span> resized_bbox.view_as(bbox)</span>
<span id="cb15-48"><a href="#cb15-48" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> resized_bbox</span></code></pre></div>
</div>
<section id="data-visualizer" class="cell markdown" id="48Cocwotg9Ly">
<h1>Data Visualizer</h1>
<p>This function will help us visualize boxes on top of images.</p>
</section>
<div class="cell code" data-execution_count="12" id="fm3vPcQnhmRU">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> data_visualizer(img, idx_to_class, bbox<span class="op">=</span><span class="va">None</span>, pred<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co">  Data visualizer on the original image. Support both GT box input and proposal input.</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co">  Input:</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co">  - img: PIL Image input</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - idx_to_class: Mapping from the index (0-19) to the class name</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co">  - bbox: GT bbox (in red, optional), a tensor of shape Nx5, where N is</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co">          the number of GT boxes, 5 indicates (x_tl, y_tl, x_br, y_br, class)</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="co">  - pred: Predicted bbox (in green, optional), a tensor of shape N&#39;x6, where</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co">          N&#39; is the number of predicted boxes, 6 indicates</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="co">          (x_tl, y_tl, x_br, y_br, class, object confidence score)</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="co">  &quot;&quot;&quot;</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>  img_copy <span class="op">=</span> np.array(img).astype(<span class="st">&#39;uint8&#39;</span>)</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> bbox <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> bbox_idx <span class="kw">in</span> <span class="bu">range</span>(bbox.shape[<span class="dv">0</span>]):</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>      one_bbox <span class="op">=</span> bbox[bbox_idx][:<span class="dv">4</span>]</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>      top_left <span class="op">=</span> (<span class="bu">int</span>(one_bbox[<span class="dv">0</span>]), <span class="bu">int</span>(one_bbox[<span class="dv">1</span>]))</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>      bottom_right <span class="op">=</span> (<span class="bu">int</span>(one_bbox[<span class="dv">2</span>]), <span class="bu">int</span>(one_bbox[<span class="dv">3</span>]))</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>      cv2.rectangle(img_copy, top_left, bottom_right, (<span class="dv">255</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="dv">2</span>)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> bbox.shape[<span class="dv">1</span>] <span class="op">&gt;</span> <span class="dv">4</span>: <span class="co"># if class info provided</span></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>        obj_cls <span class="op">=</span> idx_to_class[bbox[bbox_idx][<span class="dv">4</span>].item()]</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>        cv2.putText(img_copy, <span class="st">&#39;</span><span class="sc">%s</span><span class="st">&#39;</span> <span class="op">%</span> (obj_cls),</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>                  (<span class="bu">int</span>(one_bbox[<span class="dv">0</span>]), <span class="bu">int</span>(one_bbox[<span class="dv">1</span>]<span class="op">+</span><span class="dv">15</span>)),</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>                  cv2.FONT_HERSHEY_PLAIN, <span class="fl">1.0</span>, (<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">255</span>), thickness<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> pred <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> bbox_idx <span class="kw">in</span> <span class="bu">range</span>(pred.shape[<span class="dv">0</span>]):</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>      one_bbox <span class="op">=</span> pred[bbox_idx][:<span class="dv">4</span>]</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>      top_left <span class="op">=</span> (<span class="bu">int</span>(one_bbox[<span class="dv">0</span>]), <span class="bu">int</span>(one_bbox[<span class="dv">1</span>]))</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>      bottom_right <span class="op">=</span> (<span class="bu">int</span>(one_bbox[<span class="dv">2</span>]), <span class="bu">int</span>(one_bbox[<span class="dv">3</span>]))</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>      cv2.rectangle(img_copy, top_left, bottom_right, (<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>), <span class="dv">2</span>)</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> pred.shape[<span class="dv">1</span>] <span class="op">&gt;</span> <span class="dv">4</span>: <span class="co"># if class and conf score info provided</span></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>        obj_cls <span class="op">=</span> idx_to_class[pred[bbox_idx][<span class="dv">4</span>].item()]</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>        conf_score <span class="op">=</span> pred[bbox_idx][<span class="dv">5</span>].item()</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>        location <span class="op">=</span> (<span class="bu">int</span>(one_bbox[<span class="dv">0</span>]), <span class="bu">int</span>(one_bbox[<span class="dv">1</span>]<span class="op">+</span><span class="dv">15</span>))</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>        cv2.putText(img_copy, <span class="st">&#39;</span><span class="sc">%s</span><span class="st">, </span><span class="sc">%.2f</span><span class="st">&#39;</span> <span class="op">%</span> (obj_cls, conf_score), location,</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>                    cv2.FONT_HERSHEY_PLAIN, <span class="fl">1.0</span>, (<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">255</span>), thickness<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>  plt.imshow(img_copy)</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>  plt.axis(<span class="st">&#39;off&#39;</span>)</span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>  plt.show()</span></code></pre></div>
</div>
<section id="visualize-pascal-voc-2007" class="cell markdown"
id="X4WmocEyiXWa">
<h2>Visualize PASCAL VOC 2007</h2>
<p>It is always good practice to try and visualize parts of your dataset
before you build a model.</p>
<p>Here we sample some images from the PASCAL VOC 2007 training set, and
visualize the ground-truth object boxes and category labels:</p>
</section>
<div class="cell code" data-execution_count="13" id="ld1s28Z4fyL5">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># default examples for visualization</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>fix_random_seed(<span class="dv">0</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>sampled_idx <span class="op">=</span> torch.linspace(<span class="dv">0</span>, <span class="bu">len</span>(train_dataset)<span class="op">-</span><span class="dv">1</span>, steps<span class="op">=</span>batch_size).<span class="bu">long</span>()</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co"># get the size of each image first</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>h_list <span class="op">=</span> []</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>w_list <span class="op">=</span> []</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>img_list <span class="op">=</span> [] <span class="co"># list of images</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>MAX_NUM_BBOX <span class="op">=</span> <span class="dv">40</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>box_list <span class="op">=</span> torch.LongTensor(batch_size, MAX_NUM_BBOX, <span class="dv">5</span>).fill_(<span class="op">-</span><span class="dv">1</span>) <span class="co"># PADDED GT boxes</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, i <span class="kw">in</span> <span class="bu">enumerate</span>(sampled_idx):</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># hack to get the original image so we don&#39;t have to load from local again...</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>  img, ann <span class="op">=</span> train_dataset.<span class="fu">__getitem__</span>(i)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>  img_list.append(img)</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>  all_bbox <span class="op">=</span> ann[<span class="st">&#39;annotation&#39;</span>][<span class="st">&#39;object&#39;</span>]</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">type</span>(all_bbox) <span class="op">==</span> <span class="bu">dict</span>:</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>    all_bbox <span class="op">=</span> [all_bbox]</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> bbox_idx, one_bbox <span class="kw">in</span> <span class="bu">enumerate</span>(all_bbox):</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>    bbox <span class="op">=</span> one_bbox[<span class="st">&#39;bndbox&#39;</span>]</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>    obj_cls <span class="op">=</span> one_bbox[<span class="st">&#39;name&#39;</span>]</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>    box_list[idx][bbox_idx] <span class="op">=</span> torch.LongTensor([<span class="bu">int</span>(bbox[<span class="st">&#39;xmin&#39;</span>]), <span class="bu">int</span>(bbox[<span class="st">&#39;ymin&#39;</span>]),</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>      <span class="bu">int</span>(bbox[<span class="st">&#39;xmax&#39;</span>]), <span class="bu">int</span>(bbox[<span class="st">&#39;ymax&#39;</span>]), class_to_idx[obj_cls]])</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>  <span class="co"># get sizes</span></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>  img <span class="op">=</span> np.array(img)</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>  w_list.append(img.shape[<span class="dv">1</span>])</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>  h_list.append(img.shape[<span class="dv">0</span>])</span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>w_list <span class="op">=</span> torch.as_tensor(w_list, <span class="op">**</span>to_float_cuda)</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>h_list <span class="op">=</span> torch.as_tensor(h_list, <span class="op">**</span>to_float_cuda)</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>box_list <span class="op">=</span> torch.as_tensor(box_list, <span class="op">**</span>to_float_cuda)</span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>resized_box_list <span class="op">=</span> coord_trans(box_list, w_list, h_list, mode<span class="op">=</span><span class="st">&#39;p2a&#39;</span>) <span class="co"># on activation map coordinate system</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="14"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="v04D-gwEiWqY" data-outputId="e558e40b-6147-445f-d4ac-d4847c124f52">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize GT boxes</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(img_list)):</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  valid_box <span class="op">=</span> <span class="bu">sum</span>([<span class="dv">1</span> <span class="cf">if</span> j <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span> <span class="cf">else</span> <span class="dv">0</span> <span class="cf">for</span> j <span class="kw">in</span> box_list[i][:, <span class="dv">0</span>]])</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>  data_visualizer(img_list[i], idx_to_class, box_list[i][:valid_box])</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/4122a8f37dd6e29473620c7634674e617d41b8d2.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/3e2f384ba450227a80a0b51c7fc75a39a01df5c7.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/ca56a530582dc674e0c4c6a51383e59c2f043756.png" /></p>
</div>
</div>
<section id="detector-backbone-network" class="cell markdown"
id="IAa1Kvl2P_2k">
<h1>Detector Backbone Network</h1>
<p>Here, we use <a
href="https://pytorch.org/hub/pytorch_vision_mobilenet_v2/">MobileNet
v2</a> for image feature extraction.</p>
</section>
<div class="cell code" data-execution_count="15" id="VLmU_CiURha7">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FeatureExtractor(nn.Module):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co">  Image feature extraction with MobileNet.</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co">  &quot;&quot;&quot;</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, reshape_size<span class="op">=</span><span class="dv">224</span>, pooling<span class="op">=</span><span class="va">False</span>, verbose<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> torchvision <span class="im">import</span> models</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> torchsummary <span class="im">import</span> summary</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.mobilenet <span class="op">=</span> models.mobilenet_v2(pretrained<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.mobilenet <span class="op">=</span> nn.Sequential(<span class="op">*</span><span class="bu">list</span>(<span class="va">self</span>.mobilenet.children())[:<span class="op">-</span><span class="dv">1</span>]) <span class="co"># Remove the last classifier</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># average pooling</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pooling:</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.mobilenet.add_module(<span class="st">&#39;LastAvgPool&#39;</span>, nn.AvgPool2d(math.ceil(reshape_size<span class="op">/</span><span class="fl">32.</span>))) <span class="co"># input: N x 1280 x 7 x 7</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="va">self</span>.mobilenet.named_parameters():</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>      i[<span class="dv">1</span>].requires_grad <span class="op">=</span> <span class="va">True</span> <span class="co"># fine-tune all</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> verbose:</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>      summary(<span class="va">self</span>.mobilenet.cuda(), (<span class="dv">3</span>, reshape_size, reshape_size))</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, img, verbose<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a><span class="co">    Inputs:</span></span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a><span class="co">    - img: Batch of resized images, of shape Nx3x224x224</span></span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a><span class="co">    Outputs:</span></span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a><span class="co">    - feat: Image feature, of shape Nx1280 (pooled) or Nx1280x7x7</span></span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>    num_img <span class="op">=</span> img.shape[<span class="dv">0</span>]</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>    img_prepro <span class="op">=</span> img</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>    feat <span class="op">=</span> []</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>    process_batch <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> b <span class="kw">in</span> <span class="bu">range</span>(math.ceil(num_img<span class="op">/</span>process_batch)):</span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>      feat.append(<span class="va">self</span>.mobilenet(img_prepro[b<span class="op">*</span>process_batch:(b<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span>process_batch]</span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>                              ).squeeze(<span class="op">-</span><span class="dv">1</span>).squeeze(<span class="op">-</span><span class="dv">1</span>)) <span class="co"># forward and squeeze</span></span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>    feat <span class="op">=</span> torch.cat(feat)</span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> verbose:</span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(<span class="st">&#39;Output feature shape: &#39;</span>, feat.shape)</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> feat</span></code></pre></div>
</div>
<div class="cell markdown" id="qHeRMCcjx6v0">
<p>Now, let's see what's inside MobileNet v2. Assume we have a 3x224x224
image input.</p>
</div>
<div class="cell code" data-execution_count="16"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:0}"
id="_pV0Lau_yDwX" data-outputId="88f5bcbb-ddc3-4bea-d6c0-ac59f0879837">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> FeatureExtractor(verbose<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter &#39;pretrained&#39; is deprecated since 0.13 and may be removed in the future, please use &#39;weights&#39; instead.
  warnings.warn(
/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for &#39;weights&#39; are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 32, 112, 112]             864
       BatchNorm2d-2         [-1, 32, 112, 112]              64
             ReLU6-3         [-1, 32, 112, 112]               0
            Conv2d-4         [-1, 32, 112, 112]             288
       BatchNorm2d-5         [-1, 32, 112, 112]              64
             ReLU6-6         [-1, 32, 112, 112]               0
            Conv2d-7         [-1, 16, 112, 112]             512
       BatchNorm2d-8         [-1, 16, 112, 112]              32
  InvertedResidual-9         [-1, 16, 112, 112]               0
           Conv2d-10         [-1, 96, 112, 112]           1,536
      BatchNorm2d-11         [-1, 96, 112, 112]             192
            ReLU6-12         [-1, 96, 112, 112]               0
           Conv2d-13           [-1, 96, 56, 56]             864
      BatchNorm2d-14           [-1, 96, 56, 56]             192
            ReLU6-15           [-1, 96, 56, 56]               0
           Conv2d-16           [-1, 24, 56, 56]           2,304
      BatchNorm2d-17           [-1, 24, 56, 56]              48
 InvertedResidual-18           [-1, 24, 56, 56]               0
           Conv2d-19          [-1, 144, 56, 56]           3,456
      BatchNorm2d-20          [-1, 144, 56, 56]             288
            ReLU6-21          [-1, 144, 56, 56]               0
           Conv2d-22          [-1, 144, 56, 56]           1,296
      BatchNorm2d-23          [-1, 144, 56, 56]             288
            ReLU6-24          [-1, 144, 56, 56]               0
           Conv2d-25           [-1, 24, 56, 56]           3,456
      BatchNorm2d-26           [-1, 24, 56, 56]              48
 InvertedResidual-27           [-1, 24, 56, 56]               0
           Conv2d-28          [-1, 144, 56, 56]           3,456
      BatchNorm2d-29          [-1, 144, 56, 56]             288
            ReLU6-30          [-1, 144, 56, 56]               0
           Conv2d-31          [-1, 144, 28, 28]           1,296
      BatchNorm2d-32          [-1, 144, 28, 28]             288
            ReLU6-33          [-1, 144, 28, 28]               0
           Conv2d-34           [-1, 32, 28, 28]           4,608
      BatchNorm2d-35           [-1, 32, 28, 28]              64
 InvertedResidual-36           [-1, 32, 28, 28]               0
           Conv2d-37          [-1, 192, 28, 28]           6,144
      BatchNorm2d-38          [-1, 192, 28, 28]             384
            ReLU6-39          [-1, 192, 28, 28]               0
           Conv2d-40          [-1, 192, 28, 28]           1,728
      BatchNorm2d-41          [-1, 192, 28, 28]             384
            ReLU6-42          [-1, 192, 28, 28]               0
           Conv2d-43           [-1, 32, 28, 28]           6,144
      BatchNorm2d-44           [-1, 32, 28, 28]              64
 InvertedResidual-45           [-1, 32, 28, 28]               0
           Conv2d-46          [-1, 192, 28, 28]           6,144
      BatchNorm2d-47          [-1, 192, 28, 28]             384
            ReLU6-48          [-1, 192, 28, 28]               0
           Conv2d-49          [-1, 192, 28, 28]           1,728
      BatchNorm2d-50          [-1, 192, 28, 28]             384
            ReLU6-51          [-1, 192, 28, 28]               0
           Conv2d-52           [-1, 32, 28, 28]           6,144
      BatchNorm2d-53           [-1, 32, 28, 28]              64
 InvertedResidual-54           [-1, 32, 28, 28]               0
           Conv2d-55          [-1, 192, 28, 28]           6,144
      BatchNorm2d-56          [-1, 192, 28, 28]             384
            ReLU6-57          [-1, 192, 28, 28]               0
           Conv2d-58          [-1, 192, 14, 14]           1,728
      BatchNorm2d-59          [-1, 192, 14, 14]             384
            ReLU6-60          [-1, 192, 14, 14]               0
           Conv2d-61           [-1, 64, 14, 14]          12,288
      BatchNorm2d-62           [-1, 64, 14, 14]             128
 InvertedResidual-63           [-1, 64, 14, 14]               0
           Conv2d-64          [-1, 384, 14, 14]          24,576
      BatchNorm2d-65          [-1, 384, 14, 14]             768
            ReLU6-66          [-1, 384, 14, 14]               0
           Conv2d-67          [-1, 384, 14, 14]           3,456
      BatchNorm2d-68          [-1, 384, 14, 14]             768
            ReLU6-69          [-1, 384, 14, 14]               0
           Conv2d-70           [-1, 64, 14, 14]          24,576
      BatchNorm2d-71           [-1, 64, 14, 14]             128
 InvertedResidual-72           [-1, 64, 14, 14]               0
           Conv2d-73          [-1, 384, 14, 14]          24,576
      BatchNorm2d-74          [-1, 384, 14, 14]             768
            ReLU6-75          [-1, 384, 14, 14]               0
           Conv2d-76          [-1, 384, 14, 14]           3,456
      BatchNorm2d-77          [-1, 384, 14, 14]             768
            ReLU6-78          [-1, 384, 14, 14]               0
           Conv2d-79           [-1, 64, 14, 14]          24,576
      BatchNorm2d-80           [-1, 64, 14, 14]             128
 InvertedResidual-81           [-1, 64, 14, 14]               0
           Conv2d-82          [-1, 384, 14, 14]          24,576
      BatchNorm2d-83          [-1, 384, 14, 14]             768
            ReLU6-84          [-1, 384, 14, 14]               0
           Conv2d-85          [-1, 384, 14, 14]           3,456
      BatchNorm2d-86          [-1, 384, 14, 14]             768
            ReLU6-87          [-1, 384, 14, 14]               0
           Conv2d-88           [-1, 64, 14, 14]          24,576
      BatchNorm2d-89           [-1, 64, 14, 14]             128
 InvertedResidual-90           [-1, 64, 14, 14]               0
           Conv2d-91          [-1, 384, 14, 14]          24,576
      BatchNorm2d-92          [-1, 384, 14, 14]             768
            ReLU6-93          [-1, 384, 14, 14]               0
           Conv2d-94          [-1, 384, 14, 14]           3,456
      BatchNorm2d-95          [-1, 384, 14, 14]             768
            ReLU6-96          [-1, 384, 14, 14]               0
           Conv2d-97           [-1, 96, 14, 14]          36,864
      BatchNorm2d-98           [-1, 96, 14, 14]             192
 InvertedResidual-99           [-1, 96, 14, 14]               0
          Conv2d-100          [-1, 576, 14, 14]          55,296
     BatchNorm2d-101          [-1, 576, 14, 14]           1,152
           ReLU6-102          [-1, 576, 14, 14]               0
          Conv2d-103          [-1, 576, 14, 14]           5,184
     BatchNorm2d-104          [-1, 576, 14, 14]           1,152
           ReLU6-105          [-1, 576, 14, 14]               0
          Conv2d-106           [-1, 96, 14, 14]          55,296
     BatchNorm2d-107           [-1, 96, 14, 14]             192
InvertedResidual-108           [-1, 96, 14, 14]               0
          Conv2d-109          [-1, 576, 14, 14]          55,296
     BatchNorm2d-110          [-1, 576, 14, 14]           1,152
           ReLU6-111          [-1, 576, 14, 14]               0
          Conv2d-112          [-1, 576, 14, 14]           5,184
     BatchNorm2d-113          [-1, 576, 14, 14]           1,152
           ReLU6-114          [-1, 576, 14, 14]               0
          Conv2d-115           [-1, 96, 14, 14]          55,296
     BatchNorm2d-116           [-1, 96, 14, 14]             192
InvertedResidual-117           [-1, 96, 14, 14]               0
          Conv2d-118          [-1, 576, 14, 14]          55,296
     BatchNorm2d-119          [-1, 576, 14, 14]           1,152
           ReLU6-120          [-1, 576, 14, 14]               0
          Conv2d-121            [-1, 576, 7, 7]           5,184
     BatchNorm2d-122            [-1, 576, 7, 7]           1,152
           ReLU6-123            [-1, 576, 7, 7]               0
          Conv2d-124            [-1, 160, 7, 7]          92,160
     BatchNorm2d-125            [-1, 160, 7, 7]             320
InvertedResidual-126            [-1, 160, 7, 7]               0
          Conv2d-127            [-1, 960, 7, 7]         153,600
     BatchNorm2d-128            [-1, 960, 7, 7]           1,920
           ReLU6-129            [-1, 960, 7, 7]               0
          Conv2d-130            [-1, 960, 7, 7]           8,640
     BatchNorm2d-131            [-1, 960, 7, 7]           1,920
           ReLU6-132            [-1, 960, 7, 7]               0
          Conv2d-133            [-1, 160, 7, 7]         153,600
     BatchNorm2d-134            [-1, 160, 7, 7]             320
InvertedResidual-135            [-1, 160, 7, 7]               0
          Conv2d-136            [-1, 960, 7, 7]         153,600
     BatchNorm2d-137            [-1, 960, 7, 7]           1,920
           ReLU6-138            [-1, 960, 7, 7]               0
          Conv2d-139            [-1, 960, 7, 7]           8,640
     BatchNorm2d-140            [-1, 960, 7, 7]           1,920
           ReLU6-141            [-1, 960, 7, 7]               0
          Conv2d-142            [-1, 160, 7, 7]         153,600
     BatchNorm2d-143            [-1, 160, 7, 7]             320
InvertedResidual-144            [-1, 160, 7, 7]               0
          Conv2d-145            [-1, 960, 7, 7]         153,600
     BatchNorm2d-146            [-1, 960, 7, 7]           1,920
           ReLU6-147            [-1, 960, 7, 7]               0
          Conv2d-148            [-1, 960, 7, 7]           8,640
     BatchNorm2d-149            [-1, 960, 7, 7]           1,920
           ReLU6-150            [-1, 960, 7, 7]               0
          Conv2d-151            [-1, 320, 7, 7]         307,200
     BatchNorm2d-152            [-1, 320, 7, 7]             640
InvertedResidual-153            [-1, 320, 7, 7]               0
          Conv2d-154           [-1, 1280, 7, 7]         409,600
     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560
           ReLU6-156           [-1, 1280, 7, 7]               0
================================================================
Total params: 2,223,872
Trainable params: 2,223,872
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 152.85
Params size (MB): 8.48
Estimated Total Size (MB): 161.91
----------------------------------------------------------------
</code></pre>
</div>
</div>
<section id="anchor-and-proposal" class="cell markdown"
id="zz32q025joxy">
<h1>Anchor and Proposal</h1>
<p>The concept of <em>anchor</em> is introduced in <a
href="https://arxiv.org/pdf/1506.01497.pdf">Faster R-CNN</a> and later
used in numerous later works including <a
href="https://arxiv.org/pdf/1612.08242.pdf">YOLO v2</a>. The definition
of anchor from the original paper is summarized as follows:</p>
<p>After passing the input image through the backbone network, we have a
convolutional feature map of shape <span
class="math inline">(<em>C</em>,7,7)</span> which we interpret as a 7x7
grid of <span class="math inline"><em>C</em></span>-dimensional
features. At each point in this grid, we consider a set of <span
class="math inline"><em>A</em></span> <em>anchor boxes</em> of different
sizes and shapes; for each anchor box we classify it as either an object
or background box. The total number of anchor boxes that we consider for
the entire input image is <span
class="math inline">(<em>A</em>,7,7)</span>; we predict classification
scores of this shape by applying a sequence of convolutional layers to
the backbone features.</p>
<p>We slide a small network (e.g., 3x3 conv layer) over the CNN
activation feature map. We call this 3x3 conv a sliding window. At each
sliding-window location (i.e., centered at each position of the 7x7
activation cell), we simultaneously predict multiple region
<em>proposals</em>, where the number of proposals for each location is
denoted as <span class="math inline"><em>A</em> = 9</span>.</p>
<p>Later, we will have an object proposal layer outputs A-D scores that
estimate probability of object for each proposal, a bounding box
regression layer to produce 4A-D outputs encoding the coordinates of A
boxes, and a region classification layer to produce 20-D outputs
indicating the probability of being each object category (shared by all
A anchors). The A <em>proposals</em> are parameterized relative to A
reference boxes, which we call <em>anchors</em>. An anchor is centered
at the sliding window in question, and is associated with a shape (e.g.,
1x1, 3x3, 5x5). The list of anchor shapes are provided next.</p>
</section>
<section id="anchor-shapes" class="cell markdown" id="etBYc7rbj35F">
<h2>Anchor shapes</h2>
<p>At each spatial position of the 7x7 backbone features, we consider a
set of <span class="math inline"><em>A</em></span> anchor boxes.
Different spatial positions all use anchors of the same shape.</p>
<p>The shapes of the anchor boxes are a hyperparameter. We will provide
the anchor shapes for you. In some papers (e.g. YOLO v2), the anchor
shapes are determined in a data-driven way by clustering the set of
ground-truth box sizes, but for simplicity we will not use that approach
in this assignment.</p>
<p>Note that anchors could be much larger than the 3x3 sliding window
(e.g., 5x5) since the receptive field of activation cell on the original
image could be large.</p>
</section>
<div class="cell code" data-execution_count="17"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:0}"
id="O5w-EUJekJj-" data-outputId="2dce6e94-f58f-438f-82ee-c13731fd5109">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Declare variables for anchor priors, a Ax2 Tensor where A is the number of anchors.</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Hand-picked, same as our two-stage detector.</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>anchor_list <span class="op">=</span> torch.tensor([[<span class="dv">1</span>, <span class="dv">1</span>], [<span class="dv">2</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">3</span>], [<span class="dv">4</span>, <span class="dv">4</span>], [<span class="dv">5</span>, <span class="dv">5</span>], [<span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">3</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">5</span>], [<span class="dv">5</span>, <span class="dv">3</span>]], <span class="op">**</span>to_float_cuda)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(anchor_list.shape)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>torch.Size([9, 2])
</code></pre>
</div>
</div>
<section id="activation-grid-generator" class="cell markdown"
id="uochvAlqkgr8">
<h2>Activation Grid Generator</h2>
<p>In order to place anchors centered at each position of the 7x7 grid
of backbone features, we need to know the spatial position of the center
of each cell in the 7x7 grid of features.</p>
<p>This function will compute these center coordinates for us.</p>
</section>
<div class="cell code" data-execution_count="18" id="fC9-TKRykof7">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> GenerateGrid(batch_size, w_amap<span class="op">=</span><span class="dv">7</span>, h_amap<span class="op">=</span><span class="dv">7</span>, dtype<span class="op">=</span>torch.float32, device<span class="op">=</span><span class="st">&#39;cuda&#39;</span>):</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co">  Return a grid cell given a batch size (center coordinates).</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="co">  Inputs:</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="co">  - batch_size, B</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - w_amap: or W&#39;, width of the activation map (number of grids in the horizontal dimension)</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co">  - h_amap: or H&#39;, height of the activation map (number of grids in the vertical dimension)</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="co">  - W&#39; and H&#39; are always 7 in our case while w and h might vary.</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="co">  Outputs:</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="co">  grid: A float32 tensor of shape (B, H&#39;, W&#39;, 2) giving the (x, y) coordinates</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="co">        of the centers of each feature for a feature map of shape (B, D, H&#39;, W&#39;)</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a><span class="co">  &quot;&quot;&quot;</span></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>  w_range <span class="op">=</span> torch.arange(<span class="dv">0</span>, w_amap, dtype<span class="op">=</span>dtype, device<span class="op">=</span>device) <span class="op">+</span> <span class="fl">0.5</span></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>  h_range <span class="op">=</span> torch.arange(<span class="dv">0</span>, h_amap, dtype<span class="op">=</span>dtype, device<span class="op">=</span>device) <span class="op">+</span> <span class="fl">0.5</span></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>  w_grid_idx <span class="op">=</span> w_range.unsqueeze(<span class="dv">0</span>).repeat(h_amap, <span class="dv">1</span>)</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>  h_grid_idx <span class="op">=</span> h_range.unsqueeze(<span class="dv">1</span>).repeat(<span class="dv">1</span>, w_amap)</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>  grid <span class="op">=</span> torch.stack([w_grid_idx, h_grid_idx], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>  grid <span class="op">=</span> grid.unsqueeze(<span class="dv">0</span>).repeat(batch_size, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> grid</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="19"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="UCHpDXV0sdEX" data-outputId="7510af9e-4586-463c-bf22-c21e5a86225c">
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualization</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="co"># simply create an activation grid where the cells are in green and the centers in red</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="co"># you should see the entire image divided by a 7x7 grid, with no gaps on the edges</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>grid_list <span class="op">=</span> GenerateGrid(w_list.shape[<span class="dv">0</span>])</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>center <span class="op">=</span> torch.cat((grid_list, grid_list), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>grid_cell <span class="op">=</span> center.clone()</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>grid_cell[:, :, :, [<span class="dv">0</span>, <span class="dv">1</span>]] <span class="op">-=</span> <span class="fl">1.</span> <span class="op">/</span> <span class="fl">2.</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>grid_cell[:, :, :, [<span class="dv">2</span>, <span class="dv">3</span>]] <span class="op">+=</span> <span class="fl">1.</span> <span class="op">/</span> <span class="fl">2.</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>center <span class="op">=</span> coord_trans(center, w_list, h_list)</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>grid_cell <span class="op">=</span> coord_trans(grid_cell, w_list, h_list)</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> img, anc, grid <span class="kw">in</span> <span class="bu">zip</span>(img_list, center, grid_cell):</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>  data_visualizer(img, idx_to_class, anc.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>), grid.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>))</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/a1f5923be88ea1cc05775bbc160c9757dac65291.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/2f28e1bb5adea8344eb93492f719737496ca7daa.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/e596f249d7d20f9061525ae22b640143923b8001.png" /></p>
</div>
</div>
<section id="anchor-generator" class="cell markdown" id="R0knLi5KkxoS">
<h2>Anchor Generator</h2>
<p>At this point we have defined the spatial sizes of anchors that we
consider at each grid point, and we have computed the center of each
grid point. We now combine these two pieces of information to compute
the positions of all anchor boxes for the entire image.</p>
<p>We denote the anchor coordinates as (<span
class="math inline"><em>x</em><sub><em>t</em><em>l</em></sub><sup><em>a</em></sup></span>,
<span
class="math inline"><em>y</em><sub><em>t</em><em>l</em></sub><sup><em>a</em></sup></span>,
<span
class="math inline"><em>x</em><sub><em>b</em><em>r</em></sub><sup><em>a</em></sup></span>,
<span
class="math inline"><em>y</em><sub><em>b</em><em>r</em></sub><sup><em>a</em></sup></span>),
indicating the coordinates of the top-left corner and the bottom-right
corner accordingly. The following function returns all the anchors given
the anchor shapes and the grid cell. <strong>Note that the center of an
anchor overlaps a grid cell center.</strong></p>
</section>
<div class="cell code" data-execution_count="20" id="AzuHo-WRrew-">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> GenerateAnchor(anc, grid):</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co">  Anchor generator.</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co">  Inputs:</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co">  - anc: Tensor of shape (A, 2) giving the shapes of anchor boxes to consider at</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co">    each point in the grid. anc[a] = (w, h) gives the width and height of the</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co">    a&#39;th anchor shape.</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="co">  - grid: Tensor of shape (B, H&#39;, W&#39;, 2) giving the (x, y) coordinates of the</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="co">    center of each feature from the backbone feature map. This is the tensor</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="co">    returned from GenerateGrid.</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="co">  Outputs:</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="co">  - anchors: Tensor of shape (B, A, H&#39;, W&#39;, 4) giving the positions of all</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="co">    anchor boxes for the entire image. anchors[b, a, h, w] is an anchor box</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="co">    centered at grid[b, h, w], whose shape is given by anc[a]; we parameterize</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="co">    boxes as anchors[b, a, h, w] = (x_tl, y_tl, x_br, y_br), where (x_tl, y_tl)</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a><span class="co">    and (x_br, y_br) give the xy coordinates of the top-left and bottom-right</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a><span class="co">    corners of the box.</span></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a><span class="co">  &quot;&quot;&quot;</span></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>  anc <span class="op">=</span> anc.to(grid.device)</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>  anchors <span class="op">=</span> <span class="va">None</span></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>  <span class="co">##############################################################################</span></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>  <span class="co"># </span><span class="al">TODO</span><span class="co">: Given a set of anchor shapes and a grid cell on the activation map,  #</span></span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># generate all the anchor coordinates for each image. Support batch input.   #</span></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>  <span class="co">##############################################################################</span></span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Replace &quot;pass&quot; statement with your code</span></span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a> <span class="co"># Compute half widths and heights</span></span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>  half_anc <span class="op">=</span> anc <span class="op">/</span> <span class="fl">2.0</span>  <span class="co"># shape (A, 2)</span></span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Reshape for broadcasting:</span></span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>  <span class="co"># grid: (B, H, W, 2) -&gt; (B, 1, H, W, 2)</span></span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>  <span class="co"># half_anc: (A, 2) -&gt; (1, A, 1, 1, 2)</span></span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>  grid <span class="op">=</span> grid.unsqueeze(<span class="dv">1</span>)</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>  half_anc <span class="op">=</span> half_anc.view(<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute top-left and bottom-right coordinates via broadcasting:</span></span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>  anchors <span class="op">=</span> torch.cat([grid <span class="op">-</span> half_anc, grid <span class="op">+</span> half_anc], dim<span class="op">=-</span><span class="dv">1</span>)  <span class="co"># shape (B, A, H, W, 4)</span></span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>  <span class="co">##############################################################################</span></span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>  <span class="co">#                               </span><span class="re">END</span><span class="co"> OF YOUR CODE                             #</span></span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a>  <span class="co">##############################################################################</span></span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> anchors</span></code></pre></div>
</div>
<div class="cell markdown" id="9an-jXEr62yq">
<p>Run the following to check your implementation. You should see errors
on the order of 1e-8 or less.</p>
</div>
<div class="cell code" data-execution_count="21"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:0}"
id="gffaPg4Dsfux" data-outputId="bdd9b5f7-751f-4b5a-d506-e83e52699426">
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sanity check</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>anc_list <span class="op">=</span> GenerateAnchor(anchor_list, grid_list)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> anc_list.shape <span class="op">==</span> torch.Size([<span class="dv">3</span>, <span class="dv">9</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">4</span>]), <span class="st">&#39;shape mismatch!&#39;</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>expected_anc_list_mean <span class="op">=</span> torch.tensor([[<span class="op">-</span><span class="fl">1.25000000</span>, <span class="op">-</span><span class="fl">0.87500000</span>,  <span class="fl">2.25000000</span>,  <span class="fl">1.87500000</span>],</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>                                       [ <span class="fl">1.75000000</span>, <span class="op">-</span><span class="fl">0.87500000</span>,  <span class="fl">5.25000000</span>,  <span class="fl">1.87500000</span>],</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>                                       [ <span class="fl">4.75000000</span>, <span class="op">-</span><span class="fl">0.87500000</span>,  <span class="fl">8.25000000</span>,  <span class="fl">1.87500000</span>],</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>                                       [<span class="op">-</span><span class="fl">1.25000000</span>,  <span class="fl">1.12500000</span>,  <span class="fl">2.25000000</span>,  <span class="fl">3.87500000</span>],</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>                                       [ <span class="fl">1.75000000</span>,  <span class="fl">1.12500000</span>,  <span class="fl">5.25000000</span>,  <span class="fl">3.87500000</span>],</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>                                       [ <span class="fl">4.75000000</span>,  <span class="fl">1.12500000</span>,  <span class="fl">8.25000000</span>,  <span class="fl">3.87500000</span>],</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>                                       [<span class="op">-</span><span class="fl">1.25000000</span>,  <span class="fl">3.12500000</span>,  <span class="fl">2.25000000</span>,  <span class="fl">5.87500000</span>],</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>                                       [ <span class="fl">1.75000000</span>,  <span class="fl">3.12500000</span>,  <span class="fl">5.25000000</span>,  <span class="fl">5.87500000</span>],</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>                                       [ <span class="fl">4.75000000</span>,  <span class="fl">3.12500000</span>,  <span class="fl">8.25000000</span>,  <span class="fl">5.87500000</span>],</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>                                       [<span class="op">-</span><span class="fl">1.25000000</span>,  <span class="fl">5.12500000</span>,  <span class="fl">2.25000000</span>,  <span class="fl">7.87500000</span>],</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>                                       [ <span class="fl">1.75000000</span>,  <span class="fl">5.12500000</span>,  <span class="fl">5.25000000</span>,  <span class="fl">7.87500000</span>],</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>                                       [ <span class="fl">4.75000000</span>,  <span class="fl">5.12500000</span>,  <span class="fl">8.25000000</span>,  <span class="fl">7.87500000</span>]], <span class="op">**</span>to_float_cuda)</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>error <span class="op">=</span> rel_error(expected_anc_list_mean, anc_list[<span class="dv">0</span>, [<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">6</span>,<span class="dv">8</span>], ::<span class="dv">2</span>, ::<span class="dv">3</span>, :].view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">12</span>, <span class="dv">4</span>).mean(<span class="dv">0</span>))</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">if</span> error <span class="op">&lt;</span> <span class="fl">1e-6</span> <span class="cf">else</span> <span class="st">&quot;Fail&quot;</span></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>color <span class="op">=</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[92m&quot;</span> <span class="cf">if</span> result <span class="op">==</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">else</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[91m&quot;</span></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Relative Error: </span><span class="sc">{</span>error<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>color<span class="sc">}</span><span class="ss">Result: </span><span class="sc">{</span>result<span class="sc">}</span><span class="ch">\033</span><span class="ss">[0m&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Relative Error: 0.0
Result: Pass
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="22"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1955}"
id="xbxTvazYyV7P" data-outputId="29f3fe88-f873-4d87-b8bf-c66c96184a25">
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualization</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;*&#39;</span><span class="op">*</span><span class="dv">80</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;All nine anchors should be exactly centered:&#39;</span>)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>anc_list <span class="op">=</span> GenerateAnchor(anchor_list, grid_list[:, <span class="dv">3</span>:<span class="dv">4</span>, <span class="dv">3</span>:<span class="dv">4</span>])</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> img, anc <span class="kw">in</span> <span class="bu">zip</span>(img_list, coord_trans(anc_list, w_list, h_list)):</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(anc.shape)</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>  data_visualizer(img, idx_to_class, anc.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>))</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;*&#39;</span><span class="op">*</span><span class="dv">80</span>)</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;All anchors of the image (cluttered):&#39;</span>)</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>anc_list <span class="op">=</span> GenerateAnchor(anchor_list, grid_list) <span class="co"># all</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> img, anc <span class="kw">in</span> <span class="bu">zip</span>(img_list, coord_trans(anc_list, w_list, h_list)):</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(anc.shape)</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>  data_visualizer(img, idx_to_class, anc.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>********************************************************************************
All nine anchors should be exactly centered:
torch.Size([9, 1, 1, 4])
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/63d10d92c8481caf922a7a096e5c47a72439d555.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>torch.Size([9, 1, 1, 4])
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/f2635b5b7e32a44dda08cc3e9943e44d5501366a.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>torch.Size([9, 1, 1, 4])
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/aa432b7de5da73d2785608ce8a55cfa3cc601cf0.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>********************************************************************************
All anchors of the image (cluttered):
torch.Size([9, 7, 7, 4])
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/36071cc05bec1bcf14d26546b976902e99e8d77f.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>torch.Size([9, 7, 7, 4])
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/7a6c33e6b9f75bdaddd678b7c948aae28cb7ac6f.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>torch.Size([9, 7, 7, 4])
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/c22837d5f30f6aa2059c99b0eb27a28d2f73ae8e.png" /></p>
</div>
</div>
<section id="proposal-generator" class="cell markdown"
id="KCzcNX3Zsi3n">
<h2>Proposal Generator</h2>
<p>If we only use anchors to propose object locations, we can only cover
9x7x7=441 regions in the image. What if an object does not fall into any
of the regions?</p>
<p>Hence, in the recent literatures (e.g., <a
href="https://arxiv.org/pdf/1504.08083.pdf">Fast R-CNN</a>), the
detector predicts transformations that convert anchor boxes into
<em>region proposals</em>.</p>
<p>So far, we have represented anchors boxes by the coordinates of their
top-left and bottom-right corners <span
class="math inline">(<em>x</em><sub><em>t</em><em>l</em></sub><sup><em>a</em></sup>,<em>y</em><sub><em>t</em><em>l</em></sub><sup><em>a</em></sup>,<em>x</em><sub><em>b</em><em>r</em></sub><sup><em>a</em></sup>,<em>y</em><sub><em>b</em><em>r</em></sub><sup><em>a</em></sup>)</span>.
When converting anchors to proposals, it will be more convenient to
parameterize boxes by the xy coordinate of their center, and their with
and height: <span
class="math inline">(<em>x</em><sub><em>c</em></sub><sup><em>a</em></sup>,<em>y</em><sub><em>c</em></sub><sup><em>a</em></sup>,<em>w</em><sup><em>a</em></sup>,<em>h</em><sup><em>a</em></sup>)</span>.</p>
<p>Now, consider an anchor box with center, width and height <span
class="math inline">(<em>x</em><sub><em>c</em></sub><sup><em>a</em></sup>,<em>y</em><sub><em>c</em></sub><sup><em>a</em></sup>,<em>w</em><sup><em>a</em></sup>,<em>h</em><sup><em>a</em></sup>)</span>.
The network will predict a <em>transformation</em> <span
class="math inline">(<em>t</em><sup><em>x</em></sup>,<em>t</em><sup><em>y</em></sup>,<em>t</em><sup><em>w</em></sup>,<em>t</em><sup><em>h</em></sup>)</span>;
applying this transformation to the anchor yields a <em>region
proposal</em> with center, width and height <span
class="math inline">(<em>x</em><sub><em>c</em></sub><sup><em>p</em></sup>,<em>y</em><sub><em>c</em></sub><sup><em>p</em></sup>,<em>w</em><sup><em>p</em></sup>,<em>h</em><sup><em>p</em></sup>)</span>.
YOLO and Faster R-CNN use slightly different formulas to convert anchors
into proposals. Here you need to implement both formulations.</p>
<h3 id="yolo">YOLO</h3>
<p>For YOLO, we assume that <span
class="math inline"><em>t</em><sup><em>x</em></sup></span> and <span
class="math inline"><em>t</em><sup><em>y</em></sup></span> are both in
the range <span
class="math inline"> − 0.5 ≤ <em>t</em><sup><em>x</em></sup>, <em>t</em><sup><em>y</em></sup> ≤ 0.5</span>,
while <span class="math inline"><em>t</em><sup><em>w</em></sup></span>
and <span class="math inline"><em>t</em><sup><em>h</em></sup></span> are
real numbers in the range <span class="math inline">(−∞,∞)</span>. Then
we have:</p>
<ul>
<li><span
class="math inline"><em>x</em><sub><em>c</em></sub><sup><em>p</em></sup> = <em>x</em><sub><em>c</em></sub><sup><em>a</em></sup> + <em>t</em><sup><em>x</em></sup></span></li>
<li><span
class="math inline"><em>y</em><sub><em>c</em></sub><sup><em>p</em></sup> = <em>y</em><sub><em>c</em></sub><sup><em>a</em></sup> + <em>t</em><sup><em>y</em></sup></span></li>
<li><span
class="math inline"><em>w</em><sup><em>p</em></sup> = <em>w</em><sub><em>a</em></sub><em>e</em><em>x</em><em>p</em>(<em>t</em><sup><em>w</em></sup>)</span></li>
<li><span
class="math inline"><em>h</em><sup><em>p</em></sup> = <em>h</em><sub><em>a</em></sub><em>e</em><em>x</em><em>p</em>(<em>t</em><sup><em>h</em></sup>)</span></li>
</ul>
<h3 id="faster-r-cnn">Faster R-CNN</h3>
<p>For Faster R-CNN, we assume that all transformation parameters <span
class="math inline"><em>t</em><sup><em>x</em></sup>, <em>t</em><sup><em>y</em></sup>, <em>t</em><sup><em>w</em></sup>, <em>t</em><sub><em>h</em></sub></span>
are real numbers in the range <span class="math inline">(−∞,∞)</span>.
Then we have:</p>
<ul>
<li><span
class="math inline"><em>x</em><sub><em>c</em></sub><sup><em>p</em></sup> = <em>x</em><sub><em>c</em></sub><sup><em>a</em></sup> + <em>t</em><sup><em>x</em></sup><em>w</em><sup><em>a</em></sup></span></li>
<li><span
class="math inline"><em>y</em><sub><em>c</em></sub><sup><em>p</em></sup> = <em>y</em><sub><em>c</em></sub><sup><em>p</em></sup> + <em>t</em><sup><em>y</em></sup><em>h</em><sup><em>a</em></sup></span></li>
<li><span
class="math inline"><em>w</em><sup><em>p</em></sup> = <em>w</em><sub><em>a</em></sub><em>e</em><em>x</em><em>p</em>(<em>t</em><sup><em>w</em></sup>)</span></li>
<li><span
class="math inline"><em>h</em><sup><em>p</em></sup> = <em>h</em><sub><em>a</em></sub><em>e</em><em>x</em><em>p</em>(<em>t</em><sup><em>h</em></sup>)</span></li>
</ul>
<h3 id="training">Training</h3>
<p>During training, we compute the ground-truth transformation <span
class="math inline">$(\hat{t^x}, \hat{t^y}, \hat{t^w},
\hat{t^h})$</span> that would transform the anchor box <span
class="math inline">(<em>x</em><sub><em>c</em></sub><sup><em>a</em></sup>,<em>y</em><sub><em>c</em></sub><sup><em>a</em></sup>,<em>w</em><sup><em>a</em></sup>,<em>h</em><sup><em>a</em></sup>)</span>
into the the ground-truth box <span
class="math inline">(<em>x</em><sub><em>c</em></sub><sup><em>g</em><em>t</em></sup>,<em>y</em><sub><em>c</em></sub><sup><em>g</em><em>t</em></sup>,<em>w</em><sup><em>g</em><em>t</em></sup>,<em>h</em><sup><em>g</em><em>t</em></sup>)</span>.
We then apply a regression loss that penalizes differences between the
predicted transform <span
class="math inline">(<em>t</em><sup><em>x</em></sup>,<em>t</em><sup><em>y</em></sup>,<em>t</em><sup><em>w</em></sup>,<em>t</em><sup><em>h</em></sup>)</span>
and the ground-truth transform.</p>
</section>
<div class="cell code" data-execution_count="23" id="Mx9BlyIXspZy">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> GenerateProposal(anchors, offsets, method<span class="op">=</span><span class="st">&#39;YOLO&#39;</span>):</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="co">  Proposal generator.</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="co">  Inputs:</span></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="co">  - anchors: Anchor boxes, of shape (B, A, H&#39;, W&#39;, 4). Each anchor is represented</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="co">             as (x_tl, y_tl, x_br, y_br).</span></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="co">  - offsets: Transformations that convert anchors into proposals. Can be either</span></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a><span class="co">             of shape (B, A, 4, H&#39;, W&#39;) or (B, A, H&#39;, W&#39;, 4). The transformation</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a><span class="co">             offsets[b, a, ...] = (tx, ty, tw, th).</span></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a><span class="co">  - method: Which transformation formula to use, either &#39;YOLO&#39; or &#39;FasterRCNN&#39;</span></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a><span class="co">  Outputs:</span></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a><span class="co">  - proposals: Region proposals of shape (B, A, H&#39;, W&#39;, 4), represented as</span></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a><span class="co">               (x_tl, y_tl, x_br, y_br)</span></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a><span class="co">  &quot;&quot;&quot;</span></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">assert</span>(method <span class="kw">in</span> [<span class="st">&#39;YOLO&#39;</span>, <span class="st">&#39;FasterRCNN&#39;</span>])</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># If offsets is in (B, A, 4, H&#39;, W&#39;), permute it to (B, A, H&#39;, W&#39;, 4)</span></span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> offsets.dim() <span class="op">==</span> <span class="dv">5</span> <span class="kw">and</span> offsets.shape[<span class="dv">2</span>] <span class="op">==</span> <span class="dv">4</span>:</span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>    offsets <span class="op">=</span> offsets.permute(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>)</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Convert anchors to center, width, height format</span></span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a>  anchor_centers <span class="op">=</span> (anchors[..., :<span class="dv">2</span>] <span class="op">+</span> anchors[..., <span class="dv">2</span>:]) <span class="op">/</span> <span class="fl">2.0</span></span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a>  anchor_sizes <span class="op">=</span> anchors[..., <span class="dv">2</span>:] <span class="op">-</span> anchors[..., :<span class="dv">2</span>]</span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> method <span class="op">==</span> <span class="st">&#39;YOLO&#39;</span>:</span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply YOLO transformation</span></span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a>    proposal_centers <span class="op">=</span> anchor_centers <span class="op">+</span> offsets[..., :<span class="dv">2</span>]</span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a>    proposal_sizes <span class="op">=</span> anchor_sizes <span class="op">*</span> torch.exp(offsets[..., <span class="dv">2</span>:])</span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a>  <span class="cf">elif</span> method <span class="op">==</span> <span class="st">&#39;FasterRCNN&#39;</span>:</span>
<span id="cb37-32"><a href="#cb37-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply Faster R-CNN transformation</span></span>
<span id="cb37-33"><a href="#cb37-33" aria-hidden="true" tabindex="-1"></a>    proposal_centers <span class="op">=</span> anchor_centers <span class="op">+</span> offsets[..., :<span class="dv">2</span>] <span class="op">*</span> anchor_sizes</span>
<span id="cb37-34"><a href="#cb37-34" aria-hidden="true" tabindex="-1"></a>    proposal_sizes <span class="op">=</span> anchor_sizes <span class="op">*</span> torch.exp(offsets[..., <span class="dv">2</span>:])</span>
<span id="cb37-35"><a href="#cb37-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-36"><a href="#cb37-36" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Convert back to top-left, bottom-right format</span></span>
<span id="cb37-37"><a href="#cb37-37" aria-hidden="true" tabindex="-1"></a>  proposals <span class="op">=</span> torch.cat([proposal_centers <span class="op">-</span> proposal_sizes <span class="op">/</span> <span class="dv">2</span>,</span>
<span id="cb37-38"><a href="#cb37-38" aria-hidden="true" tabindex="-1"></a>                         proposal_centers <span class="op">+</span> proposal_sizes <span class="op">/</span> <span class="dv">2</span>], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb37-39"><a href="#cb37-39" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> proposals</span></code></pre></div>
</div>
<div class="cell markdown" id="1IglWagADIb6">
<p>Run the following to check your implementation. You should see errors
on the order of 1e-6 or less.</p>
</div>
<div class="cell code" data-execution_count="24"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:0}"
id="beEUhlCHtFAN" data-outputId="e43216cb-002e-41b5-8964-f303cf498ee8">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;-&#39;</span> <span class="op">*</span> <span class="dv">80</span>)</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Sanity check for YOLO.&#39;</span>)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>yolo_offset_list <span class="op">=</span> torch.cat([torch.ones_like(anc_list[:, :, :, :, <span class="dv">0</span>:<span class="dv">2</span>]).fill_(<span class="fl">.5</span>), torch.ones_like(anc_list[:, :, :, :, <span class="dv">2</span>:<span class="dv">4</span>])], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>yolo_proposal_list <span class="op">=</span> GenerateProposal(anc_list, yolo_offset_list, <span class="st">&#39;YOLO&#39;</span>) <span class="co"># no scaling</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;1. Center moved by ~0.5 cell&#39;</span>)</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>error <span class="op">=</span> rel_error(anc_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">0</span>:<span class="dv">2</span>] <span class="op">+</span> (anc_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">2</span>:<span class="dv">4</span>] <span class="op">-</span> anc_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">0</span>:<span class="dv">2</span>])<span class="op">/</span><span class="fl">2.0</span> <span class="op">+</span> <span class="fl">0.5</span>, <span class="op">\</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>        (yolo_proposal_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">0</span>:<span class="dv">2</span>] <span class="op">+</span> (yolo_proposal_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">2</span>:<span class="dv">4</span>] <span class="op">-</span> yolo_proposal_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">0</span>:<span class="dv">2</span>]) <span class="op">/</span> <span class="fl">2.0</span>))</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">if</span> error <span class="op">&lt;</span> <span class="fl">1e-6</span> <span class="cf">else</span> <span class="st">&quot;Fail&quot;</span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>color <span class="op">=</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[92m&quot;</span> <span class="cf">if</span> result <span class="op">==</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">else</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[91m&quot;</span></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Relative Error: </span><span class="sc">{</span>error<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>color<span class="sc">}</span><span class="ss">Result: </span><span class="sc">{</span>result<span class="sc">}</span><span class="ch">\033</span><span class="ss">[0m&#39;</span>)</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;2. w/h changed by e&#39;</span>)</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>error <span class="op">=</span> rel_error((anc_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">2</span>:<span class="dv">4</span>] <span class="op">-</span> anc_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">0</span>:<span class="dv">2</span>]) <span class="op">*</span> torch.exp(torch.ones_like(anc_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">0</span>:<span class="dv">2</span>])), <span class="op">\</span></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>        (yolo_proposal_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">2</span>:<span class="dv">4</span>] <span class="op">-</span> yolo_proposal_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">0</span>:<span class="dv">2</span>]))</span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">if</span> error <span class="op">&lt;</span> <span class="fl">1e-6</span> <span class="cf">else</span> <span class="st">&quot;Fail&quot;</span></span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>color <span class="op">=</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[92m&quot;</span> <span class="cf">if</span> result <span class="op">==</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">else</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[91m&quot;</span></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Relative Error: </span><span class="sc">{</span>error<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>color<span class="sc">}</span><span class="ss">Result: </span><span class="sc">{</span>result<span class="sc">}</span><span class="ch">\033</span><span class="ss">[0m&#39;</span>)</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;-&#39;</span> <span class="op">*</span> <span class="dv">80</span>)</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Sanity check for FasterRCNN.&#39;</span>)</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>rcnn_offset_list <span class="op">=</span> torch.ones_like(anc_list)</span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>rcnn_proposal_list <span class="op">=</span> GenerateProposal(anc_list, rcnn_offset_list, <span class="st">&#39;FasterRCNN&#39;</span>)</span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;1. x/y shifted by wh&#39;</span>)</span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a>error <span class="op">=</span> rel_error(anc_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">0</span>:<span class="dv">2</span>] <span class="op">+</span> (anc_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">2</span>:<span class="dv">4</span>] <span class="op">-</span> anc_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">0</span>:<span class="dv">2</span>]) <span class="op">*</span> <span class="fl">3.0</span> <span class="op">/</span><span class="fl">2.0</span>, <span class="op">\</span></span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a>      (rcnn_proposal_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">0</span>:<span class="dv">2</span>] <span class="op">+</span> (rcnn_proposal_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">2</span>:<span class="dv">4</span>] <span class="op">-</span> rcnn_proposal_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">0</span>:<span class="dv">2</span>]) <span class="op">/</span> <span class="fl">2.0</span>))</span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">if</span> error <span class="op">&lt;</span> <span class="fl">1e-6</span> <span class="cf">else</span> <span class="st">&quot;Fail&quot;</span></span>
<span id="cb38-29"><a href="#cb38-29" aria-hidden="true" tabindex="-1"></a>color <span class="op">=</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[92m&quot;</span> <span class="cf">if</span> result <span class="op">==</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">else</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[91m&quot;</span></span>
<span id="cb38-30"><a href="#cb38-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Relative Error: </span><span class="sc">{</span>error<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>color<span class="sc">}</span><span class="ss">Result: </span><span class="sc">{</span>result<span class="sc">}</span><span class="ch">\033</span><span class="ss">[0m&#39;</span>)</span>
<span id="cb38-31"><a href="#cb38-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-32"><a href="#cb38-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;2. w/h should changed by e&#39;</span>)</span>
<span id="cb38-33"><a href="#cb38-33" aria-hidden="true" tabindex="-1"></a>error <span class="op">=</span> rel_error((anc_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">2</span>:<span class="dv">4</span>] <span class="op">-</span> anc_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">0</span>:<span class="dv">2</span>]) <span class="op">*</span> torch.exp(torch.ones_like(anc_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">0</span>:<span class="dv">2</span>])), <span class="op">\</span></span>
<span id="cb38-34"><a href="#cb38-34" aria-hidden="true" tabindex="-1"></a>        (rcnn_proposal_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">2</span>:<span class="dv">4</span>] <span class="op">-</span> rcnn_proposal_list[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, :, <span class="dv">0</span>:<span class="dv">2</span>]))</span>
<span id="cb38-35"><a href="#cb38-35" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">if</span> error <span class="op">&lt;</span> <span class="fl">1e-6</span> <span class="cf">else</span> <span class="st">&quot;Fail&quot;</span></span>
<span id="cb38-36"><a href="#cb38-36" aria-hidden="true" tabindex="-1"></a>color <span class="op">=</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[92m&quot;</span> <span class="cf">if</span> result <span class="op">==</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">else</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[91m&quot;</span></span>
<span id="cb38-37"><a href="#cb38-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Relative Error: </span><span class="sc">{</span>error<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>color<span class="sc">}</span><span class="ss">Result: </span><span class="sc">{</span>result<span class="sc">}</span><span class="ch">\033</span><span class="ss">[0m&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>--------------------------------------------------------------------------------
Sanity check for YOLO.
1. Center moved by ~0.5 cell
Relative Error: 0.0
Result: Pass
2. w/h changed by e
Relative Error: 1.7541862007419695e-07
Result: Pass
--------------------------------------------------------------------------------
Sanity check for FasterRCNN.
1. x/y shifted by wh
Relative Error: 0.0
Result: Pass
2. w/h should changed by e
Relative Error: 1.7541862007419695e-07
Result: Pass
</code></pre>
</div>
</div>
<div class="cell markdown" id="gYzP-8tGo6bp">
<p>As an additional sanity check, we visualize an anchor (in red) and
the corresponding proposal (in green) that results from applying the
transform <span class="math inline">(0.5,0.5,0,0)</span>. The proposal
should shift down and to the right (when using the YOLO
formulation).</p>
</div>
<div class="cell code" data-execution_count="25"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="YQZH2b7fhS49" data-outputId="76318926-1a99-4b9e-c355-6b46881cc4b6">
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>yolo_offset_list <span class="op">=</span> torch.cat([torch.ones_like(anc_list[:, :, :, :, <span class="dv">0</span>:<span class="dv">2</span>]).fill_(<span class="fl">.5</span>), torch.zeros_like(anc_list[:, :, :, :, <span class="dv">2</span>:<span class="dv">4</span>])], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>yolo_proposal_list <span class="op">=</span> GenerateProposal(anc_list, yolo_offset_list, <span class="st">&#39;YOLO&#39;</span>)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> img, anc, prop <span class="kw">in</span> <span class="bu">zip</span>(img_list, coord_trans(anc_list[:, <span class="dv">0</span>:<span class="dv">1</span>, <span class="dv">3</span>:<span class="dv">4</span>, <span class="dv">3</span>:<span class="dv">4</span>, :], w_list, h_list), <span class="op">\</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>                          coord_trans(yolo_proposal_list[:, <span class="dv">0</span>:<span class="dv">1</span>, <span class="dv">3</span>:<span class="dv">4</span>, <span class="dv">3</span>:<span class="dv">4</span>, :], w_list, h_list)):</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>  data_visualizer(img, idx_to_class, anc.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>), prop.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>))</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/a3ac736af0215775a6cd3d59303f6da0cad8ec5c.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/2bf2aaf17e3a2f8f5cd58ef7e2ecba0bcbd427ea.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/cff2590156bedcb781b1a89e538a50280f9f133a.png" /></p>
</div>
</div>
<div class="cell markdown" id="WvR1zYcMpdYU">
<p>Next we visualize the effect of applying the transform <span
class="math inline">(0,0,1,1)</span> (with the YOLO formula) to the same
anchor box (in red). Now the proposal (in green) should have the same
center as the anchor, but the proposal should be larger.</p>
</div>
<div class="cell code" data-execution_count="26"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="3LtrWZCeyYVS" data-outputId="9f224d5f-88fc-4628-a72b-8acd87c9e38a">
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>yolo_offset_list <span class="op">=</span> torch.cat([torch.zeros_like(anc_list[:, :, :, :, <span class="dv">0</span>:<span class="dv">2</span>]), torch.ones_like(anc_list[:, :, :, :, <span class="dv">2</span>:<span class="dv">4</span>]).fill_(<span class="fl">1.</span>)], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>yolo_proposal_list <span class="op">=</span> GenerateProposal(anc_list, yolo_offset_list, <span class="st">&#39;YOLO&#39;</span>)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> img, anc, prop <span class="kw">in</span> <span class="bu">zip</span>(img_list, coord_trans(anc_list[:, <span class="dv">0</span>:<span class="dv">1</span>, <span class="dv">3</span>:<span class="dv">4</span>, <span class="dv">3</span>:<span class="dv">4</span>, :], w_list, h_list), <span class="op">\</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>                          coord_trans(yolo_proposal_list[:, <span class="dv">0</span>:<span class="dv">1</span>, <span class="dv">3</span>:<span class="dv">4</span>, <span class="dv">3</span>:<span class="dv">4</span>, :], w_list, h_list)):</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>  data_visualizer(img, idx_to_class, anc.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>), prop.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>))</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/d37c907e3b38e7f0e63a5e18dddef2ff7d0122ce.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/245d8fa284bcd3f77569ac15a98d63b0b168ed4e.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/c4d1a0ecd1d52b3495101665590f9eb26b238451.png" /></p>
</div>
</div>
<div class="cell markdown" id="d7WJQkOkp6E5">
<p>Next to sanity-check our implementation of the Faster R-CNN
transformation formulas, we visualize the effect of applying the
transform <span class="math inline">(1,1,0,0)</span> to the same anchor
(in red). The proposal (in green) should shift down and to the right by
an amount equal to the size of the anchor.</p>
</div>
<div class="cell code" data-execution_count="27"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="Fk6FWCcYh1hZ" data-outputId="79b923bd-e01c-4d99-8517-e33587c99a95">
<div class="sourceCode" id="cb42"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualization (shift by wh, Faster R-CNN)</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="co"># anchors in red and proposals in green</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>rcnn_offset_list <span class="op">=</span> torch.cat([torch.ones_like(anc_list[:, :, :, :, <span class="dv">0</span>:<span class="dv">2</span>]), torch.zeros_like(anc_list[:, :, :, :, <span class="dv">2</span>:<span class="dv">4</span>])], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>rcnn_proposal_list <span class="op">=</span> GenerateProposal(anc_list, rcnn_offset_list, <span class="st">&#39;FasterRCNN&#39;</span>)</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> img, anc, prop <span class="kw">in</span> <span class="bu">zip</span>(img_list, coord_trans(anc_list[:, <span class="dv">0</span>:<span class="dv">1</span>, <span class="dv">3</span>:<span class="dv">4</span>, <span class="dv">3</span>:<span class="dv">4</span>, :], w_list, h_list), <span class="op">\</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>                          coord_trans(rcnn_proposal_list[:, <span class="dv">0</span>:<span class="dv">1</span>, <span class="dv">3</span>:<span class="dv">4</span>, <span class="dv">3</span>:<span class="dv">4</span>, :], w_list, h_list)):</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>  data_visualizer(img, idx_to_class, anc.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>), prop.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>))</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/46a3f3bf95803505326758fdfec0c8eb95e202b7.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/9e62da4b4634dbddc1b3b7da44e75f4dbd9364b1.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/98c385af36d8d2fae48cd5ed0cffa627171c381b.png" /></p>
</div>
</div>
<div class="cell markdown" id="Ex-G6inJqOgv">
<p>We further check our implementation of the Faster R-CNN
transformation formula, and visualize the effect of applying the
transformation <span class="math inline">(0,0,1,1)</span> to the same
anchor. Now the proposal (in green) should have the same center as the
anchor (in red), but the proposal should be larger by a factor of <span
class="math inline"><em>e</em></span>.</p>
</div>
<div class="cell code" data-execution_count="28"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="rzDVtYz1hjVR" data-outputId="5a55993f-80de-4b4f-e529-91babc2fe037">
<div class="sourceCode" id="cb43"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualization (no shift and then scale by e, Faster R-CNN)</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="co"># anchors in red and proposals in green</span></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>rcnn_offset_list <span class="op">=</span> torch.cat([torch.zeros_like(anc_list[:, :, :, :, <span class="dv">0</span>:<span class="dv">2</span>]), torch.ones_like(anc_list[:, :, :, :, <span class="dv">2</span>:<span class="dv">4</span>]).fill_(<span class="dv">1</span>)], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>rcnn_proposal_list <span class="op">=</span> GenerateProposal(anc_list, rcnn_offset_list, <span class="st">&#39;FasterRCNN&#39;</span>)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> img, anc, prop <span class="kw">in</span> <span class="bu">zip</span>(img_list, coord_trans(anc_list[:, <span class="dv">0</span>:<span class="dv">1</span>, <span class="dv">3</span>:<span class="dv">4</span>, <span class="dv">3</span>:<span class="dv">4</span>, :], w_list, h_list), <span class="op">\</span></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>                          coord_trans(rcnn_proposal_list[:, <span class="dv">0</span>:<span class="dv">1</span>, <span class="dv">3</span>:<span class="dv">4</span>, <span class="dv">3</span>:<span class="dv">4</span>, :], w_list, h_list)):</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>  data_visualizer(img, idx_to_class, anc.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>), prop.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>))</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/d37c907e3b38e7f0e63a5e18dddef2ff7d0122ce.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/245d8fa284bcd3f77569ac15a98d63b0b168ed4e.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/c4d1a0ecd1d52b3495101665590f9eb26b238451.png" /></p>
</div>
</div>
<section id="prediction-networks" class="cell markdown"
id="_lBcOWGWtNka">
<h1>Prediction Networks</h1>
<p>This module outputs the prediction scores (see figure below). We have
provided the code to determine activated/negative anchors for you,
though you need to implement the IoU function for it to work. You will
also need to compute the loss function. The loss function consists of
three parts, confidence score regression, bounding box offsets
regression, and object classication.</p>
<p><img
src="https://miro.medium.com/max/1055/1*YG6heD55fEmZeUKRSlsqlA.png"
alt="pred_scores" /></p>
<p>Image credit: <a
href="https://towardsdatascience.com/yolov1-you-only-look-once-object-detection-e1f3ffec8a89">towardsdatascience</a>.
In this example, number of anchor shapes is <span
class="math inline"><em>A</em> = 2</span> while we have <span
class="math inline"><em>A</em> = 9</span>.</p>
</section>
<section id="intersection-over-union-iou" class="cell markdown"
id="Q8HqHqojtXhE">
<h2>Intersection Over Union (IoU)</h2>
<p>The definition of IoU and instructions on how to compute IoU can be
found in the lecture slides.</p>
</section>
<div class="cell code" data-execution_count="29" id="mJOBdG2ltgT5">
<div class="sourceCode" id="cb44"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> IoU(proposals, bboxes):</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute intersection over union between sets of bounding boxes.</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Inputs:</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="co">    - proposals: Tensor of shape (B, A, H&#39;, W&#39;, 4)</span></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="co">    - bboxes: Tensor of shape (B, N, 5) (the last column is the class)</span></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Outputs:</span></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a><span class="co">    - iou_mat: IoU matrix of shape (B, A*H&#39;*W&#39;, N)</span></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>    B, A, H, W, _ <span class="op">=</span> proposals.shape</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>    N <span class="op">=</span> bboxes.shape[<span class="dv">1</span>]</span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Reshape proposals to (B, R, 4) where R = A * H * W.</span></span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>    proposals <span class="op">=</span> proposals.view(B, <span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>)</span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Keep only the first 4 columns for bboxes (ignore class) -&gt; shape: (B, N, 4)</span></span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a>    bboxes <span class="op">=</span> bboxes[:, :, :<span class="dv">4</span>]</span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add dimensions for broadcasting: proposals -&gt; (B, R, 1, 4) and bboxes -&gt; (B, 1, N, 4)</span></span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a>    proposals <span class="op">=</span> proposals.unsqueeze(<span class="dv">2</span>)</span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a>    bboxes <span class="op">=</span> bboxes.unsqueeze(<span class="dv">1</span>)</span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute intersection coordinates using broadcasting.</span></span>
<span id="cb44-25"><a href="#cb44-25" aria-hidden="true" tabindex="-1"></a>    inter_top_left <span class="op">=</span> torch.maximum(proposals[..., :<span class="dv">2</span>], bboxes[..., :<span class="dv">2</span>])</span>
<span id="cb44-26"><a href="#cb44-26" aria-hidden="true" tabindex="-1"></a>    inter_bottom_right <span class="op">=</span> torch.minimum(proposals[..., <span class="dv">2</span>:], bboxes[..., <span class="dv">2</span>:])</span>
<span id="cb44-27"><a href="#cb44-27" aria-hidden="true" tabindex="-1"></a>    inter_wh <span class="op">=</span> (inter_bottom_right <span class="op">-</span> inter_top_left).clamp(<span class="bu">min</span><span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb44-28"><a href="#cb44-28" aria-hidden="true" tabindex="-1"></a>    inter_area <span class="op">=</span> inter_wh[..., <span class="dv">0</span>] <span class="op">*</span> inter_wh[..., <span class="dv">1</span>]</span>
<span id="cb44-29"><a href="#cb44-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-30"><a href="#cb44-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute areas for proposals and bboxes.</span></span>
<span id="cb44-31"><a href="#cb44-31" aria-hidden="true" tabindex="-1"></a>    proposals_wh <span class="op">=</span> proposals[..., <span class="dv">2</span>:] <span class="op">-</span> proposals[..., :<span class="dv">2</span>]</span>
<span id="cb44-32"><a href="#cb44-32" aria-hidden="true" tabindex="-1"></a>    proposals_area <span class="op">=</span> proposals_wh[..., <span class="dv">0</span>] <span class="op">*</span> proposals_wh[..., <span class="dv">1</span>]</span>
<span id="cb44-33"><a href="#cb44-33" aria-hidden="true" tabindex="-1"></a>    bboxes_wh <span class="op">=</span> bboxes[..., <span class="dv">2</span>:] <span class="op">-</span> bboxes[..., :<span class="dv">2</span>]</span>
<span id="cb44-34"><a href="#cb44-34" aria-hidden="true" tabindex="-1"></a>    bboxes_area <span class="op">=</span> bboxes_wh[..., <span class="dv">0</span>] <span class="op">*</span> bboxes_wh[..., <span class="dv">1</span>]</span>
<span id="cb44-35"><a href="#cb44-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-36"><a href="#cb44-36" aria-hidden="true" tabindex="-1"></a>    union_area <span class="op">=</span> proposals_area <span class="op">+</span> bboxes_area <span class="op">-</span> inter_area</span>
<span id="cb44-37"><a href="#cb44-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-38"><a href="#cb44-38" aria-hidden="true" tabindex="-1"></a>    iou_mat <span class="op">=</span> inter_area <span class="op">/</span> union_area</span>
<span id="cb44-39"><a href="#cb44-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> iou_mat</span></code></pre></div>
</div>
<div class="cell markdown" id="sY52QCKlTBsR">
<p>Run the following to check your implementation. You should see errors
on the order of 1e-6 or less.</p>
</div>
<div class="cell code" data-execution_count="30"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:0}"
id="IRXHJXFIbbDs" data-outputId="b96a620a-6433-43fb-efb2-2a5e570db579">
<div class="sourceCode" id="cb45"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># simple sanity check</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>width, height <span class="op">=</span> torch.tensor([<span class="dv">35</span>, <span class="dv">35</span>], <span class="op">**</span>to_float_cuda), torch.tensor([<span class="dv">40</span>, <span class="dv">40</span>], <span class="op">**</span>to_float_cuda)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>sample_bbox <span class="op">=</span> torch.tensor([[[<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">11</span>,<span class="dv">11</span>,<span class="dv">0</span>], [<span class="dv">20</span>,<span class="dv">20</span>,<span class="dv">30</span>,<span class="dv">30</span>,<span class="dv">0</span>]]], <span class="op">**</span>to_float_cuda)</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>sample_proposals <span class="op">=</span> torch.tensor([[[[[<span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">15</span>,<span class="dv">15</span>], [<span class="dv">27</span>,<span class="dv">27</span>,<span class="dv">37</span>,<span class="dv">37</span>]]]]], <span class="op">**</span>to_float_cuda)</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> IoU(sample_proposals, sample_bbox)</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a><span class="co"># check 1</span></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>expected_result <span class="op">=</span> torch.tensor([[[<span class="fl">0.21951219</span>, <span class="fl">0.00000000</span>],</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>                                 [<span class="fl">0.00000000</span>, <span class="fl">0.04712042</span>]]], <span class="op">**</span>to_float_cuda)</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>error <span class="op">=</span> rel_error(expected_result, result)</span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">if</span> error <span class="op">&lt;</span> <span class="fl">1e-6</span> <span class="cf">else</span> <span class="st">&quot;Fail&quot;</span></span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>color <span class="op">=</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[92m&quot;</span> <span class="cf">if</span> result <span class="op">==</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">else</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[91m&quot;</span></span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Simple IoU Matrix Relative Error: </span><span class="sc">{</span>error<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>color<span class="sc">}</span><span class="ss">Result: </span><span class="sc">{</span>result<span class="sc">}</span><span class="ch">\033</span><span class="ss">[0m&#39;</span>)</span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a><span class="co"># check 2</span></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a>iou_mat <span class="op">=</span> IoU(anc_list, resized_box_list)</span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a>expected_iou_mat <span class="op">=</span> torch.tensor([<span class="fl">0.11666405</span>, <span class="fl">0.15146968</span>, <span class="fl">0.02956639</span>], <span class="op">**</span>to_float_cuda)</span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a>error <span class="op">=</span> rel_error(expected_iou_mat, iou_mat[:, :, <span class="dv">0</span>].mean(<span class="dv">1</span>))</span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">if</span> error <span class="op">&lt;</span> <span class="fl">1e-6</span> <span class="cf">else</span> <span class="st">&quot;Fail&quot;</span></span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a>color <span class="op">=</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[92m&quot;</span> <span class="cf">if</span> result <span class="op">==</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">else</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[91m&quot;</span></span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;IoU Matrix Relative Error: </span><span class="sc">{</span>error<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>color<span class="sc">}</span><span class="ss">Result: </span><span class="sc">{</span>result<span class="sc">}</span><span class="ch">\033</span><span class="ss">[0m&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Simple IoU Matrix Relative Error: 0.0
Result: Pass
IoU Matrix Relative Error: 6.299873689386004e-08
Result: Pass
</code></pre>
</div>
</div>
<section id="activated-positive-and-negative-anchors"
class="cell markdown" id="WNSwO-wDwzoQ">
<h2>Activated (positive) and negative anchors</h2>
<p>During training we need to match the ground-truth boxes against the
anchors to determine the classification labels for the anchors -- which
anchors should be classified as containing an object and which should be
classified as background? We have written this part for you.</p>
<p>Read and digest the input/output definition carefully. You are highly
recommended to read through the code as later parts rely heavily on this
function.</p>
</section>
<div class="cell code" data-execution_count="31" id="z7uXbDraMkHR">
<div class="sourceCode" id="cb47"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ReferenceOnActivatedAnchors(anchors, bboxes, grid, iou_mat, pos_thresh<span class="op">=</span><span class="fl">0.7</span>, neg_thresh<span class="op">=</span><span class="fl">0.3</span>, method<span class="op">=</span><span class="st">&#39;FasterRCNN&#39;</span>):</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="co">  Determine the activated (positive) and negative anchors for model training.</span></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="co">  For YOLO - A grid cell is responsible for predicting a GT box if the center of</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a><span class="co">  the box falls into that cell.</span></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a><span class="co">  Implementation details: First compute manhattan distance between grid cell centers</span></span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a><span class="co">  (BxH’xW’) and GT box centers (BxN). This gives us a matrix of shape Bx(H&#39;xW&#39;)xN and</span></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a><span class="co">  perform torch.min(dim=1)[1] on it gives us the indexes indicating activated grids</span></span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a><span class="co">  responsible for GT boxes (convert to x and y). Among all the anchors associated with</span></span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a><span class="co">  the activate grids, the anchor with the largest IoU with the GT box is responsible to</span></span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a><span class="co">  predict (regress to) the GT box.</span></span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a><span class="co">  Note: One anchor might match multiple GT boxes.</span></span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a><span class="co">  For Faster R-CNN - Positive anchors are defined Any of the two</span></span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a><span class="co">  (i) the anchor/anchors with the highest IoU overlap with a GT box, or</span></span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a><span class="co">  (ii) an anchor that has an IoU overlap higher than 0.7 with any GT box.</span></span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a><span class="co">  Note: One anchor can match at most one GT box (the one with the largest IoU overlapping).</span></span>
<span id="cb47-19"><a href="#cb47-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-20"><a href="#cb47-20" aria-hidden="true" tabindex="-1"></a><span class="co">  For both - We assign a negative label to a anchor if its IoU ratio is lower than</span></span>
<span id="cb47-21"><a href="#cb47-21" aria-hidden="true" tabindex="-1"></a><span class="co">  a threshold value for all GT boxes. Anchors that are neither positive nor negative</span></span>
<span id="cb47-22"><a href="#cb47-22" aria-hidden="true" tabindex="-1"></a><span class="co">  do not contribute to the training objective.</span></span>
<span id="cb47-23"><a href="#cb47-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-24"><a href="#cb47-24" aria-hidden="true" tabindex="-1"></a><span class="co">  Main steps include:</span></span>
<span id="cb47-25"><a href="#cb47-25" aria-hidden="true" tabindex="-1"></a><span class="co">  i) Decide activated and negative anchors based on the IoU matrix.</span></span>
<span id="cb47-26"><a href="#cb47-26" aria-hidden="true" tabindex="-1"></a><span class="co">  ii) Compute GT confidence score/offsets/object class on the positive proposals.</span></span>
<span id="cb47-27"><a href="#cb47-27" aria-hidden="true" tabindex="-1"></a><span class="co">  iii) Compute GT confidence score on the negative proposals.</span></span>
<span id="cb47-28"><a href="#cb47-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-29"><a href="#cb47-29" aria-hidden="true" tabindex="-1"></a><span class="co">  Inputs:</span></span>
<span id="cb47-30"><a href="#cb47-30" aria-hidden="true" tabindex="-1"></a><span class="co">  - anchors: Anchor boxes, of shape BxAxH’xW’x4</span></span>
<span id="cb47-31"><a href="#cb47-31" aria-hidden="true" tabindex="-1"></a><span class="co">  - bboxes: GT boxes of shape BxNx5, where N is the number of PADDED GT boxes,</span></span>
<span id="cb47-32"><a href="#cb47-32" aria-hidden="true" tabindex="-1"></a><span class="co">            5 indicates (x_{lr}^{gt}, y_{lr}^{gt}, x_{rb}^{gt}, y_{rb}^{gt}) and class index</span></span>
<span id="cb47-33"><a href="#cb47-33" aria-hidden="true" tabindex="-1"></a><span class="co">  - grid (float): A cell grid of shape BxH&#39;xW&#39;x2 where 2 indicate the (x, y) coord</span></span>
<span id="cb47-34"><a href="#cb47-34" aria-hidden="true" tabindex="-1"></a><span class="co">  - iou_mat: IoU matrix of shape Bx(AxH’xW’)xN</span></span>
<span id="cb47-35"><a href="#cb47-35" aria-hidden="true" tabindex="-1"></a><span class="co">  - pos_thresh: Positive threshold value</span></span>
<span id="cb47-36"><a href="#cb47-36" aria-hidden="true" tabindex="-1"></a><span class="co">  - neg_thresh: Negative threshold value</span></span>
<span id="cb47-37"><a href="#cb47-37" aria-hidden="true" tabindex="-1"></a><span class="co">  - method: Switch between &#39;YOLO&#39; mode and &#39;FasterRCNN&#39; mode</span></span>
<span id="cb47-38"><a href="#cb47-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-39"><a href="#cb47-39" aria-hidden="true" tabindex="-1"></a><span class="co">  Outputs:</span></span>
<span id="cb47-40"><a href="#cb47-40" aria-hidden="true" tabindex="-1"></a><span class="co">  - activated_anc_ind: Index on activated anchors, of shape M, where M indicates the</span></span>
<span id="cb47-41"><a href="#cb47-41" aria-hidden="true" tabindex="-1"></a><span class="co">                       number of activated anchors</span></span>
<span id="cb47-42"><a href="#cb47-42" aria-hidden="true" tabindex="-1"></a><span class="co">  - negative_anc_ind: Index on negative anchors, of shape M</span></span>
<span id="cb47-43"><a href="#cb47-43" aria-hidden="true" tabindex="-1"></a><span class="co">  - GT_conf_scores: GT IoU confidence scores on activated anchors, of shape M</span></span>
<span id="cb47-44"><a href="#cb47-44" aria-hidden="true" tabindex="-1"></a><span class="co">  - GT_offsets: GT offsets on activated anchors, of shape Mx4. They are denoted as</span></span>
<span id="cb47-45"><a href="#cb47-45" aria-hidden="true" tabindex="-1"></a><span class="co">                \hat{t^x}, \hat{t^y}, \hat{t^w}, \hat{t^h} in the formulation earlier.</span></span>
<span id="cb47-46"><a href="#cb47-46" aria-hidden="true" tabindex="-1"></a><span class="co">  - GT_class: GT class category on activated anchors, essentially indexed from bboxes[:, :, 4],</span></span>
<span id="cb47-47"><a href="#cb47-47" aria-hidden="true" tabindex="-1"></a><span class="co">              of shape M</span></span>
<span id="cb47-48"><a href="#cb47-48" aria-hidden="true" tabindex="-1"></a><span class="co">  - activated_anc_coord: Coordinates on activated anchors (mainly for visualization purposes)</span></span>
<span id="cb47-49"><a href="#cb47-49" aria-hidden="true" tabindex="-1"></a><span class="co">  - negative_anc_coord: Coordinates on negative anchors (mainly for visualization purposes)</span></span>
<span id="cb47-50"><a href="#cb47-50" aria-hidden="true" tabindex="-1"></a><span class="co">  &quot;&quot;&quot;</span></span>
<span id="cb47-51"><a href="#cb47-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-52"><a href="#cb47-52" aria-hidden="true" tabindex="-1"></a>  <span class="cf">assert</span>(method <span class="kw">in</span> [<span class="st">&#39;FasterRCNN&#39;</span>, <span class="st">&#39;YOLO&#39;</span>])</span>
<span id="cb47-53"><a href="#cb47-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-54"><a href="#cb47-54" aria-hidden="true" tabindex="-1"></a>  B, A, h_amap, w_amap, _ <span class="op">=</span> anchors.shape</span>
<span id="cb47-55"><a href="#cb47-55" aria-hidden="true" tabindex="-1"></a>  N <span class="op">=</span> bboxes.shape[<span class="dv">1</span>]</span>
<span id="cb47-56"><a href="#cb47-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-57"><a href="#cb47-57" aria-hidden="true" tabindex="-1"></a>  <span class="co"># activated/positive anchors</span></span>
<span id="cb47-58"><a href="#cb47-58" aria-hidden="true" tabindex="-1"></a>  max_iou_per_anc, max_iou_per_anc_ind <span class="op">=</span> iou_mat.<span class="bu">max</span>(dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb47-59"><a href="#cb47-59" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> method <span class="op">==</span> <span class="st">&#39;FasterRCNN&#39;</span>:</span>
<span id="cb47-60"><a href="#cb47-60" aria-hidden="true" tabindex="-1"></a>    max_iou_per_box <span class="op">=</span> iou_mat.<span class="bu">max</span>(dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>]</span>
<span id="cb47-61"><a href="#cb47-61" aria-hidden="true" tabindex="-1"></a>    activated_anc_mask <span class="op">=</span> (iou_mat <span class="op">==</span> max_iou_per_box) <span class="op">&amp;</span> (max_iou_per_box <span class="op">&gt;</span> <span class="dv">0</span>)</span>
<span id="cb47-62"><a href="#cb47-62" aria-hidden="true" tabindex="-1"></a>    activated_anc_mask <span class="op">|=</span> (iou_mat <span class="op">&gt;</span> pos_thresh) <span class="co"># using the pos_thresh condition as well</span></span>
<span id="cb47-63"><a href="#cb47-63" aria-hidden="true" tabindex="-1"></a>    <span class="co"># if an anchor matches multiple GT boxes, choose the box with the largest iou</span></span>
<span id="cb47-64"><a href="#cb47-64" aria-hidden="true" tabindex="-1"></a>    activated_anc_mask <span class="op">=</span> activated_anc_mask.<span class="bu">max</span>(dim<span class="op">=-</span><span class="dv">1</span>)[<span class="dv">0</span>] <span class="co"># Bx(AxH’xW’)</span></span>
<span id="cb47-65"><a href="#cb47-65" aria-hidden="true" tabindex="-1"></a>    activated_anc_ind <span class="op">=</span> torch.nonzero(activated_anc_mask.view(<span class="op">-</span><span class="dv">1</span>)).squeeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb47-66"><a href="#cb47-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-67"><a href="#cb47-67" aria-hidden="true" tabindex="-1"></a>    <span class="co"># GT conf scores</span></span>
<span id="cb47-68"><a href="#cb47-68" aria-hidden="true" tabindex="-1"></a>    GT_conf_scores <span class="op">=</span> max_iou_per_anc[activated_anc_mask] <span class="co"># M</span></span>
<span id="cb47-69"><a href="#cb47-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-70"><a href="#cb47-70" aria-hidden="true" tabindex="-1"></a>    <span class="co"># GT class</span></span>
<span id="cb47-71"><a href="#cb47-71" aria-hidden="true" tabindex="-1"></a>    box_cls <span class="op">=</span> bboxes[:, :, <span class="dv">4</span>].view(B, <span class="dv">1</span>, N).expand((B, A<span class="op">*</span>h_amap<span class="op">*</span>w_amap, N))</span>
<span id="cb47-72"><a href="#cb47-72" aria-hidden="true" tabindex="-1"></a>    GT_class <span class="op">=</span> torch.gather(box_cls, <span class="op">-</span><span class="dv">1</span>, max_iou_per_anc_ind.unsqueeze(<span class="op">-</span><span class="dv">1</span>)).squeeze(<span class="op">-</span><span class="dv">1</span>) <span class="co"># M</span></span>
<span id="cb47-73"><a href="#cb47-73" aria-hidden="true" tabindex="-1"></a>    GT_class <span class="op">=</span> GT_class[activated_anc_mask].<span class="bu">long</span>()</span>
<span id="cb47-74"><a href="#cb47-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-75"><a href="#cb47-75" aria-hidden="true" tabindex="-1"></a>    bboxes_expand <span class="op">=</span> bboxes[:, :, :<span class="dv">4</span>].view(B, <span class="dv">1</span>, N, <span class="dv">4</span>).expand((B, A<span class="op">*</span>h_amap<span class="op">*</span>w_amap, N, <span class="dv">4</span>))</span>
<span id="cb47-76"><a href="#cb47-76" aria-hidden="true" tabindex="-1"></a>    bboxes <span class="op">=</span> torch.gather(bboxes_expand, <span class="op">-</span><span class="dv">2</span>, max_iou_per_anc_ind.unsqueeze(<span class="op">-</span><span class="dv">1</span>) <span class="op">\</span></span>
<span id="cb47-77"><a href="#cb47-77" aria-hidden="true" tabindex="-1"></a>      .unsqueeze(<span class="op">-</span><span class="dv">1</span>).expand(B, A<span class="op">*</span>h_amap<span class="op">*</span>w_amap, <span class="dv">1</span>, <span class="dv">4</span>)).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>)</span>
<span id="cb47-78"><a href="#cb47-78" aria-hidden="true" tabindex="-1"></a>    bboxes <span class="op">=</span> bboxes[activated_anc_ind]</span>
<span id="cb47-79"><a href="#cb47-79" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span>:</span>
<span id="cb47-80"><a href="#cb47-80" aria-hidden="true" tabindex="-1"></a>    bbox_mask <span class="op">=</span> (bboxes[:, :, <span class="dv">0</span>] <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>) <span class="co"># BxN, indicate invalid boxes</span></span>
<span id="cb47-81"><a href="#cb47-81" aria-hidden="true" tabindex="-1"></a>    bbox_centers <span class="op">=</span> (bboxes[:, :, <span class="dv">2</span>:<span class="dv">4</span>] <span class="op">-</span> bboxes[:, :, :<span class="dv">2</span>]) <span class="op">/</span> <span class="fl">2.</span> <span class="op">+</span> bboxes[:, :, :<span class="dv">2</span>] <span class="co"># BxNx2</span></span>
<span id="cb47-82"><a href="#cb47-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-83"><a href="#cb47-83" aria-hidden="true" tabindex="-1"></a>    mah_dist <span class="op">=</span> torch.<span class="bu">abs</span>(grid.view(B, <span class="op">-</span><span class="dv">1</span>, <span class="dv">2</span>).unsqueeze(<span class="dv">2</span>) <span class="op">-</span> bbox_centers.unsqueeze(<span class="dv">1</span>)).<span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>) <span class="co"># Bx(H&#39;xW&#39;)xN</span></span>
<span id="cb47-84"><a href="#cb47-84" aria-hidden="true" tabindex="-1"></a>    min_mah_dist <span class="op">=</span> mah_dist.<span class="bu">min</span>(dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>] <span class="co"># Bx1xN</span></span>
<span id="cb47-85"><a href="#cb47-85" aria-hidden="true" tabindex="-1"></a>    grid_mask <span class="op">=</span> (mah_dist <span class="op">==</span> min_mah_dist).unsqueeze(<span class="dv">1</span>) <span class="co"># Bx1x(H&#39;xW&#39;)xN</span></span>
<span id="cb47-86"><a href="#cb47-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-87"><a href="#cb47-87" aria-hidden="true" tabindex="-1"></a>    reshaped_iou_mat <span class="op">=</span> iou_mat.view(B, A, <span class="op">-</span><span class="dv">1</span>, N)</span>
<span id="cb47-88"><a href="#cb47-88" aria-hidden="true" tabindex="-1"></a>    anc_with_largest_iou <span class="op">=</span> reshaped_iou_mat.<span class="bu">max</span>(dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>] <span class="co"># Bx1x(H’xW’)xN</span></span>
<span id="cb47-89"><a href="#cb47-89" aria-hidden="true" tabindex="-1"></a>    anc_mask <span class="op">=</span> (anc_with_largest_iou <span class="op">==</span> reshaped_iou_mat) <span class="co"># BxAx(H’xW’)xN</span></span>
<span id="cb47-90"><a href="#cb47-90" aria-hidden="true" tabindex="-1"></a>    activated_anc_mask <span class="op">=</span> (grid_mask <span class="op">&amp;</span> anc_mask).view(B, <span class="op">-</span><span class="dv">1</span>, N)</span>
<span id="cb47-91"><a href="#cb47-91" aria-hidden="true" tabindex="-1"></a>    activated_anc_mask <span class="op">&amp;=</span> bbox_mask.unsqueeze(<span class="dv">1</span>)</span>
<span id="cb47-92"><a href="#cb47-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-93"><a href="#cb47-93" aria-hidden="true" tabindex="-1"></a>    <span class="co"># one anchor could match multiple GT boxes</span></span>
<span id="cb47-94"><a href="#cb47-94" aria-hidden="true" tabindex="-1"></a>    activated_anc_ind <span class="op">=</span> torch.nonzero(activated_anc_mask.view(<span class="op">-</span><span class="dv">1</span>)).squeeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb47-95"><a href="#cb47-95" aria-hidden="true" tabindex="-1"></a>    GT_conf_scores <span class="op">=</span> iou_mat.view(<span class="op">-</span><span class="dv">1</span>)[activated_anc_ind]</span>
<span id="cb47-96"><a href="#cb47-96" aria-hidden="true" tabindex="-1"></a>    bboxes <span class="op">=</span> bboxes.view(B, <span class="dv">1</span>, N, <span class="dv">5</span>).repeat(<span class="dv">1</span>, A<span class="op">*</span>h_amap<span class="op">*</span>w_amap, <span class="dv">1</span>, <span class="dv">1</span>).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>)[activated_anc_ind]</span>
<span id="cb47-97"><a href="#cb47-97" aria-hidden="true" tabindex="-1"></a>    GT_class <span class="op">=</span> bboxes[:, <span class="dv">4</span>].<span class="bu">long</span>()</span>
<span id="cb47-98"><a href="#cb47-98" aria-hidden="true" tabindex="-1"></a>    bboxes <span class="op">=</span> bboxes[:, :<span class="dv">4</span>]</span>
<span id="cb47-99"><a href="#cb47-99" aria-hidden="true" tabindex="-1"></a>    activated_anc_ind <span class="op">=</span> (activated_anc_ind <span class="op">/</span> activated_anc_mask.shape[<span class="op">-</span><span class="dv">1</span>]).<span class="bu">long</span>()</span>
<span id="cb47-100"><a href="#cb47-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-101"><a href="#cb47-101" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">&#39;number of pos proposals: &#39;</span>, activated_anc_ind.shape[<span class="dv">0</span>])</span>
<span id="cb47-102"><a href="#cb47-102" aria-hidden="true" tabindex="-1"></a>  activated_anc_coord <span class="op">=</span> anchors.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>)[activated_anc_ind]</span>
<span id="cb47-103"><a href="#cb47-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-104"><a href="#cb47-104" aria-hidden="true" tabindex="-1"></a>  <span class="co"># GT offsets</span></span>
<span id="cb47-105"><a href="#cb47-105" aria-hidden="true" tabindex="-1"></a>  <span class="co"># bbox and anchor coordinates are x_tl, y_tl, x_br, y_br</span></span>
<span id="cb47-106"><a href="#cb47-106" aria-hidden="true" tabindex="-1"></a>  <span class="co"># offsets are t_x, t_y, t_w, t_h</span></span>
<span id="cb47-107"><a href="#cb47-107" aria-hidden="true" tabindex="-1"></a>  wh_offsets <span class="op">=</span> torch.log((bboxes[:, <span class="dv">2</span>:<span class="dv">4</span>] <span class="op">-</span> bboxes[:, :<span class="dv">2</span>]) <span class="op">\</span></span>
<span id="cb47-108"><a href="#cb47-108" aria-hidden="true" tabindex="-1"></a>    <span class="op">/</span> (activated_anc_coord[:, <span class="dv">2</span>:<span class="dv">4</span>] <span class="op">-</span> activated_anc_coord[:, :<span class="dv">2</span>]))</span>
<span id="cb47-109"><a href="#cb47-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-110"><a href="#cb47-110" aria-hidden="true" tabindex="-1"></a>  xy_offsets <span class="op">=</span> (bboxes[:, :<span class="dv">2</span>] <span class="op">+</span> bboxes[:, <span class="dv">2</span>:<span class="dv">4</span>] <span class="op">-</span> <span class="op">\</span></span>
<span id="cb47-111"><a href="#cb47-111" aria-hidden="true" tabindex="-1"></a>    activated_anc_coord[:, :<span class="dv">2</span>] <span class="op">-</span> activated_anc_coord[:, <span class="dv">2</span>:<span class="dv">4</span>]) <span class="op">/</span> <span class="fl">2.</span></span>
<span id="cb47-112"><a href="#cb47-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-113"><a href="#cb47-113" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> method <span class="op">==</span> <span class="st">&quot;FasterRCNN&quot;</span>:</span>
<span id="cb47-114"><a href="#cb47-114" aria-hidden="true" tabindex="-1"></a>    xy_offsets <span class="op">/=</span> (activated_anc_coord[:, <span class="dv">2</span>:<span class="dv">4</span>] <span class="op">-</span> activated_anc_coord[:, :<span class="dv">2</span>])</span>
<span id="cb47-115"><a href="#cb47-115" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span>:</span>
<span id="cb47-116"><a href="#cb47-116" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> torch.<span class="bu">max</span>(torch.<span class="bu">abs</span>(xy_offsets)) <span class="op">&lt;=</span> <span class="fl">0.5</span>, <span class="op">\</span></span>
<span id="cb47-117"><a href="#cb47-117" aria-hidden="true" tabindex="-1"></a>      <span class="st">&quot;x and y offsets should be between -0.5 and 0.5! Got </span><span class="sc">{}</span><span class="st">&quot;</span>.<span class="bu">format</span>( <span class="op">\</span></span>
<span id="cb47-118"><a href="#cb47-118" aria-hidden="true" tabindex="-1"></a>      torch.<span class="bu">max</span>(torch.<span class="bu">abs</span>(xy_offsets)))</span>
<span id="cb47-119"><a href="#cb47-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-120"><a href="#cb47-120" aria-hidden="true" tabindex="-1"></a>  GT_offsets <span class="op">=</span> torch.cat((xy_offsets, wh_offsets), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb47-121"><a href="#cb47-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-122"><a href="#cb47-122" aria-hidden="true" tabindex="-1"></a>  <span class="co"># negative anchors</span></span>
<span id="cb47-123"><a href="#cb47-123" aria-hidden="true" tabindex="-1"></a>  negative_anc_mask <span class="op">=</span> (max_iou_per_anc <span class="op">&lt;</span> neg_thresh) <span class="co"># Bx(AxH’xW’)</span></span>
<span id="cb47-124"><a href="#cb47-124" aria-hidden="true" tabindex="-1"></a>  negative_anc_ind <span class="op">=</span> torch.nonzero(negative_anc_mask.view(<span class="op">-</span><span class="dv">1</span>)).squeeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb47-125"><a href="#cb47-125" aria-hidden="true" tabindex="-1"></a>  negative_anc_ind <span class="op">=</span> negative_anc_ind[torch.randint(<span class="dv">0</span>, negative_anc_ind.shape[<span class="dv">0</span>], (activated_anc_ind.shape[<span class="dv">0</span>],))]</span>
<span id="cb47-126"><a href="#cb47-126" aria-hidden="true" tabindex="-1"></a>  negative_anc_coord <span class="op">=</span> anchors.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>)[negative_anc_ind.view(<span class="op">-</span><span class="dv">1</span>)]</span>
<span id="cb47-127"><a href="#cb47-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-128"><a href="#cb47-128" aria-hidden="true" tabindex="-1"></a>  <span class="co"># activated_anc_coord and negative_anc_coord are mainly for visualization purposes</span></span>
<span id="cb47-129"><a href="#cb47-129" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> activated_anc_ind, negative_anc_ind, GT_conf_scores, GT_offsets, GT_class, <span class="op">\</span></span>
<span id="cb47-130"><a href="#cb47-130" aria-hidden="true" tabindex="-1"></a>         activated_anc_coord, negative_anc_coord</span></code></pre></div>
</div>
<div class="cell markdown" id="6OHpu5SMXrio">
<p>Run the following to check your implementation. You should see errors
on the order of 1e-6 or less.</p>
</div>
<div class="cell code" data-execution_count="32"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:0}"
id="fK_USCuaXSzh" data-outputId="a3f48948-31ef-4fb3-c0a2-2fd9bd7339d7">
<div class="sourceCode" id="cb48"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sanity check on YOLO (the one on Faster R-CNN is in A5-2)</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>activated_anc_ind, negative_anc_ind, GT_conf_scores, GT_offsets, GT_class, <span class="op">\</span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>  activated_anc_coord, negative_anc_coord <span class="op">=</span> ReferenceOnActivatedAnchors(anc_list, resized_box_list, grid_list, iou_mat, neg_thresh<span class="op">=</span><span class="fl">0.2</span>, method<span class="op">=</span><span class="st">&#39;YOLO&#39;</span>)</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>expected_GT_conf_scores <span class="op">=</span> torch.tensor([<span class="fl">0.74538743</span>, <span class="fl">0.72793430</span>, <span class="fl">0.76044953</span>, <span class="fl">0.37116671</span>], <span class="op">**</span>to_float_cuda)</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>expected_GT_offsets <span class="op">=</span> torch.tensor([[ <span class="fl">0.04900002</span>,  <span class="fl">0.35735703</span>, <span class="op">-</span><span class="fl">0.09431065</span>,  <span class="fl">0.19244696</span>],</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>                                    [<span class="op">-</span><span class="fl">0.14700007</span>,  <span class="fl">0.37299442</span>, <span class="op">-</span><span class="fl">0.00250307</span>,  <span class="fl">0.25213102</span>],</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>                                    [<span class="op">-</span><span class="fl">0.40600014</span>,  <span class="fl">0.09625626</span>,  <span class="fl">0.20863886</span>, <span class="op">-</span><span class="fl">0.07974572</span>],</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>                                    [ <span class="fl">0.15399981</span>, <span class="op">-</span><span class="fl">0.42933345</span>, <span class="op">-</span><span class="fl">0.03459148</span>, <span class="op">-</span><span class="fl">0.86750042</span>]], <span class="op">**</span>to_float_cuda)</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>expected_GT_class <span class="op">=</span> torch.tensor([ <span class="dv">6</span>,  <span class="dv">7</span>, <span class="dv">19</span>,  <span class="dv">6</span>], <span class="op">**</span>to_long_cuda)</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>error <span class="op">=</span> rel_error(GT_conf_scores, expected_GT_conf_scores)</span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">if</span> error <span class="op">&lt;</span> <span class="fl">1e-6</span> <span class="cf">else</span> <span class="st">&quot;Fail&quot;</span></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>color <span class="op">=</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[92m&quot;</span> <span class="cf">if</span> result <span class="op">==</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">else</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[91m&quot;</span></span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Confidence Scores Relative Error: </span><span class="sc">{</span>error<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>color<span class="sc">}</span><span class="ss">Result: </span><span class="sc">{</span>result<span class="sc">}</span><span class="ch">\033</span><span class="ss">[0m&#39;</span>)</span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a>error <span class="op">=</span> rel_error(GT_offsets, expected_GT_offsets)</span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">if</span> error <span class="op">&lt;</span> <span class="fl">1e-6</span> <span class="cf">else</span> <span class="st">&quot;Fail&quot;</span></span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a>color <span class="op">=</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[92m&quot;</span> <span class="cf">if</span> result <span class="op">==</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">else</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[91m&quot;</span></span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Offsets Relative Error: </span><span class="sc">{</span>error<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>color<span class="sc">}</span><span class="ss">Result: </span><span class="sc">{</span>result<span class="sc">}</span><span class="ch">\033</span><span class="ss">[0m&#39;</span>)</span>
<span id="cb48-21"><a href="#cb48-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-22"><a href="#cb48-22" aria-hidden="true" tabindex="-1"></a>error <span class="op">=</span> rel_error(GT_class, expected_GT_class)</span>
<span id="cb48-23"><a href="#cb48-23" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">if</span> error <span class="op">&lt;</span> <span class="fl">1e-6</span> <span class="cf">else</span> <span class="st">&quot;Fail&quot;</span></span>
<span id="cb48-24"><a href="#cb48-24" aria-hidden="true" tabindex="-1"></a>color <span class="op">=</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[92m&quot;</span> <span class="cf">if</span> result <span class="op">==</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">else</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[91m&quot;</span></span>
<span id="cb48-25"><a href="#cb48-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Class Probabilities Relative Error: </span><span class="sc">{</span>error<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>color<span class="sc">}</span><span class="ss">Result: </span><span class="sc">{</span>result<span class="sc">}</span><span class="ch">\033</span><span class="ss">[0m&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>number of pos proposals:  4
Confidence Scores Relative Error: 0.0
Result: Pass
Offsets Relative Error: 7.441442448907765e-07
Result: Pass
Class Probabilities Relative Error: 0.0
Result: Pass
</code></pre>
</div>
</div>
<div class="cell markdown" id="YsPZw2mTutWP">
<p>We can sanity check this function by visualizing ground-truth boxes
(in red) along with positive / negative anchors (in green).</p>
</div>
<div class="cell code" data-execution_count="33"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1955}"
id="2TuJNoCvUuqc" data-outputId="7fb1585b-a715-429a-e4fb-b4e3ee73f2ad">
<div class="sourceCode" id="cb50"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize activated and negative anchors</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>anc_per_img <span class="op">=</span> torch.prod(torch.tensor(anc_list.shape[<span class="dv">1</span>:<span class="op">-</span><span class="dv">1</span>]))</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;*&#39;</span><span class="op">*</span><span class="dv">80</span>)</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Activated (positive) anchors:&#39;</span>)</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> img, bbox, idx <span class="kw">in</span> <span class="bu">zip</span>(img_list, box_list, torch.arange(box_list.shape[<span class="dv">0</span>])):</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>  anc_ind_in_img <span class="op">=</span> (activated_anc_ind <span class="op">&gt;=</span> idx <span class="op">*</span> anc_per_img) <span class="op">&amp;</span> (activated_anc_ind <span class="op">&lt;</span> (idx<span class="op">+</span><span class="dv">1</span>) <span class="op">*</span> anc_per_img)</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">&#39;</span><span class="sc">{}</span><span class="st"> activated anchors!&#39;</span>.<span class="bu">format</span>(torch.<span class="bu">sum</span>(anc_ind_in_img)))</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>  data_visualizer(img, idx_to_class, bbox[:, :<span class="dv">4</span>], coord_trans(activated_anc_coord[anc_ind_in_img], w_list[idx], h_list[idx]))</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;*&#39;</span><span class="op">*</span><span class="dv">80</span>)</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Negative anchors:&#39;</span>)</span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> img, bbox, idx <span class="kw">in</span> <span class="bu">zip</span>(img_list, box_list, torch.arange(box_list.shape[<span class="dv">0</span>])):</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>  anc_ind_in_img <span class="op">=</span> (negative_anc_ind <span class="op">&gt;=</span> idx <span class="op">*</span> anc_per_img) <span class="op">&amp;</span> (negative_anc_ind <span class="op">&lt;</span> (idx<span class="op">+</span><span class="dv">1</span>) <span class="op">*</span> anc_per_img)</span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">&#39;</span><span class="sc">{}</span><span class="st"> negative anchors!&#39;</span>.<span class="bu">format</span>(torch.<span class="bu">sum</span>(anc_ind_in_img)))</span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a>  data_visualizer(img, idx_to_class, bbox[:, :<span class="dv">4</span>], coord_trans(negative_anc_coord[anc_ind_in_img], w_list[idx], h_list[idx]))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>********************************************************************************
Activated (positive) anchors:
1 activated anchors!
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/1c6c5e7ac1ae8e53cbbc93c742deb4d27d316c5c.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>2 activated anchors!
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/c7ba4d053a42d4f30617736b199218fec8b4600f.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>1 activated anchors!
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/362f3008564eb3cc17a8530f86961a147dc64d8a.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>********************************************************************************
Negative anchors:
1 negative anchors!
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/b28b2dfebf5f7f729cb4446c29a84a12d9ac5215.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>2 negative anchors!
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/d203f21ba43974e8551454079fd18241e164a1b9.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>1 negative anchors!
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/a797cec00629e4829558f124ae303f4be8c03af1.png" /></p>
</div>
</div>
<section id="prediction-network" class="cell markdown"
id="XW_Zek3_dgfF">
<h2>Prediction Network</h2>
<p>The prediction network inputs the features from the backbone network,
and outputs the classification scores and transformations for each
anchor.</p>
<p>For each position in the 7x7 grid of features from the backbone, the
prediction network outputs <code>C</code> numbers to be interpreted as
classification scores over the <code>C</code> object categories for the
anchors at that position.</p>
<p>In addition, for each of the <code>A</code> anchors at each position,
the prediction network outputs a transformation (4 numbers, to convert
the anchor box into a region proposal) and a confidence score (where
large positive values indicate high probability that the anchor contains
an object, and large negative values indicate low probability that the
anchor contains an object).</p>
<p>Collecting all of these outputs, we see that for each position in the
7x7 grid of features we need to output a total of <code>5A+C</code>
numbers, so the prediction network receives an input tensor of shape
<code>(B, 1280, 7, 7)</code> and produces an output tensor of shape
<code>(B, 5A+C, 7, 7)</code>. We can achieve this with two
<code>1x1</code> convolution layers operating on the input tensor, where
the number of filters in the second layer is <code>5A+C</code>.</p>
<p>During training, we do not apply the loss on the full set of anchor
boxes for the image; instead we designate a subset of anchors as
positive and negative by matching them with ground-truth boxes as in the
function above. The Prediction network is also responsible for picking
out the outputs corresponding to the positive and negative anchors.</p>
</section>
<div class="cell code" data-execution_count="34" id="vMkvupmCdnYH">
<div class="sourceCode" id="cb57"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PredictionNetwork(nn.Module):</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_dim, hidden_dim<span class="op">=</span><span class="dv">128</span>, num_anchors<span class="op">=</span><span class="dv">9</span>, num_classes<span class="op">=</span><span class="dv">20</span>, drop_ratio<span class="op">=</span><span class="fl">0.3</span>):</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span>(num_classes <span class="op">!=</span> <span class="dv">0</span> <span class="kw">and</span> num_anchors <span class="op">!=</span> <span class="dv">0</span>)</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.num_classes <span class="op">=</span> num_classes</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.num_anchors <span class="op">=</span> num_anchors</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">##############################################################################</span></span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">TODO</span><span class="co">: Set up a network that will predict outputs for all anchors. This     #</span></span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># network should have a 1x1 convolution with hidden_dim filters, followed    #</span></span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># by a Dropout layer with p=drop_ratio, a Leaky ReLU nonlinearity, and       #</span></span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># finally another 1x1 convolution layer to predict all outputs. You can      #</span></span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># use an nn.Sequential for this network, and store it in a member variable.  #</span></span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># HINT: The output should be of shape (B, 5*A+C, 7, 7), where                #</span></span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># A=self.num_anchors and C=self.num_classes.                                 #</span></span>
<span id="cb57-17"><a href="#cb57-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">##############################################################################</span></span>
<span id="cb57-18"><a href="#cb57-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Replace &quot;pass&quot; statement with your code</span></span>
<span id="cb57-19"><a href="#cb57-19" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.network <span class="op">=</span> nn.Sequential(</span>
<span id="cb57-20"><a href="#cb57-20" aria-hidden="true" tabindex="-1"></a>        nn.Conv2d(in_dim, hidden_dim, kernel_size<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb57-21"><a href="#cb57-21" aria-hidden="true" tabindex="-1"></a>        nn.Dropout(p<span class="op">=</span>drop_ratio),</span>
<span id="cb57-22"><a href="#cb57-22" aria-hidden="true" tabindex="-1"></a>        nn.LeakyReLU(),</span>
<span id="cb57-23"><a href="#cb57-23" aria-hidden="true" tabindex="-1"></a>        nn.Conv2d(hidden_dim, <span class="dv">5</span> <span class="op">*</span> num_anchors <span class="op">+</span> num_classes, kernel_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb57-24"><a href="#cb57-24" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb57-25"><a href="#cb57-25" aria-hidden="true" tabindex="-1"></a>    <span class="co">##############################################################################</span></span>
<span id="cb57-26"><a href="#cb57-26" aria-hidden="true" tabindex="-1"></a>    <span class="co">#                               </span><span class="re">END</span><span class="co"> OF YOUR CODE                             #</span></span>
<span id="cb57-27"><a href="#cb57-27" aria-hidden="true" tabindex="-1"></a>    <span class="co">##############################################################################</span></span>
<span id="cb57-28"><a href="#cb57-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-29"><a href="#cb57-29" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> _extract_anchor_data(<span class="va">self</span>, anchor_data, anchor_idx):</span>
<span id="cb57-30"><a href="#cb57-30" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb57-31"><a href="#cb57-31" aria-hidden="true" tabindex="-1"></a><span class="co">    Inputs:</span></span>
<span id="cb57-32"><a href="#cb57-32" aria-hidden="true" tabindex="-1"></a><span class="co">    - anchor_data: Tensor of shape (B, A, D, H, W) giving a vector of length</span></span>
<span id="cb57-33"><a href="#cb57-33" aria-hidden="true" tabindex="-1"></a><span class="co">      D for each of A anchors at each point in an H x W grid.</span></span>
<span id="cb57-34"><a href="#cb57-34" aria-hidden="true" tabindex="-1"></a><span class="co">    - anchor_idx: int64 Tensor of shape (M,) giving anchor indices to extract</span></span>
<span id="cb57-35"><a href="#cb57-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-36"><a href="#cb57-36" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb57-37"><a href="#cb57-37" aria-hidden="true" tabindex="-1"></a><span class="co">    - extracted_anchors: Tensor of shape (M, D) giving anchor data for each</span></span>
<span id="cb57-38"><a href="#cb57-38" aria-hidden="true" tabindex="-1"></a><span class="co">      of the anchors specified by anchor_idx.</span></span>
<span id="cb57-39"><a href="#cb57-39" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb57-40"><a href="#cb57-40" aria-hidden="true" tabindex="-1"></a>    B, A, D, H, W <span class="op">=</span> anchor_data.shape</span>
<span id="cb57-41"><a href="#cb57-41" aria-hidden="true" tabindex="-1"></a>    anchor_data <span class="op">=</span> anchor_data.permute(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>).contiguous().view(<span class="op">-</span><span class="dv">1</span>, D)</span>
<span id="cb57-42"><a href="#cb57-42" aria-hidden="true" tabindex="-1"></a>    extracted_anchors <span class="op">=</span> anchor_data[anchor_idx]</span>
<span id="cb57-43"><a href="#cb57-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> extracted_anchors</span>
<span id="cb57-44"><a href="#cb57-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-45"><a href="#cb57-45" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> _extract_class_scores(<span class="va">self</span>, all_scores, anchor_idx):</span>
<span id="cb57-46"><a href="#cb57-46" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb57-47"><a href="#cb57-47" aria-hidden="true" tabindex="-1"></a><span class="co">    Inputs:</span></span>
<span id="cb57-48"><a href="#cb57-48" aria-hidden="true" tabindex="-1"></a><span class="co">    - all_scores: Tensor of shape (B, C, H, W) giving classification scores for</span></span>
<span id="cb57-49"><a href="#cb57-49" aria-hidden="true" tabindex="-1"></a><span class="co">      C classes at each point in an H x W grid.</span></span>
<span id="cb57-50"><a href="#cb57-50" aria-hidden="true" tabindex="-1"></a><span class="co">    - anchor_idx: int64 Tensor of shape (M,) giving the indices of anchors at</span></span>
<span id="cb57-51"><a href="#cb57-51" aria-hidden="true" tabindex="-1"></a><span class="co">      which to extract classification scores</span></span>
<span id="cb57-52"><a href="#cb57-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-53"><a href="#cb57-53" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb57-54"><a href="#cb57-54" aria-hidden="true" tabindex="-1"></a><span class="co">    - extracted_scores: Tensor of shape (M, C) giving the classification scores</span></span>
<span id="cb57-55"><a href="#cb57-55" aria-hidden="true" tabindex="-1"></a><span class="co">      for each of the anchors specified by anchor_idx.</span></span>
<span id="cb57-56"><a href="#cb57-56" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb57-57"><a href="#cb57-57" aria-hidden="true" tabindex="-1"></a>    B, C, H, W <span class="op">=</span> all_scores.shape</span>
<span id="cb57-58"><a href="#cb57-58" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> <span class="va">self</span>.num_anchors</span>
<span id="cb57-59"><a href="#cb57-59" aria-hidden="true" tabindex="-1"></a>    all_scores <span class="op">=</span> all_scores.contiguous().permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>).contiguous()</span>
<span id="cb57-60"><a href="#cb57-60" aria-hidden="true" tabindex="-1"></a>    all_scores <span class="op">=</span> all_scores.view(B, <span class="dv">1</span>, H, W, C).expand(B, A, H, W, C)</span>
<span id="cb57-61"><a href="#cb57-61" aria-hidden="true" tabindex="-1"></a>    all_scores <span class="op">=</span> all_scores.reshape(B <span class="op">*</span> A <span class="op">*</span> H <span class="op">*</span> W, C)</span>
<span id="cb57-62"><a href="#cb57-62" aria-hidden="true" tabindex="-1"></a>    extracted_scores <span class="op">=</span> all_scores[anchor_idx]</span>
<span id="cb57-63"><a href="#cb57-63" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> extracted_scores</span>
<span id="cb57-64"><a href="#cb57-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-65"><a href="#cb57-65" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, features, pos_anchor_idx<span class="op">=</span><span class="va">None</span>, neg_anchor_idx<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb57-66"><a href="#cb57-66" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb57-67"><a href="#cb57-67" aria-hidden="true" tabindex="-1"></a><span class="co">    Run the forward pass of the network to predict outputs given features</span></span>
<span id="cb57-68"><a href="#cb57-68" aria-hidden="true" tabindex="-1"></a><span class="co">    from the backbone network.</span></span>
<span id="cb57-69"><a href="#cb57-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-70"><a href="#cb57-70" aria-hidden="true" tabindex="-1"></a><span class="co">    Inputs:</span></span>
<span id="cb57-71"><a href="#cb57-71" aria-hidden="true" tabindex="-1"></a><span class="co">    - features: Tensor of shape (B, in_dim, 7, 7) giving image features computed</span></span>
<span id="cb57-72"><a href="#cb57-72" aria-hidden="true" tabindex="-1"></a><span class="co">      by the backbone network.</span></span>
<span id="cb57-73"><a href="#cb57-73" aria-hidden="true" tabindex="-1"></a><span class="co">    - pos_anchor_idx: int64 Tensor of shape (M,) giving the indices of anchors</span></span>
<span id="cb57-74"><a href="#cb57-74" aria-hidden="true" tabindex="-1"></a><span class="co">      marked as positive. These are only given during training; at test-time</span></span>
<span id="cb57-75"><a href="#cb57-75" aria-hidden="true" tabindex="-1"></a><span class="co">      this should be None.</span></span>
<span id="cb57-76"><a href="#cb57-76" aria-hidden="true" tabindex="-1"></a><span class="co">    - neg_anchor_idx: int64 Tensor of shape (M,) giving the indices of anchors</span></span>
<span id="cb57-77"><a href="#cb57-77" aria-hidden="true" tabindex="-1"></a><span class="co">      marked as negative. These are only given at training; at test-time this</span></span>
<span id="cb57-78"><a href="#cb57-78" aria-hidden="true" tabindex="-1"></a><span class="co">      should be None.</span></span>
<span id="cb57-79"><a href="#cb57-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-80"><a href="#cb57-80" aria-hidden="true" tabindex="-1"></a><span class="co">    The outputs from this method are different during training and inference.</span></span>
<span id="cb57-81"><a href="#cb57-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-82"><a href="#cb57-82" aria-hidden="true" tabindex="-1"></a><span class="co">    During training, pos_anchor_idx and neg_anchor_idx are given and identify</span></span>
<span id="cb57-83"><a href="#cb57-83" aria-hidden="true" tabindex="-1"></a><span class="co">    which anchors should be positive and negative, and this forward pass needs</span></span>
<span id="cb57-84"><a href="#cb57-84" aria-hidden="true" tabindex="-1"></a><span class="co">    to extract only the predictions for the positive and negative anchors.</span></span>
<span id="cb57-85"><a href="#cb57-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-86"><a href="#cb57-86" aria-hidden="true" tabindex="-1"></a><span class="co">    During inference, only features are provided and this method needs to return</span></span>
<span id="cb57-87"><a href="#cb57-87" aria-hidden="true" tabindex="-1"></a><span class="co">    predictions for all anchors.</span></span>
<span id="cb57-88"><a href="#cb57-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-89"><a href="#cb57-89" aria-hidden="true" tabindex="-1"></a><span class="co">    Outputs (During training):</span></span>
<span id="cb57-90"><a href="#cb57-90" aria-hidden="true" tabindex="-1"></a><span class="co">    - conf_scores: Tensor of shape (2*M, 1) giving the predicted classification</span></span>
<span id="cb57-91"><a href="#cb57-91" aria-hidden="true" tabindex="-1"></a><span class="co">      scores for positive anchors and negative anchors (in that order).</span></span>
<span id="cb57-92"><a href="#cb57-92" aria-hidden="true" tabindex="-1"></a><span class="co">    - offsets: Tensor of shape (M, 4) giving predicted transformation for</span></span>
<span id="cb57-93"><a href="#cb57-93" aria-hidden="true" tabindex="-1"></a><span class="co">      positive anchors.</span></span>
<span id="cb57-94"><a href="#cb57-94" aria-hidden="true" tabindex="-1"></a><span class="co">    - class_scores: Tensor of shape (M, C) giving classification scores for</span></span>
<span id="cb57-95"><a href="#cb57-95" aria-hidden="true" tabindex="-1"></a><span class="co">      positive anchors.</span></span>
<span id="cb57-96"><a href="#cb57-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-97"><a href="#cb57-97" aria-hidden="true" tabindex="-1"></a><span class="co">    Outputs (During inference):</span></span>
<span id="cb57-98"><a href="#cb57-98" aria-hidden="true" tabindex="-1"></a><span class="co">    - conf_scores: Tensor of shape (B, A, H, W) giving predicted classification</span></span>
<span id="cb57-99"><a href="#cb57-99" aria-hidden="true" tabindex="-1"></a><span class="co">      scores for all anchors.</span></span>
<span id="cb57-100"><a href="#cb57-100" aria-hidden="true" tabindex="-1"></a><span class="co">    - offsets: Tensor of shape (B, A, 4, H, W) giving predicted transformations</span></span>
<span id="cb57-101"><a href="#cb57-101" aria-hidden="true" tabindex="-1"></a><span class="co">      all all anchors.</span></span>
<span id="cb57-102"><a href="#cb57-102" aria-hidden="true" tabindex="-1"></a><span class="co">    - class_scores: Tensor of shape (B, C, H, W) giving classification scores for</span></span>
<span id="cb57-103"><a href="#cb57-103" aria-hidden="true" tabindex="-1"></a><span class="co">      each spatial position.</span></span>
<span id="cb57-104"><a href="#cb57-104" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb57-105"><a href="#cb57-105" aria-hidden="true" tabindex="-1"></a>    conf_scores, offsets, class_scores <span class="op">=</span> <span class="va">None</span>, <span class="va">None</span>, <span class="va">None</span></span>
<span id="cb57-106"><a href="#cb57-106" aria-hidden="true" tabindex="-1"></a>    <span class="co">############################################################################</span></span>
<span id="cb57-107"><a href="#cb57-107" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">TODO</span><span class="co">: Use backbone features to predict conf_scores, offsets, and         #</span></span>
<span id="cb57-108"><a href="#cb57-108" aria-hidden="true" tabindex="-1"></a>    <span class="co"># class_scores. Make sure conf_scores is between 0 and 1 by squashing the  #</span></span>
<span id="cb57-109"><a href="#cb57-109" aria-hidden="true" tabindex="-1"></a>    <span class="co"># network output with a sigmoid. Also make sure the first two elements t^x #</span></span>
<span id="cb57-110"><a href="#cb57-110" aria-hidden="true" tabindex="-1"></a>    <span class="co"># and t^y of offsets are between -0.5 and 0.5 by squashing with a sigmoid  #</span></span>
<span id="cb57-111"><a href="#cb57-111" aria-hidden="true" tabindex="-1"></a>    <span class="co"># and subtracting 0.5.                                                     #</span></span>
<span id="cb57-112"><a href="#cb57-112" aria-hidden="true" tabindex="-1"></a>    <span class="co">#                                                                          #</span></span>
<span id="cb57-113"><a href="#cb57-113" aria-hidden="true" tabindex="-1"></a>    <span class="co"># During training you need to extract the outputs for only the positive    #</span></span>
<span id="cb57-114"><a href="#cb57-114" aria-hidden="true" tabindex="-1"></a>    <span class="co"># and negative anchors as specified above.                                 #</span></span>
<span id="cb57-115"><a href="#cb57-115" aria-hidden="true" tabindex="-1"></a>    <span class="co">#                                                                          #</span></span>
<span id="cb57-116"><a href="#cb57-116" aria-hidden="true" tabindex="-1"></a>    <span class="co"># HINT: You can use the provided helper methods self._extract_anchor_data  #</span></span>
<span id="cb57-117"><a href="#cb57-117" aria-hidden="true" tabindex="-1"></a>    <span class="co"># and self._extract_class_scores to extract information for positive and   #</span></span>
<span id="cb57-118"><a href="#cb57-118" aria-hidden="true" tabindex="-1"></a>    <span class="co"># negative anchors specified by pos_anchor_idx and neg_anchor_idx.         #</span></span>
<span id="cb57-119"><a href="#cb57-119" aria-hidden="true" tabindex="-1"></a>    <span class="co">############################################################################</span></span>
<span id="cb57-120"><a href="#cb57-120" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Replace &quot;pass&quot; statement with your code</span></span>
<span id="cb57-121"><a href="#cb57-121" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Run the network on the input features</span></span>
<span id="cb57-122"><a href="#cb57-122" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Run the network on the input features</span></span>
<span id="cb57-123"><a href="#cb57-123" aria-hidden="true" tabindex="-1"></a>    network_pred <span class="op">=</span> <span class="va">self</span>.network(features)  <span class="co"># (B, 5*A + C, H, W)</span></span>
<span id="cb57-124"><a href="#cb57-124" aria-hidden="true" tabindex="-1"></a>    B, total_channels, H, W <span class="op">=</span> network_pred.shape</span>
<span id="cb57-125"><a href="#cb57-125" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> <span class="va">self</span>.num_anchors</span>
<span id="cb57-126"><a href="#cb57-126" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> total_channels <span class="op">-</span> <span class="dv">5</span> <span class="op">*</span> A  <span class="co"># number of class channels</span></span>
<span id="cb57-127"><a href="#cb57-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-128"><a href="#cb57-128" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Split into anchor and class predictions, and reshape anchor predictions</span></span>
<span id="cb57-129"><a href="#cb57-129" aria-hidden="true" tabindex="-1"></a>    anchor_pred <span class="op">=</span> network_pred[:, :<span class="dv">5</span> <span class="op">*</span> A, :, :].view(B, A, <span class="dv">5</span>, H, W)</span>
<span id="cb57-130"><a href="#cb57-130" aria-hidden="true" tabindex="-1"></a>    class_scores_all <span class="op">=</span> network_pred[:, <span class="dv">5</span> <span class="op">*</span> A:, :, :]</span>
<span id="cb57-131"><a href="#cb57-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-132"><a href="#cb57-132" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pos_anchor_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> neg_anchor_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb57-133"><a href="#cb57-133" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Training mode:</span></span>
<span id="cb57-134"><a href="#cb57-134" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute confidence scores and offsets in one go.</span></span>
<span id="cb57-135"><a href="#cb57-135" aria-hidden="true" tabindex="-1"></a>        conf_pred <span class="op">=</span> torch.sigmoid(anchor_pred[:, :, <span class="dv">0</span>, :, :]).unsqueeze(<span class="dv">2</span>)  <span class="co"># (B, A, 1, H, W)</span></span>
<span id="cb57-136"><a href="#cb57-136" aria-hidden="true" tabindex="-1"></a>        offsets_pred <span class="op">=</span> anchor_pred[:, :, <span class="dv">1</span>:<span class="dv">5</span>, :, :]  <span class="co"># (B, A, 4, H, W)</span></span>
<span id="cb57-137"><a href="#cb57-137" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply sigmoid to x,y and subtract 0.5:</span></span>
<span id="cb57-138"><a href="#cb57-138" aria-hidden="true" tabindex="-1"></a>        offsets_xy <span class="op">=</span> torch.sigmoid(offsets_pred[:, :, <span class="dv">0</span>:<span class="dv">2</span>, :, :]) <span class="op">-</span> <span class="fl">0.5</span></span>
<span id="cb57-139"><a href="#cb57-139" aria-hidden="true" tabindex="-1"></a>        offsets_rest <span class="op">=</span> offsets_pred[:, :, <span class="dv">2</span>:<span class="dv">4</span>, :, :]</span>
<span id="cb57-140"><a href="#cb57-140" aria-hidden="true" tabindex="-1"></a>        offsets_pred <span class="op">=</span> torch.cat([offsets_xy, offsets_rest], dim<span class="op">=</span><span class="dv">2</span>)  <span class="co"># (B, A, 4, H, W)</span></span>
<span id="cb57-141"><a href="#cb57-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-142"><a href="#cb57-142" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Flatten predictions over batch, anchors, and spatial dims.</span></span>
<span id="cb57-143"><a href="#cb57-143" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For confidence, 1 channel means order doesn’t matter much.</span></span>
<span id="cb57-144"><a href="#cb57-144" aria-hidden="true" tabindex="-1"></a>        conf_pred_flat <span class="op">=</span> conf_pred.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb57-145"><a href="#cb57-145" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For offsets, match the helper&#39;s permutation:</span></span>
<span id="cb57-146"><a href="#cb57-146" aria-hidden="true" tabindex="-1"></a>        offsets_flat <span class="op">=</span> offsets_pred.permute(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>).contiguous().view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>)</span>
<span id="cb57-147"><a href="#cb57-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-148"><a href="#cb57-148" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract positive and negative predictions</span></span>
<span id="cb57-149"><a href="#cb57-149" aria-hidden="true" tabindex="-1"></a>        pos_conf <span class="op">=</span> conf_pred_flat[pos_anchor_idx]</span>
<span id="cb57-150"><a href="#cb57-150" aria-hidden="true" tabindex="-1"></a>        neg_conf <span class="op">=</span> conf_pred_flat[neg_anchor_idx]</span>
<span id="cb57-151"><a href="#cb57-151" aria-hidden="true" tabindex="-1"></a>        conf_scores <span class="op">=</span> torch.cat([pos_conf, neg_conf], dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb57-152"><a href="#cb57-152" aria-hidden="true" tabindex="-1"></a>        offsets <span class="op">=</span> offsets_flat[pos_anchor_idx]</span>
<span id="cb57-153"><a href="#cb57-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-154"><a href="#cb57-154" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For class scores, flatten in a vectorized way:</span></span>
<span id="cb57-155"><a href="#cb57-155" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (B, C, H, W) -&gt; (B, H, W, C) -&gt; unsqueeze and expand for A anchors,</span></span>
<span id="cb57-156"><a href="#cb57-156" aria-hidden="true" tabindex="-1"></a>        <span class="co"># then flatten to shape (B*A*H*W, C)</span></span>
<span id="cb57-157"><a href="#cb57-157" aria-hidden="true" tabindex="-1"></a>        class_scores_all_flat <span class="op">=</span> (</span>
<span id="cb57-158"><a href="#cb57-158" aria-hidden="true" tabindex="-1"></a>            class_scores_all.permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb57-159"><a href="#cb57-159" aria-hidden="true" tabindex="-1"></a>            .unsqueeze(<span class="dv">1</span>)</span>
<span id="cb57-160"><a href="#cb57-160" aria-hidden="true" tabindex="-1"></a>            .expand(B, A, H, W, C)</span>
<span id="cb57-161"><a href="#cb57-161" aria-hidden="true" tabindex="-1"></a>            .contiguous()</span>
<span id="cb57-162"><a href="#cb57-162" aria-hidden="true" tabindex="-1"></a>            .view(<span class="op">-</span><span class="dv">1</span>, C)</span>
<span id="cb57-163"><a href="#cb57-163" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb57-164"><a href="#cb57-164" aria-hidden="true" tabindex="-1"></a>        class_scores <span class="op">=</span> class_scores_all_flat[pos_anchor_idx]</span>
<span id="cb57-165"><a href="#cb57-165" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb57-166"><a href="#cb57-166" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Inference mode -&gt; return predictions for all anchors.</span></span>
<span id="cb57-167"><a href="#cb57-167" aria-hidden="true" tabindex="-1"></a>        conf_scores <span class="op">=</span> torch.sigmoid(anchor_pred[:, :, <span class="dv">0</span>:<span class="dv">1</span>, :, :]).squeeze(<span class="dv">2</span>)</span>
<span id="cb57-168"><a href="#cb57-168" aria-hidden="true" tabindex="-1"></a>        offsets_pred <span class="op">=</span> anchor_pred[:, :, <span class="dv">1</span>:<span class="dv">5</span>, :, :]</span>
<span id="cb57-169"><a href="#cb57-169" aria-hidden="true" tabindex="-1"></a>        offsets_xy <span class="op">=</span> torch.sigmoid(offsets_pred[:, :, <span class="dv">0</span>:<span class="dv">2</span>, :, :]) <span class="op">-</span> <span class="fl">0.5</span></span>
<span id="cb57-170"><a href="#cb57-170" aria-hidden="true" tabindex="-1"></a>        offsets_rest <span class="op">=</span> offsets_pred[:, :, <span class="dv">2</span>:<span class="dv">4</span>, :, :]</span>
<span id="cb57-171"><a href="#cb57-171" aria-hidden="true" tabindex="-1"></a>        offsets <span class="op">=</span> torch.cat([offsets_xy, offsets_rest], dim<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb57-172"><a href="#cb57-172" aria-hidden="true" tabindex="-1"></a>        class_scores <span class="op">=</span> class_scores_all</span>
<span id="cb57-173"><a href="#cb57-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-174"><a href="#cb57-174" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> conf_scores, offsets, class_scores</span></code></pre></div>
</div>
<div class="cell markdown" id="tqPhOOjiWuSM">
<p>Run the following to check your implementation. You should see errors
on the order of 1e-4 or less.</p>
</div>
<div class="cell code" data-execution_count="35"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:0}"
id="4lgXGvq7JOmS" data-outputId="20c57930-8830-4450-a3e3-ab9bf1a3e3bc">
<div class="sourceCode" id="cb58"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sanity check</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>fix_random_seed(<span class="dv">0</span>)</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>pred_network <span class="op">=</span> PredictionNetwork(<span class="dv">1280</span>, drop_ratio<span class="op">=</span><span class="dv">0</span>).to(<span class="op">**</span>to_float_cuda)</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> torch.linspace(<span class="op">-</span><span class="fl">10.</span>, <span class="fl">10.</span>, steps<span class="op">=</span><span class="dv">3</span><span class="op">*</span><span class="dv">1280</span><span class="op">*</span><span class="dv">7</span><span class="op">*</span><span class="dv">7</span>, <span class="op">**</span>to_float_cuda).view(<span class="dv">3</span>, <span class="dv">1280</span>, <span class="dv">7</span>, <span class="dv">7</span>)</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>pos_anchor_idx <span class="op">=</span> torch.tensor([<span class="dv">122</span>, <span class="dv">605</span>, <span class="dv">871</span>, <span class="dv">955</span>], <span class="op">**</span>to_long_cuda)</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>neg_anchor_idx <span class="op">=</span> torch.tensor([<span class="dv">1048</span>, <span class="dv">1292</span>, <span class="dv">1124</span>, <span class="dv">1092</span>], <span class="op">**</span>to_long_cuda)</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>conf_scores, offsets, class_prob <span class="op">=</span> pred_network(features, pos_anchor_idx, neg_anchor_idx)</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>expected_conf_scores <span class="op">=</span> torch.tensor([[<span class="fl">0.85080749</span>], [<span class="fl">0.55230302</span>], [<span class="fl">0.45239496</span>], [<span class="fl">0.51819414</span>],</span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>                                     [<span class="fl">0.38467780</span>], [<span class="fl">0.82627463</span>], [<span class="fl">0.53837817</span>], [<span class="fl">0.538446366</span>]], <span class="op">**</span>to_float_cuda)</span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a>expected_offsets <span class="op">=</span> torch.tensor([[<span class="op">-</span><span class="fl">0.16344640</span>,  <span class="fl">0.45598251</span>, <span class="op">-</span><span class="fl">1.56108809</span>, <span class="op">-</span><span class="fl">1.96177566</span>],</span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a>                                 [ <span class="fl">0.09087485</span>, <span class="op">-</span><span class="fl">0.11321104</span>,  <span class="fl">0.46109992</span>,  <span class="fl">0.13557276</span>],</span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a>                                 [ <span class="fl">0.14098871</span>, <span class="op">-</span><span class="fl">0.04003078</span>, <span class="op">-</span><span class="fl">0.14689390</span>,  <span class="fl">0.01480492</span>],</span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a>                                 [<span class="op">-</span><span class="fl">0.22611487</span>,  <span class="fl">0.14513946</span>, <span class="op">-</span><span class="fl">1.26124716</span>,  <span class="fl">0.58137202</span>]], <span class="op">**</span>to_float_cuda)</span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a>expected_class_prob <span class="op">=</span> torch.tensor([<span class="fl">0.88649291</span>, <span class="fl">1.08752346</span>, <span class="fl">0.90241265</span>, <span class="fl">1.28021181</span>, <span class="fl">0.77324629</span>,</span>
<span id="cb58-16"><a href="#cb58-16" aria-hidden="true" tabindex="-1"></a>                                    <span class="op">-</span><span class="fl">0.93609941</span>, <span class="fl">1.44269419</span>, <span class="op">-</span><span class="fl">1.01072836</span>, <span class="fl">0.09888625</span>, <span class="op">-</span><span class="fl">0.09179375</span>,</span>
<span id="cb58-17"><a href="#cb58-17" aria-hidden="true" tabindex="-1"></a>                                    <span class="op">-</span><span class="fl">0.48814785</span>, <span class="op">-</span><span class="fl">1.14749694</span>, <span class="fl">0.24533349</span>, <span class="op">-</span><span class="fl">0.19522685</span>, <span class="fl">0.21445289</span>,</span>
<span id="cb58-18"><a href="#cb58-18" aria-hidden="true" tabindex="-1"></a>                                    <span class="fl">0.91779679</span>, <span class="fl">0.97305167</span>, <span class="fl">1.01984429</span>, <span class="op">-</span><span class="fl">0.11932681</span>, <span class="fl">0.34998628</span>], <span class="op">**</span>to_float_cuda)</span>
<span id="cb58-19"><a href="#cb58-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-20"><a href="#cb58-20" aria-hidden="true" tabindex="-1"></a>error <span class="op">=</span> rel_error(conf_scores, expected_conf_scores)</span>
<span id="cb58-21"><a href="#cb58-21" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">if</span> error <span class="op">&lt;</span> <span class="fl">1e-4</span> <span class="cf">else</span> <span class="st">&quot;Fail&quot;</span></span>
<span id="cb58-22"><a href="#cb58-22" aria-hidden="true" tabindex="-1"></a>color <span class="op">=</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[92m&quot;</span> <span class="cf">if</span> result <span class="op">==</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">else</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[91m&quot;</span></span>
<span id="cb58-23"><a href="#cb58-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Confidence Scores Relative Error: </span><span class="sc">{</span>error<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>color<span class="sc">}</span><span class="ss">Result: </span><span class="sc">{</span>result<span class="sc">}</span><span class="ch">\033</span><span class="ss">[0m&#39;</span>)</span>
<span id="cb58-24"><a href="#cb58-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-25"><a href="#cb58-25" aria-hidden="true" tabindex="-1"></a>error <span class="op">=</span> rel_error(offsets, expected_offsets)</span>
<span id="cb58-26"><a href="#cb58-26" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">if</span> error <span class="op">&lt;</span> <span class="fl">1e-4</span> <span class="cf">else</span> <span class="st">&quot;Fail&quot;</span></span>
<span id="cb58-27"><a href="#cb58-27" aria-hidden="true" tabindex="-1"></a>color <span class="op">=</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[92m&quot;</span> <span class="cf">if</span> result <span class="op">==</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">else</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[91m&quot;</span></span>
<span id="cb58-28"><a href="#cb58-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Offsets Relative Error: </span><span class="sc">{</span>error<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>color<span class="sc">}</span><span class="ss">Result: </span><span class="sc">{</span>result<span class="sc">}</span><span class="ch">\033</span><span class="ss">[0m&#39;</span>)</span>
<span id="cb58-29"><a href="#cb58-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-30"><a href="#cb58-30" aria-hidden="true" tabindex="-1"></a>error <span class="op">=</span> rel_error(class_prob.mean(<span class="dv">0</span>), expected_class_prob)</span>
<span id="cb58-31"><a href="#cb58-31" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">if</span> error <span class="op">&lt;</span> <span class="fl">1e-4</span> <span class="cf">else</span> <span class="st">&quot;Fail&quot;</span></span>
<span id="cb58-32"><a href="#cb58-32" aria-hidden="true" tabindex="-1"></a>color <span class="op">=</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[92m&quot;</span> <span class="cf">if</span> result <span class="op">==</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">else</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[91m&quot;</span></span>
<span id="cb58-33"><a href="#cb58-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Class Probabilities Relative Error: </span><span class="sc">{</span>error<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>color<span class="sc">}</span><span class="ss">Result: </span><span class="sc">{</span>result<span class="sc">}</span><span class="ch">\033</span><span class="ss">[0m&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Confidence Scores Relative Error: 2.3242040469995118e-07
Result: Pass
Offsets Relative Error: 2.4281827791128308e-05
Result: Pass
Class Probabilities Relative Error: 1.3798310192214558e-06
Result: Pass
</code></pre>
</div>
</div>
<section id="loss-function" class="cell markdown" id="ah05Gd6BOKG2">
<h2>Loss Function</h2>
<p>The confidence score regression loss is for both activated/negative
anchors while the bounding box regression loss and the object
classification loss are for activated anchors only. These are
implemented for you.</p>
</section>
<section id="confidence-score-regression" class="cell markdown"
id="ZDwpyHZBxNRn">
<h3>Confidence score regression</h3>
</section>
<div class="cell code" data-execution_count="36" id="cmVyv6NrxTiM">
<div class="sourceCode" id="cb60"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ConfScoreRegression(conf_scores, GT_conf_scores):</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a><span class="co">  Use sum-squared error as in YOLO</span></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a><span class="co">  Inputs:</span></span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a><span class="co">  - conf_scores: Predicted confidence scores</span></span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - GT_conf_scores: GT confidence scores</span></span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a><span class="co">  Outputs:</span></span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a><span class="co">  - conf_score_loss</span></span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a><span class="co">  &quot;&quot;&quot;</span></span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># the target conf_scores for negative samples are zeros</span></span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a>  GT_conf_scores <span class="op">=</span> torch.cat((torch.ones_like(GT_conf_scores), <span class="op">\</span></span>
<span id="cb60-14"><a href="#cb60-14" aria-hidden="true" tabindex="-1"></a>                              torch.zeros_like(GT_conf_scores)), dim<span class="op">=</span><span class="dv">0</span>).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb60-15"><a href="#cb60-15" aria-hidden="true" tabindex="-1"></a>  conf_score_loss <span class="op">=</span> torch.<span class="bu">sum</span>((conf_scores <span class="op">-</span> GT_conf_scores)<span class="op">**</span><span class="dv">2</span>) <span class="op">*</span> <span class="fl">1.</span> <span class="op">/</span> GT_conf_scores.shape[<span class="dv">0</span>]</span>
<span id="cb60-16"><a href="#cb60-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> conf_score_loss</span></code></pre></div>
</div>
<section id="bounding-box-regression" class="cell markdown"
id="sRyF6HDGxT7P">
<h3>Bounding box regression</h3>
</section>
<div class="cell code" data-execution_count="37" id="yecLoQLjxcx7">
<div class="sourceCode" id="cb61"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> BboxRegression(offsets, GT_offsets):</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">&quot;&quot;&quot;&quot;</span></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="co">  Use sum-squared error as in YOLO</span></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a><span class="co">  For both xy and wh</span></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a><span class="co">  Inputs:</span></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - offsets: Predicted box offsets</span></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a><span class="co">  - GT_offsets: GT box offsets</span></span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a><span class="co">  Outputs:</span></span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a><span class="co">  - bbox_reg_loss</span></span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a><span class="co">  &quot;&quot;&quot;</span></span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a>  bbox_reg_loss <span class="op">=</span> torch.<span class="bu">sum</span>((offsets <span class="op">-</span> GT_offsets)<span class="op">**</span><span class="dv">2</span>) <span class="op">*</span> <span class="fl">1.</span> <span class="op">/</span> GT_offsets.shape[<span class="dv">0</span>]</span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> bbox_reg_loss</span></code></pre></div>
</div>
<section id="object-classifiction" class="cell markdown"
id="lADrqUuoxdRb">
<h3>Object classifiction</h3>
</section>
<div class="cell code" data-execution_count="38" id="2FoLOeypxpC8">
<div class="sourceCode" id="cb62"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ObjectClassification(class_prob, GT_class, batch_size, anc_per_img, activated_anc_ind):</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">&quot;&quot;&quot;&quot;</span></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a><span class="co">  Use softmax loss</span></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a><span class="co">  Inputs:</span></span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a><span class="co">  - class_prob: Predicted softmax class probability</span></span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - GT_class: GT box class label</span></span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a><span class="co">  Outputs:</span></span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a><span class="co">  - object_cls_loss</span></span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a><span class="co">  &quot;&quot;&quot;</span></span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># average within sample and then average across batch</span></span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># such that the class pred would not bias towards dense popular objects like `person`</span></span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a>  all_loss <span class="op">=</span> F.cross_entropy(class_prob, GT_class, reduction<span class="op">=</span><span class="st">&#39;none&#39;</span>) <span class="co"># , reduction=&#39;sum&#39;) * 1. / batch_size</span></span>
<span id="cb62-15"><a href="#cb62-15" aria-hidden="true" tabindex="-1"></a>  object_cls_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb62-16"><a href="#cb62-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(batch_size):</span>
<span id="cb62-17"><a href="#cb62-17" aria-hidden="true" tabindex="-1"></a>    anc_ind_in_img <span class="op">=</span> (activated_anc_ind <span class="op">&gt;=</span> idx <span class="op">*</span> anc_per_img) <span class="op">&amp;</span> (activated_anc_ind <span class="op">&lt;</span> (idx<span class="op">+</span><span class="dv">1</span>) <span class="op">*</span> anc_per_img)</span>
<span id="cb62-18"><a href="#cb62-18" aria-hidden="true" tabindex="-1"></a>    object_cls_loss <span class="op">+=</span> all_loss[anc_ind_in_img].<span class="bu">sum</span>() <span class="op">*</span> <span class="fl">1.</span> <span class="op">/</span> torch.<span class="bu">sum</span>(anc_ind_in_img)</span>
<span id="cb62-19"><a href="#cb62-19" aria-hidden="true" tabindex="-1"></a>  object_cls_loss <span class="op">/=</span> batch_size</span>
<span id="cb62-20"><a href="#cb62-20" aria-hidden="true" tabindex="-1"></a>  <span class="co"># object_cls_loss = F.cross_entropy(class_prob, GT_class, reduction=&#39;sum&#39;) * 1. / batch_size</span></span>
<span id="cb62-21"><a href="#cb62-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-22"><a href="#cb62-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> object_cls_loss</span></code></pre></div>
</div>
<div class="cell markdown" id="CJQGhhMTVi3k">
<p>Run the following to check your implementation. You should see errors
on the order of 1e-6 or less.</p>
</div>
<div class="cell code" data-execution_count="39"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:0}"
id="B0iG-DAUOQ56" data-outputId="e4efadf9-f039-44f1-f2aa-1e55fc1573e7">
<div class="sourceCode" id="cb63"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sanity check</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>conf_loss <span class="op">=</span> ConfScoreRegression(conf_scores, GT_conf_scores)</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>reg_loss <span class="op">=</span> BboxRegression(offsets, GT_offsets)</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>cls_loss <span class="op">=</span> ObjectClassification(class_prob, GT_class, w_list.shape[<span class="dv">0</span>], anc_per_img, activated_anc_ind)</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;conf loss: </span><span class="sc">{:.4f}</span><span class="st">, reg loss: </span><span class="sc">{:.4f}</span><span class="st">, cls loss: </span><span class="sc">{:.4f}</span><span class="st">&#39;</span>.<span class="bu">format</span>(conf_loss, reg_loss, cls_loss))</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>loss_all <span class="op">=</span> torch.tensor([conf_loss.data, reg_loss.data, cls_loss.data], <span class="op">**</span>to_float_cuda)</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>expected_loss <span class="op">=</span> torch.tensor([<span class="fl">0.27064770460128784</span>, <span class="fl">2.9750006198883057</span>, <span class="fl">2.3919472694396973</span>], <span class="op">**</span>to_float_cuda)</span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a>error <span class="op">=</span> rel_error(loss_all, expected_loss)</span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">if</span> error <span class="op">&lt;</span> <span class="fl">1e-6</span> <span class="cf">else</span> <span class="st">&quot;Fail&quot;</span></span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a>color <span class="op">=</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[92m&quot;</span> <span class="cf">if</span> result <span class="op">==</span> <span class="st">&quot;Pass&quot;</span> <span class="cf">else</span> <span class="st">&quot;</span><span class="ch">\033</span><span class="st">[91m&quot;</span></span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Loss Relative Error: </span><span class="sc">{</span>error<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>color<span class="sc">}</span><span class="ss">Result: </span><span class="sc">{</span>result<span class="sc">}</span><span class="ch">\033</span><span class="ss">[0m&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>conf loss: 0.2706, reg loss: 2.9750, cls loss: 2.3919
Loss Relative Error: 1.9935103523494035e-07
Result: Pass
</code></pre>
</div>
</div>
<section id="train-an-object-detector" class="cell markdown"
id="MIt5AxlAxwKz">
<h1>Train an object detector</h1>
</section>
<section id="object-detection-module" class="cell markdown"
id="7yCYzKIxx2qB">
<h2>Object detection module</h2>
<p>We will now combine everything into the
<code>SingleStageDetector</code> class:</p>
</section>
<div class="cell code" data-execution_count="40" id="7OsS-KZex6uK">
<div class="sourceCode" id="cb65"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SingleStageDetector(nn.Module):</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.anchor_list <span class="op">=</span> torch.tensor([[<span class="dv">1</span>, <span class="dv">1</span>], [<span class="dv">2</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">3</span>], [<span class="dv">4</span>, <span class="dv">4</span>], [<span class="dv">5</span>, <span class="dv">5</span>], [<span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">3</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">5</span>], [<span class="dv">5</span>, <span class="dv">3</span>]]) <span class="co"># READ ONLY</span></span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.feat_extractor <span class="op">=</span> FeatureExtractor()</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.num_classes <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.pred_network <span class="op">=</span> PredictionNetwork(<span class="dv">1280</span>, num_anchors<span class="op">=</span><span class="va">self</span>.anchor_list.shape[<span class="dv">0</span>], <span class="op">\</span></span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a>                                          num_classes<span class="op">=</span><span class="va">self</span>.num_classes)</span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>):</span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">NotImplementedError</span></span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> inference(<span class="va">self</span>):</span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">NotImplementedError</span></span></code></pre></div>
</div>
<div class="cell markdown" id="5Im5jy1QRaeV">
<p>Implement the <code>forward</code> function of our detector. This
implements the training-time forward pass: it receives the input images
and the ground-truth bounding boxes, and returns the total loss for the
minibatch.</p>
</div>
<div class="cell code" data-execution_count="41" id="MsBG9yqNRWhu">
<div class="sourceCode" id="cb66"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> detector_forward(<span class="va">self</span>, images, bboxes):</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Training-time forward pass for the single-stage detector.</span></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Inputs:</span></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a><span class="co">    - images: Input images, of shape (B, 3, 224, 224)</span></span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a><span class="co">    - bboxes: GT bounding boxes of shape (B, N, 5) (padded)</span></span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Outputs:</span></span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a><span class="co">    - total_loss: Torch scalar giving the total loss for the batch.</span></span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># weights to multiple to each loss term</span></span>
<span id="cb66-13"><a href="#cb66-13" aria-hidden="true" tabindex="-1"></a>    w_conf <span class="op">=</span> <span class="dv">1</span> <span class="co"># for conf_scores</span></span>
<span id="cb66-14"><a href="#cb66-14" aria-hidden="true" tabindex="-1"></a>    w_reg <span class="op">=</span> <span class="dv">1</span> <span class="co"># for offsets</span></span>
<span id="cb66-15"><a href="#cb66-15" aria-hidden="true" tabindex="-1"></a>    w_cls <span class="op">=</span> <span class="dv">1</span> <span class="co"># for class_prob</span></span>
<span id="cb66-16"><a href="#cb66-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-17"><a href="#cb66-17" aria-hidden="true" tabindex="-1"></a>    total_loss <span class="op">=</span> <span class="va">None</span></span>
<span id="cb66-18"><a href="#cb66-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">##############################################################################</span></span>
<span id="cb66-19"><a href="#cb66-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">TODO</span><span class="co">: Implement the forward pass of SingleStageDetector.                   #</span></span>
<span id="cb66-20"><a href="#cb66-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># A few key steps are outlined as follows:                                   #</span></span>
<span id="cb66-21"><a href="#cb66-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># i) Image feature extraction,                                               #</span></span>
<span id="cb66-22"><a href="#cb66-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ii) Grid and anchor generation,                                            #</span></span>
<span id="cb66-23"><a href="#cb66-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># iii) Compute IoU between anchors and GT boxes and then determine activated/#</span></span>
<span id="cb66-24"><a href="#cb66-24" aria-hidden="true" tabindex="-1"></a>    <span class="co">#      negative anchors, and GT_conf_scores, GT_offsets, GT_class,           #</span></span>
<span id="cb66-25"><a href="#cb66-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># iv) Compute conf_scores, offsets, class_prob through the prediction network#</span></span>
<span id="cb66-26"><a href="#cb66-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># v) Compute the total_loss which is formulated as:                          #</span></span>
<span id="cb66-27"><a href="#cb66-27" aria-hidden="true" tabindex="-1"></a>    <span class="co">#    total_loss = w_conf * conf_loss + w_reg * reg_loss + w_cls * cls_loss,  #</span></span>
<span id="cb66-28"><a href="#cb66-28" aria-hidden="true" tabindex="-1"></a>    <span class="co">#    where conf_loss is determined by ConfScoreRegression, w_reg by          #</span></span>
<span id="cb66-29"><a href="#cb66-29" aria-hidden="true" tabindex="-1"></a>    <span class="co">#    BboxRegression, and w_cls by ObjectClassification.                      #</span></span>
<span id="cb66-30"><a href="#cb66-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># HINT: Set `neg_thresh=0.2` in ReferenceOnActivatedAnchors in this notebook #</span></span>
<span id="cb66-31"><a href="#cb66-31" aria-hidden="true" tabindex="-1"></a>    <span class="co">#       (A5-1) for a better performance than with the default value.         #</span></span>
<span id="cb66-32"><a href="#cb66-32" aria-hidden="true" tabindex="-1"></a>    <span class="co">##############################################################################</span></span>
<span id="cb66-33"><a href="#cb66-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Replace &quot;pass&quot; statement with your code</span></span>
<span id="cb66-34"><a href="#cb66-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># i) Extract image features from the backbone</span></span>
<span id="cb66-35"><a href="#cb66-35" aria-hidden="true" tabindex="-1"></a>    features <span class="op">=</span> <span class="va">self</span>.feat_extractor(images)</span>
<span id="cb66-36"><a href="#cb66-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-37"><a href="#cb66-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ii) Generate grid and anchors</span></span>
<span id="cb66-38"><a href="#cb66-38" aria-hidden="true" tabindex="-1"></a>    grid <span class="op">=</span> GenerateGrid(images.shape[<span class="dv">0</span>], dtype<span class="op">=</span>images.dtype, device<span class="op">=</span>images.device)</span>
<span id="cb66-39"><a href="#cb66-39" aria-hidden="true" tabindex="-1"></a>    anchors <span class="op">=</span> GenerateAnchor(<span class="va">self</span>.anchor_list, grid)</span>
<span id="cb66-40"><a href="#cb66-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-41"><a href="#cb66-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># iii) Compute IoU between anchors and GT boxes, then determine activated/negative anchors</span></span>
<span id="cb66-42"><a href="#cb66-42" aria-hidden="true" tabindex="-1"></a>    iou_mat <span class="op">=</span> IoU(anchors, bboxes)</span>
<span id="cb66-43"><a href="#cb66-43" aria-hidden="true" tabindex="-1"></a>    (activated_anc_ind, negative_anc_ind,</span>
<span id="cb66-44"><a href="#cb66-44" aria-hidden="true" tabindex="-1"></a>     GT_conf_scores, GT_offsets, GT_class,</span>
<span id="cb66-45"><a href="#cb66-45" aria-hidden="true" tabindex="-1"></a>     _, _) <span class="op">=</span> ReferenceOnActivatedAnchors(</span>
<span id="cb66-46"><a href="#cb66-46" aria-hidden="true" tabindex="-1"></a>         anchors<span class="op">=</span>anchors,</span>
<span id="cb66-47"><a href="#cb66-47" aria-hidden="true" tabindex="-1"></a>         bboxes<span class="op">=</span>bboxes,</span>
<span id="cb66-48"><a href="#cb66-48" aria-hidden="true" tabindex="-1"></a>         iou_mat<span class="op">=</span>iou_mat,</span>
<span id="cb66-49"><a href="#cb66-49" aria-hidden="true" tabindex="-1"></a>         grid<span class="op">=</span>grid,</span>
<span id="cb66-50"><a href="#cb66-50" aria-hidden="true" tabindex="-1"></a>         neg_thresh<span class="op">=</span><span class="fl">0.2</span></span>
<span id="cb66-51"><a href="#cb66-51" aria-hidden="true" tabindex="-1"></a>     )</span>
<span id="cb66-52"><a href="#cb66-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-53"><a href="#cb66-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># iv) Compute predictions from the prediction network using the extracted features</span></span>
<span id="cb66-54"><a href="#cb66-54" aria-hidden="true" tabindex="-1"></a>    conf_scores, offsets, class_prob <span class="op">=</span> <span class="va">self</span>.pred_network(features, activated_anc_ind, negative_anc_ind)</span>
<span id="cb66-55"><a href="#cb66-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-56"><a href="#cb66-56" aria-hidden="true" tabindex="-1"></a>    <span class="co"># v) Compute individual losses</span></span>
<span id="cb66-57"><a href="#cb66-57" aria-hidden="true" tabindex="-1"></a>    conf_loss <span class="op">=</span> ConfScoreRegression(conf_scores, GT_conf_scores)</span>
<span id="cb66-58"><a href="#cb66-58" aria-hidden="true" tabindex="-1"></a>    reg_loss <span class="op">=</span> BboxRegression(offsets, GT_offsets)</span>
<span id="cb66-59"><a href="#cb66-59" aria-hidden="true" tabindex="-1"></a>    cls_loss <span class="op">=</span> ObjectClassification(class_prob, GT_class, images.shape[<span class="dv">0</span>],</span>
<span id="cb66-60"><a href="#cb66-60" aria-hidden="true" tabindex="-1"></a>                                    <span class="va">self</span>.anchor_list.shape[<span class="dv">0</span>] <span class="op">*</span> <span class="dv">7</span> <span class="op">*</span> <span class="dv">7</span>, activated_anc_ind)</span>
<span id="cb66-61"><a href="#cb66-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-62"><a href="#cb66-62" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Total loss: weighted sum of all losses</span></span>
<span id="cb66-63"><a href="#cb66-63" aria-hidden="true" tabindex="-1"></a>    total_loss <span class="op">=</span> w_conf <span class="op">*</span> conf_loss <span class="op">+</span> w_reg <span class="op">*</span> reg_loss <span class="op">+</span> w_cls <span class="op">*</span> cls_loss</span>
<span id="cb66-64"><a href="#cb66-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-65"><a href="#cb66-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> total_loss</span>
<span id="cb66-66"><a href="#cb66-66" aria-hidden="true" tabindex="-1"></a>    <span class="co">##############################################################################</span></span>
<span id="cb66-67"><a href="#cb66-67" aria-hidden="true" tabindex="-1"></a>    <span class="co">#                               </span><span class="re">END</span><span class="co"> OF YOUR CODE                             #</span></span>
<span id="cb66-68"><a href="#cb66-68" aria-hidden="true" tabindex="-1"></a>    <span class="co">##############################################################################</span></span>
<span id="cb66-69"><a href="#cb66-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-70"><a href="#cb66-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> total_loss</span>
<span id="cb66-71"><a href="#cb66-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-72"><a href="#cb66-72" aria-hidden="true" tabindex="-1"></a>  SingleStageDetector.forward <span class="op">=</span> detector_forward</span></code></pre></div>
</div>
<section id="object-detection-solver" class="cell markdown"
id="JXZAaDklx7Bs">
<h2>Object detection solver</h2>
<p>The <code>DetectionSolver</code> object runs the training loop to
train an single stage detector.</p>
</section>
<div class="cell code" data-execution_count="42" id="s8KX5ohHyBFA">
<div class="sourceCode" id="cb67"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> DetectionSolver(detector, train_loader, learning_rate<span class="op">=</span><span class="fl">3e-3</span>,</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>                    lr_decay<span class="op">=</span><span class="dv">1</span>, num_epochs<span class="op">=</span><span class="dv">20</span>, <span class="op">**</span>kwargs):</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a><span class="co">  Run optimization to train the model.</span></span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a><span class="co">  &quot;&quot;&quot;</span></span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># ship model to GPU</span></span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a>  detector.to(<span class="op">**</span>to_float_cuda)</span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># optimizer setup</span></span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a>  <span class="im">from</span> torch <span class="im">import</span> optim</span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># optimizer = optim.Adam(</span></span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a>  optimizer <span class="op">=</span> optim.SGD(</span>
<span id="cb67-14"><a href="#cb67-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">filter</span>(<span class="kw">lambda</span> p: p.requires_grad, detector.parameters()),</span>
<span id="cb67-15"><a href="#cb67-15" aria-hidden="true" tabindex="-1"></a>    learning_rate) <span class="co"># leave betas and eps by default</span></span>
<span id="cb67-16"><a href="#cb67-16" aria-hidden="true" tabindex="-1"></a>  lr_scheduler <span class="op">=</span> optim.lr_scheduler.LambdaLR(optimizer,</span>
<span id="cb67-17"><a href="#cb67-17" aria-hidden="true" tabindex="-1"></a>                                             <span class="kw">lambda</span> epoch: lr_decay <span class="op">**</span> epoch)</span>
<span id="cb67-18"><a href="#cb67-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-19"><a href="#cb67-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># sample minibatch data</span></span>
<span id="cb67-20"><a href="#cb67-20" aria-hidden="true" tabindex="-1"></a>  loss_history <span class="op">=</span> []</span>
<span id="cb67-21"><a href="#cb67-21" aria-hidden="true" tabindex="-1"></a>  detector.train()</span>
<span id="cb67-22"><a href="#cb67-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb67-23"><a href="#cb67-23" aria-hidden="true" tabindex="-1"></a>    start_t <span class="op">=</span> time.time()</span>
<span id="cb67-24"><a href="#cb67-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> iter_num, data_batch <span class="kw">in</span> <span class="bu">enumerate</span>(train_loader):</span>
<span id="cb67-25"><a href="#cb67-25" aria-hidden="true" tabindex="-1"></a>      images, boxes, w_batch, h_batch, _ <span class="op">=</span> data_batch</span>
<span id="cb67-26"><a href="#cb67-26" aria-hidden="true" tabindex="-1"></a>      resized_boxes <span class="op">=</span> coord_trans(boxes, w_batch, h_batch, mode<span class="op">=</span><span class="st">&#39;p2a&#39;</span>)</span>
<span id="cb67-27"><a href="#cb67-27" aria-hidden="true" tabindex="-1"></a>      images <span class="op">=</span> images.to(<span class="op">**</span>to_float_cuda)</span>
<span id="cb67-28"><a href="#cb67-28" aria-hidden="true" tabindex="-1"></a>      resized_boxes <span class="op">=</span> resized_boxes.to(<span class="op">**</span>to_float_cuda)</span>
<span id="cb67-29"><a href="#cb67-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-30"><a href="#cb67-30" aria-hidden="true" tabindex="-1"></a>      loss <span class="op">=</span> detector(images, resized_boxes)</span>
<span id="cb67-31"><a href="#cb67-31" aria-hidden="true" tabindex="-1"></a>      optimizer.zero_grad()</span>
<span id="cb67-32"><a href="#cb67-32" aria-hidden="true" tabindex="-1"></a>      loss.backward()</span>
<span id="cb67-33"><a href="#cb67-33" aria-hidden="true" tabindex="-1"></a>      loss_history.append(loss.item())</span>
<span id="cb67-34"><a href="#cb67-34" aria-hidden="true" tabindex="-1"></a>      optimizer.step()</span>
<span id="cb67-35"><a href="#cb67-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-36"><a href="#cb67-36" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(<span class="st">&#39;(Iter </span><span class="sc">{}</span><span class="st"> / </span><span class="sc">{}</span><span class="st">)&#39;</span>.<span class="bu">format</span>(iter_num, <span class="bu">len</span>(train_loader)))</span>
<span id="cb67-37"><a href="#cb67-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-38"><a href="#cb67-38" aria-hidden="true" tabindex="-1"></a>    end_t <span class="op">=</span> time.time()</span>
<span id="cb67-39"><a href="#cb67-39" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&#39;(Epoch </span><span class="sc">{}</span><span class="st"> / </span><span class="sc">{}</span><span class="st">) loss: </span><span class="sc">{:.4f}</span><span class="st"> time per epoch: </span><span class="sc">{:.1f}</span><span class="st">s&#39;</span>.<span class="bu">format</span>(</span>
<span id="cb67-40"><a href="#cb67-40" aria-hidden="true" tabindex="-1"></a>        i, num_epochs, loss.item(), end_t<span class="op">-</span>start_t))</span>
<span id="cb67-41"><a href="#cb67-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-42"><a href="#cb67-42" aria-hidden="true" tabindex="-1"></a>    lr_scheduler.step()</span>
<span id="cb67-43"><a href="#cb67-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-44"><a href="#cb67-44" aria-hidden="true" tabindex="-1"></a>  <span class="co"># plot the training losses</span></span>
<span id="cb67-45"><a href="#cb67-45" aria-hidden="true" tabindex="-1"></a>  plt.plot(loss_history)</span>
<span id="cb67-46"><a href="#cb67-46" aria-hidden="true" tabindex="-1"></a>  plt.xlabel(<span class="st">&#39;Iteration&#39;</span>)</span>
<span id="cb67-47"><a href="#cb67-47" aria-hidden="true" tabindex="-1"></a>  plt.ylabel(<span class="st">&#39;Loss&#39;</span>)</span>
<span id="cb67-48"><a href="#cb67-48" aria-hidden="true" tabindex="-1"></a>  plt.title(<span class="st">&#39;Training loss history&#39;</span>)</span>
<span id="cb67-49"><a href="#cb67-49" aria-hidden="true" tabindex="-1"></a>  plt.show()</span></code></pre></div>
</div>
<section id="overfit-small-data" class="cell markdown"
id="D-9nFPtLyDE_">
<h2>Overfit small data</h2>
<p>To make sure that everything is working as expected, we can try to
overfit the detector to a small subset of data.</p>
<p>After 200 epochs of training you should see a total loss of around or
less than 0.3.</p>
</section>
<div class="cell code" data-execution_count="43"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:10806}"
id="eNKLRL7HyHO0" data-outputId="14aac382-69f2-4f10-c235-5702cc931879">
<div class="sourceCode" id="cb68"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># monitor the training loss</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>fix_random_seed(<span class="dv">0</span>)</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>num_sample <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>small_dataset <span class="op">=</span> torch.utils.data.Subset(train_dataset, torch.linspace(<span class="dv">0</span>, <span class="bu">len</span>(train_dataset)<span class="op">-</span><span class="dv">1</span>, steps<span class="op">=</span>num_sample).<span class="bu">long</span>())</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>small_train_loader <span class="op">=</span> pascal_voc2007_loader(small_dataset, <span class="dv">10</span>) <span class="co"># a new loader</span></span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> lr <span class="kw">in</span> [<span class="fl">1e-2</span>]:</span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">&#39;lr: &#39;</span>, lr)</span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a>  detector <span class="op">=</span> SingleStageDetector()</span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a>  DetectionSolver(detector, small_train_loader, learning_rate<span class="op">=</span>lr, num_epochs<span class="op">=</span><span class="dv">200</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>lr:  0.01
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 0 / 200) loss: 4.6980 time per epoch: 0.3s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 1 / 200) loss: 3.3210 time per epoch: 0.2s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 2 / 200) loss: 2.7847 time per epoch: 0.2s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 3 / 200) loss: 2.2985 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 4 / 200) loss: 1.9676 time per epoch: 0.2s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 5 / 200) loss: 1.8208 time per epoch: 0.2s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 6 / 200) loss: 1.6559 time per epoch: 0.2s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 7 / 200) loss: 1.5891 time per epoch: 0.2s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 8 / 200) loss: 1.6032 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 9 / 200) loss: 1.4221 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 10 / 200) loss: 1.2913 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 11 / 200) loss: 1.3840 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 12 / 200) loss: 1.2488 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 13 / 200) loss: 1.2580 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 14 / 200) loss: 1.2994 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 15 / 200) loss: 1.0747 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 16 / 200) loss: 1.0605 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 17 / 200) loss: 1.0460 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 18 / 200) loss: 1.0366 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 19 / 200) loss: 1.0823 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 20 / 200) loss: 0.8831 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 21 / 200) loss: 0.8917 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 22 / 200) loss: 0.8678 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 23 / 200) loss: 0.8315 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 24 / 200) loss: 1.0137 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 25 / 200) loss: 0.9317 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 26 / 200) loss: 0.8861 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 27 / 200) loss: 0.8030 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 28 / 200) loss: 0.9057 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 29 / 200) loss: 0.8698 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 30 / 200) loss: 0.7764 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 31 / 200) loss: 0.7410 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 32 / 200) loss: 0.7463 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 33 / 200) loss: 0.7800 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 34 / 200) loss: 0.7177 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 35 / 200) loss: 0.6912 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 36 / 200) loss: 0.6830 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 37 / 200) loss: 0.6588 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 38 / 200) loss: 0.6691 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 39 / 200) loss: 0.7341 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 40 / 200) loss: 0.6291 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 41 / 200) loss: 0.6598 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 42 / 200) loss: 0.6186 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 43 / 200) loss: 0.6766 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 44 / 200) loss: 0.5686 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 45 / 200) loss: 0.6807 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 46 / 200) loss: 0.6317 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 47 / 200) loss: 0.5952 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 48 / 200) loss: 0.5647 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 49 / 200) loss: 0.6221 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 50 / 200) loss: 0.6759 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 51 / 200) loss: 0.5141 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 52 / 200) loss: 0.5408 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 53 / 200) loss: 0.5653 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 54 / 200) loss: 0.5693 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 55 / 200) loss: 0.5842 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 56 / 200) loss: 0.5288 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 57 / 200) loss: 0.5279 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 58 / 200) loss: 0.5940 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 59 / 200) loss: 0.5218 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 60 / 200) loss: 0.5849 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 61 / 200) loss: 0.4761 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 62 / 200) loss: 0.4785 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 63 / 200) loss: 0.5279 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 64 / 200) loss: 0.4630 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 65 / 200) loss: 0.4545 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 66 / 200) loss: 0.5218 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 67 / 200) loss: 0.4959 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 68 / 200) loss: 0.4445 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 69 / 200) loss: 0.5377 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 70 / 200) loss: 0.5019 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 71 / 200) loss: 0.5213 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 72 / 200) loss: 0.4856 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 73 / 200) loss: 0.4138 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 74 / 200) loss: 0.5137 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 75 / 200) loss: 0.3823 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 76 / 200) loss: 0.3982 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 77 / 200) loss: 0.3974 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 78 / 200) loss: 0.4158 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 79 / 200) loss: 0.4389 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 80 / 200) loss: 0.3709 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 81 / 200) loss: 0.3929 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 82 / 200) loss: 0.4364 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 83 / 200) loss: 0.4067 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 84 / 200) loss: 0.4279 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 85 / 200) loss: 0.3791 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 86 / 200) loss: 0.4162 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 87 / 200) loss: 0.3555 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 88 / 200) loss: 0.4072 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 89 / 200) loss: 0.3606 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 90 / 200) loss: 0.4634 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 91 / 200) loss: 0.4365 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 92 / 200) loss: 0.4034 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 93 / 200) loss: 0.3693 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 94 / 200) loss: 0.4072 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 95 / 200) loss: 0.3968 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 96 / 200) loss: 0.3696 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 97 / 200) loss: 0.3849 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 98 / 200) loss: 0.4583 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 99 / 200) loss: 0.4224 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 100 / 200) loss: 0.4054 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 101 / 200) loss: 0.4080 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 102 / 200) loss: 0.4304 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 103 / 200) loss: 0.4020 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 104 / 200) loss: 0.3899 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 105 / 200) loss: 0.3639 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 106 / 200) loss: 0.3900 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 107 / 200) loss: 0.3882 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 108 / 200) loss: 0.3397 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 109 / 200) loss: 0.3747 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 110 / 200) loss: 0.3508 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 111 / 200) loss: 0.3906 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 112 / 200) loss: 0.3648 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 113 / 200) loss: 0.3626 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 114 / 200) loss: 0.3967 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 115 / 200) loss: 0.3168 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 116 / 200) loss: 0.3318 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 117 / 200) loss: 0.3617 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 118 / 200) loss: 0.3659 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 119 / 200) loss: 0.3451 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 120 / 200) loss: 0.3300 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 121 / 200) loss: 0.3156 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 122 / 200) loss: 0.3771 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 123 / 200) loss: 0.3884 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 124 / 200) loss: 0.3686 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 125 / 200) loss: 0.3421 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 126 / 200) loss: 0.3210 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 127 / 200) loss: 0.3747 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 128 / 200) loss: 0.3167 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 129 / 200) loss: 0.3726 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 130 / 200) loss: 0.3343 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 131 / 200) loss: 0.3200 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 132 / 200) loss: 0.2968 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 133 / 200) loss: 0.3640 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 134 / 200) loss: 0.3195 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 135 / 200) loss: 0.3356 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 136 / 200) loss: 0.3175 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 137 / 200) loss: 0.2927 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 138 / 200) loss: 0.3498 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 139 / 200) loss: 0.3361 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 140 / 200) loss: 0.3063 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 141 / 200) loss: 0.3048 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 142 / 200) loss: 0.3559 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 143 / 200) loss: 0.3004 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 144 / 200) loss: 0.2678 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 145 / 200) loss: 0.3132 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 146 / 200) loss: 0.2815 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 147 / 200) loss: 0.2947 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 148 / 200) loss: 0.2794 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 149 / 200) loss: 0.2910 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 150 / 200) loss: 0.3397 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 151 / 200) loss: 0.3627 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 152 / 200) loss: 0.3152 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 153 / 200) loss: 0.3305 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 154 / 200) loss: 0.3132 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 155 / 200) loss: 0.2490 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 156 / 200) loss: 0.2823 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 157 / 200) loss: 0.2810 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 158 / 200) loss: 0.2704 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 159 / 200) loss: 0.2710 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 160 / 200) loss: 0.2959 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 161 / 200) loss: 0.2779 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 162 / 200) loss: 0.2537 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 163 / 200) loss: 0.2840 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 164 / 200) loss: 0.2863 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 165 / 200) loss: 0.2720 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 166 / 200) loss: 0.2418 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 167 / 200) loss: 0.2736 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 168 / 200) loss: 0.2744 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 169 / 200) loss: 0.3039 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 170 / 200) loss: 0.2833 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 171 / 200) loss: 0.2563 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 172 / 200) loss: 0.2420 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 173 / 200) loss: 0.2686 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 174 / 200) loss: 0.2648 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 175 / 200) loss: 0.2719 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 176 / 200) loss: 0.2754 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 177 / 200) loss: 0.2919 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 178 / 200) loss: 0.2604 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 179 / 200) loss: 0.2733 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 180 / 200) loss: 0.2585 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 181 / 200) loss: 0.2893 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 182 / 200) loss: 0.2842 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 183 / 200) loss: 0.2753 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 184 / 200) loss: 0.2433 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 185 / 200) loss: 0.2241 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 186 / 200) loss: 0.2737 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 187 / 200) loss: 0.2552 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 188 / 200) loss: 0.2508 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 189 / 200) loss: 0.2644 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 190 / 200) loss: 0.2563 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 191 / 200) loss: 0.2773 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 192 / 200) loss: 0.2521 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 193 / 200) loss: 0.3123 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 194 / 200) loss: 0.2467 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 195 / 200) loss: 0.2631 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 196 / 200) loss: 0.2188 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 197 / 200) loss: 0.2383 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 198 / 200) loss: 0.2741 time per epoch: 0.1s
number of pos proposals:  50
(Iter 0 / 1)
(Epoch 199 / 200) loss: 0.2392 time per epoch: 0.1s
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/0a88716398c57767b2f366ef4d69fbf50853943e.png" /></p>
</div>
</div>
<section id="train-a-net" class="cell markdown" id="CuSBfcGWyHlD">
<h2>Train a net</h2>
<p>Now that we are confident that the training code is working properly,
let's train the network on more data and for longer. We will train for
50 epochs; this should take about 20 minutes on a T4 GPU on Google
Colab. You should see a total loss around or less than 0.3.</p>
<p>Note that real object detection systems typically train for 12-24
hours and distribute training over multiple GPUs. As such our result
will be far from the state of the art, but it should give some
reasonable results!</p>
</section>
<div class="cell code" data-execution_count="44"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:44634}"
id="Aipf7-XQyJ28" data-outputId="6c25330a-51c8-4138-ac2a-ca9697b6fa55">
<div class="sourceCode" id="cb70"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># monitor the training loss</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> pascal_voc2007_loader(train_dataset, <span class="dv">100</span>) <span class="co"># a new loader</span></span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">5e-2</span></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>yolo_detector <span class="op">=</span> SingleStageDetector()</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>DetectionSolver(yolo_detector, train_loader, learning_rate<span class="op">=</span>lr, num_epochs<span class="op">=</span>num_epochs)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 0 / 50) loss: 2.2777 time per epoch: 23.9s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 1 / 50) loss: 1.6184 time per epoch: 24.4s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 2 / 50) loss: 1.2138 time per epoch: 24.4s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 3 / 50) loss: 1.0620 time per epoch: 25.2s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 4 / 50) loss: 0.8175 time per epoch: 25.1s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 5 / 50) loss: 0.7697 time per epoch: 24.1s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 6 / 50) loss: 0.7132 time per epoch: 23.9s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 7 / 50) loss: 0.6989 time per epoch: 24.0s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 8 / 50) loss: 0.5361 time per epoch: 24.1s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 9 / 50) loss: 0.5025 time per epoch: 24.3s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 10 / 50) loss: 0.4479 time per epoch: 24.1s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 11 / 50) loss: 0.4272 time per epoch: 24.1s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 12 / 50) loss: 0.4013 time per epoch: 24.4s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 13 / 50) loss: 0.4218 time per epoch: 24.0s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 14 / 50) loss: 0.3555 time per epoch: 23.9s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 15 / 50) loss: 0.3835 time per epoch: 23.7s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 16 / 50) loss: 0.3323 time per epoch: 23.1s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 17 / 50) loss: 0.3146 time per epoch: 24.3s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 18 / 50) loss: 0.3028 time per epoch: 24.6s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 19 / 50) loss: 0.3134 time per epoch: 24.8s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 20 / 50) loss: 0.2833 time per epoch: 25.3s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 21 / 50) loss: 0.3127 time per epoch: 25.8s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 22 / 50) loss: 0.2776 time per epoch: 25.3s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 23 / 50) loss: 0.2616 time per epoch: 25.1s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 24 / 50) loss: 0.2546 time per epoch: 25.2s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 25 / 50) loss: 0.2417 time per epoch: 25.0s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 26 / 50) loss: 0.2528 time per epoch: 24.8s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 27 / 50) loss: 0.2227 time per epoch: 24.9s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 28 / 50) loss: 0.2639 time per epoch: 24.4s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 29 / 50) loss: 0.2184 time per epoch: 25.2s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 30 / 50) loss: 0.2236 time per epoch: 24.6s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 31 / 50) loss: 0.2314 time per epoch: 24.7s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 32 / 50) loss: 0.2030 time per epoch: 24.8s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 33 / 50) loss: 0.2184 time per epoch: 24.4s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 34 / 50) loss: 0.1934 time per epoch: 24.4s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 35 / 50) loss: 0.2298 time per epoch: 24.2s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 36 / 50) loss: 0.1882 time per epoch: 24.2s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 37 / 50) loss: 0.1878 time per epoch: 24.7s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 38 / 50) loss: 0.2066 time per epoch: 24.1s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 39 / 50) loss: 0.1831 time per epoch: 24.2s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 40 / 50) loss: 0.1771 time per epoch: 24.2s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 41 / 50) loss: 0.1927 time per epoch: 24.2s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 42 / 50) loss: 0.1815 time per epoch: 24.3s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 43 / 50) loss: 0.2165 time per epoch: 26.1s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 44 / 50) loss: 0.1541 time per epoch: 29.5s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 45 / 50) loss: 0.1909 time per epoch: 25.4s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 46 / 50) loss: 0.1727 time per epoch: 25.0s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 47 / 50) loss: 0.1586 time per epoch: 25.5s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 48 / 50) loss: 0.1565 time per epoch: 24.6s
number of pos proposals:  348
(Iter 0 / 25)
number of pos proposals:  410
(Iter 1 / 25)
number of pos proposals:  375
(Iter 2 / 25)
number of pos proposals:  362
(Iter 3 / 25)
number of pos proposals:  348
(Iter 4 / 25)
number of pos proposals:  316
(Iter 5 / 25)
number of pos proposals:  379
(Iter 6 / 25)
number of pos proposals:  362
(Iter 7 / 25)
number of pos proposals:  368
(Iter 8 / 25)
number of pos proposals:  363
(Iter 9 / 25)
number of pos proposals:  325
(Iter 10 / 25)
number of pos proposals:  355
(Iter 11 / 25)
number of pos proposals:  346
(Iter 12 / 25)
number of pos proposals:  363
(Iter 13 / 25)
number of pos proposals:  357
(Iter 14 / 25)
number of pos proposals:  349
(Iter 15 / 25)
number of pos proposals:  370
(Iter 16 / 25)
number of pos proposals:  367
(Iter 17 / 25)
number of pos proposals:  395
(Iter 18 / 25)
number of pos proposals:  386
(Iter 19 / 25)
number of pos proposals:  392
(Iter 20 / 25)
number of pos proposals:  405
(Iter 21 / 25)
number of pos proposals:  335
(Iter 22 / 25)
number of pos proposals:  359
(Iter 23 / 25)
number of pos proposals:  376
(Iter 24 / 25)
(Epoch 49 / 50) loss: 0.2039 time per epoch: 24.8s
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/b869b593173269d0f7f4d098b6857701855e3930.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="45" id="j_K7nL8eviXV">
<div class="sourceCode" id="cb72"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># (optional) load/save checkpoint</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="co"># torch.save(yolo_detector.state_dict(), &#39;yolo_detector.pt&#39;) # uncomment to save your checkpoint</span></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a><span class="co"># yolo_detector.load_state_dict(torch.load(&#39;yolo_detector.pt&#39;)) # uncomment to load your previous checkpoint</span></span></code></pre></div>
</div>
<section id="use-an-object-detector" class="cell markdown"
id="xzU71hc_y9Ij">
<h1>Use an object detector</h1>
</section>
<section id="thresholding" class="cell markdown" id="TxwNNfV-zLkJ">
<h2>Thresholding</h2>
<p>We will implement this in the object detection module.</p>
</section>
<section id="non-maximum-suppression-nms" class="cell markdown"
id="e42TAEcpjeKW">
<h2>Non-Maximum Suppression (NMS)</h2>
<p>The definition of NMS and instructions on how to compute NMS can be
found in the lecture slides.</p>
</section>
<div class="cell code" data-execution_count="46" id="zeWgWrzfYgm_">
<div class="sourceCode" id="cb73"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> nms(boxes, scores, iou_threshold<span class="op">=</span><span class="fl">0.5</span>, topk<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a><span class="co">  Non-maximum suppression removes overlapping bounding boxes.</span></span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a><span class="co">  Inputs:</span></span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a><span class="co">  - boxes: top-left and bottom-right coordinate values of the bounding boxes</span></span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a><span class="co">    to perform NMS on, of shape Nx4</span></span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a><span class="co">  - scores: scores for each one of the boxes, of shape N</span></span>
<span id="cb73-9"><a href="#cb73-9" aria-hidden="true" tabindex="-1"></a><span class="co">  - iou_threshold: discards all overlapping boxes with IoU &gt; iou_threshold; float</span></span>
<span id="cb73-10"><a href="#cb73-10" aria-hidden="true" tabindex="-1"></a><span class="co">  - topk: If this is not None, then return only the topk highest-scoring boxes.</span></span>
<span id="cb73-11"><a href="#cb73-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Otherwise if this is None, then return all boxes that pass NMS.</span></span>
<span id="cb73-12"><a href="#cb73-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-13"><a href="#cb73-13" aria-hidden="true" tabindex="-1"></a><span class="co">  Outputs:</span></span>
<span id="cb73-14"><a href="#cb73-14" aria-hidden="true" tabindex="-1"></a><span class="co">  - keep: torch.long tensor with the indices of the elements that have been</span></span>
<span id="cb73-15"><a href="#cb73-15" aria-hidden="true" tabindex="-1"></a><span class="co">    kept by NMS, sorted in decreasing order of scores; of shape [num_kept_boxes]</span></span>
<span id="cb73-16"><a href="#cb73-16" aria-hidden="true" tabindex="-1"></a><span class="co">  &quot;&quot;&quot;</span></span>
<span id="cb73-17"><a href="#cb73-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-18"><a href="#cb73-18" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="kw">not</span> boxes.numel()) <span class="kw">or</span> (<span class="kw">not</span> scores.numel()):</span>
<span id="cb73-19"><a href="#cb73-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.zeros(<span class="dv">0</span>, dtype<span class="op">=</span>torch.<span class="bu">long</span>, device<span class="op">=</span>boxes.device)</span>
<span id="cb73-20"><a href="#cb73-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-21"><a href="#cb73-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sort boxes by scores in descending order</span></span>
<span id="cb73-22"><a href="#cb73-22" aria-hidden="true" tabindex="-1"></a>  order <span class="op">=</span> scores.sort(descending<span class="op">=</span><span class="va">True</span>)[<span class="dv">1</span>]</span>
<span id="cb73-23"><a href="#cb73-23" aria-hidden="true" tabindex="-1"></a>  keep <span class="op">=</span> []  <span class="co"># List to store indices of boxes to keep</span></span>
<span id="cb73-24"><a href="#cb73-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-25"><a href="#cb73-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Iterate until there are no boxes left</span></span>
<span id="cb73-26"><a href="#cb73-26" aria-hidden="true" tabindex="-1"></a>  <span class="cf">while</span> order.numel() <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb73-27"><a href="#cb73-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. Select the highest-scoring box among the remaining ones,</span></span>
<span id="cb73-28"><a href="#cb73-28" aria-hidden="true" tabindex="-1"></a>    <span class="co">#    which has not been chosen in this step before.</span></span>
<span id="cb73-29"><a href="#cb73-29" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> order[<span class="dv">0</span>].item()</span>
<span id="cb73-30"><a href="#cb73-30" aria-hidden="true" tabindex="-1"></a>    keep.append(i)</span>
<span id="cb73-31"><a href="#cb73-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-32"><a href="#cb73-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> order.numel() <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb73-33"><a href="#cb73-33" aria-hidden="true" tabindex="-1"></a>      <span class="cf">break</span></span>
<span id="cb73-34"><a href="#cb73-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-35"><a href="#cb73-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute IoU of the selected box with the rest</span></span>
<span id="cb73-36"><a href="#cb73-36" aria-hidden="true" tabindex="-1"></a>    current_box <span class="op">=</span> boxes[i].unsqueeze(<span class="dv">0</span>)         <span class="co"># shape (1,4)</span></span>
<span id="cb73-37"><a href="#cb73-37" aria-hidden="true" tabindex="-1"></a>    other_boxes <span class="op">=</span> boxes[order[<span class="dv">1</span>:]]                <span class="co"># shape (N-1,4)</span></span>
<span id="cb73-38"><a href="#cb73-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-39"><a href="#cb73-39" aria-hidden="true" tabindex="-1"></a>    xx1 <span class="op">=</span> torch.<span class="bu">max</span>(current_box[:, <span class="dv">0</span>], other_boxes[:, <span class="dv">0</span>])</span>
<span id="cb73-40"><a href="#cb73-40" aria-hidden="true" tabindex="-1"></a>    yy1 <span class="op">=</span> torch.<span class="bu">max</span>(current_box[:, <span class="dv">1</span>], other_boxes[:, <span class="dv">1</span>])</span>
<span id="cb73-41"><a href="#cb73-41" aria-hidden="true" tabindex="-1"></a>    xx2 <span class="op">=</span> torch.<span class="bu">min</span>(current_box[:, <span class="dv">2</span>], other_boxes[:, <span class="dv">2</span>])</span>
<span id="cb73-42"><a href="#cb73-42" aria-hidden="true" tabindex="-1"></a>    yy2 <span class="op">=</span> torch.<span class="bu">min</span>(current_box[:, <span class="dv">3</span>], other_boxes[:, <span class="dv">3</span>])</span>
<span id="cb73-43"><a href="#cb73-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-44"><a href="#cb73-44" aria-hidden="true" tabindex="-1"></a>    inter_w <span class="op">=</span> (xx2 <span class="op">-</span> xx1).clamp(<span class="bu">min</span><span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb73-45"><a href="#cb73-45" aria-hidden="true" tabindex="-1"></a>    inter_h <span class="op">=</span> (yy2 <span class="op">-</span> yy1).clamp(<span class="bu">min</span><span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb73-46"><a href="#cb73-46" aria-hidden="true" tabindex="-1"></a>    inter_area <span class="op">=</span> inter_w <span class="op">*</span> inter_h</span>
<span id="cb73-47"><a href="#cb73-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-48"><a href="#cb73-48" aria-hidden="true" tabindex="-1"></a>    area_current <span class="op">=</span> ((current_box[:, <span class="dv">2</span>] <span class="op">-</span> current_box[:, <span class="dv">0</span>]) <span class="op">*</span></span>
<span id="cb73-49"><a href="#cb73-49" aria-hidden="true" tabindex="-1"></a>                    (current_box[:, <span class="dv">3</span>] <span class="op">-</span> current_box[:, <span class="dv">1</span>])).squeeze(<span class="dv">0</span>)</span>
<span id="cb73-50"><a href="#cb73-50" aria-hidden="true" tabindex="-1"></a>    area_others <span class="op">=</span> ((other_boxes[:, <span class="dv">2</span>] <span class="op">-</span> other_boxes[:, <span class="dv">0</span>]) <span class="op">*</span></span>
<span id="cb73-51"><a href="#cb73-51" aria-hidden="true" tabindex="-1"></a>                   (other_boxes[:, <span class="dv">3</span>] <span class="op">-</span> other_boxes[:, <span class="dv">1</span>]))</span>
<span id="cb73-52"><a href="#cb73-52" aria-hidden="true" tabindex="-1"></a>    union_area <span class="op">=</span> area_current <span class="op">+</span> area_others <span class="op">-</span> inter_area</span>
<span id="cb73-53"><a href="#cb73-53" aria-hidden="true" tabindex="-1"></a>    iou <span class="op">=</span> inter_area <span class="op">/</span> union_area</span>
<span id="cb73-54"><a href="#cb73-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-55"><a href="#cb73-55" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. Eliminate boxes with IoU &gt; threshold</span></span>
<span id="cb73-56"><a href="#cb73-56" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Using as_tuple=True returns a 1D tensor of indices.</span></span>
<span id="cb73-57"><a href="#cb73-57" aria-hidden="true" tabindex="-1"></a>    inds <span class="op">=</span> (iou <span class="op">&lt;=</span> iou_threshold).nonzero(as_tuple<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>]</span>
<span id="cb73-58"><a href="#cb73-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-59"><a href="#cb73-59" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> inds.numel() <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb73-60"><a href="#cb73-60" aria-hidden="true" tabindex="-1"></a>      <span class="cf">break</span></span>
<span id="cb73-61"><a href="#cb73-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-62"><a href="#cb73-62" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Update order: skip the selected box and boxes with high IoU overlap</span></span>
<span id="cb73-63"><a href="#cb73-63" aria-hidden="true" tabindex="-1"></a>    order <span class="op">=</span> order[inds <span class="op">+</span> <span class="dv">1</span>]  <span class="co"># +1 because order[0] was current_box</span></span>
<span id="cb73-64"><a href="#cb73-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-65"><a href="#cb73-65" aria-hidden="true" tabindex="-1"></a>  keep <span class="op">=</span> torch.tensor(keep, dtype<span class="op">=</span>torch.<span class="bu">long</span>, device<span class="op">=</span>boxes.device)</span>
<span id="cb73-66"><a href="#cb73-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-67"><a href="#cb73-67" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 3. If any boxes remain, GOTO 1 (handled by the while loop)</span></span>
<span id="cb73-68"><a href="#cb73-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-69"><a href="#cb73-69" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> topk <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb73-70"><a href="#cb73-70" aria-hidden="true" tabindex="-1"></a>    keep <span class="op">=</span> keep[:topk]</span>
<span id="cb73-71"><a href="#cb73-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-72"><a href="#cb73-72" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> keep</span></code></pre></div>
</div>
<div class="cell markdown" id="hq1biRRs6Rqf">
<p>We will now compare your implementation of NMS with the
implementation in torchvision. Most likely, your implementation will be
faster on CPU than on CUDA, and the torchvision implementation will
likely be much faster than yours. This is expected, but your
implementation should produce the same outputs as the torchvision
version.</p>
</div>
<div class="cell code" data-execution_count="47"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:0}"
id="wqXkUdvdHh-U" data-outputId="74d931cc-fbf3-4f00-a054-aaf36401f425">
<div class="sourceCode" id="cb74"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>fix_random_seed(<span class="dv">0</span>)</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>boxes <span class="op">=</span> (<span class="fl">100.</span> <span class="op">*</span> torch.rand(<span class="dv">5000</span>, <span class="dv">4</span>)).<span class="bu">round</span>()</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>boxes[:,<span class="dv">2</span>] <span class="op">=</span> boxes[:,<span class="dv">2</span>] <span class="op">+</span> boxes[:,<span class="dv">0</span>] <span class="op">+</span> <span class="fl">1.</span></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>boxes[:,<span class="dv">3</span>] <span class="op">=</span> boxes[:,<span class="dv">3</span>] <span class="op">+</span> boxes[:,<span class="dv">1</span>] <span class="op">+</span> <span class="fl">1.</span></span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> torch.randn(<span class="dv">5000</span>)</span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a>names <span class="op">=</span> [<span class="st">&#39;your_cpu&#39;</span>, <span class="st">&#39;torchvision_cpu&#39;</span>, <span class="st">&#39;torchvision_cuda&#39;</span>]</span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a>iou_thresholds <span class="op">=</span> [<span class="fl">0.3</span>, <span class="fl">0.5</span>, <span class="fl">0.7</span>]</span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a>elapsed <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">zip</span>(names, [<span class="fl">0.</span>]<span class="op">*</span><span class="bu">len</span>(names)))</span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a>intersects <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">zip</span>(names[<span class="dv">1</span>:], [<span class="fl">0.</span>]<span class="op">*</span>(<span class="bu">len</span>(names)<span class="op">-</span><span class="dv">1</span>)))</span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-12"><a href="#cb74-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> iou_threshold <span class="kw">in</span> iou_thresholds:</span>
<span id="cb74-13"><a href="#cb74-13" aria-hidden="true" tabindex="-1"></a>  tic <span class="op">=</span> time.time()</span>
<span id="cb74-14"><a href="#cb74-14" aria-hidden="true" tabindex="-1"></a>  my_keep <span class="op">=</span> nms(boxes, scores, iou_threshold)</span>
<span id="cb74-15"><a href="#cb74-15" aria-hidden="true" tabindex="-1"></a>  elapsed[<span class="st">&#39;your_cpu&#39;</span>] <span class="op">+=</span> time.time() <span class="op">-</span> tic</span>
<span id="cb74-16"><a href="#cb74-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-17"><a href="#cb74-17" aria-hidden="true" tabindex="-1"></a>  tic <span class="op">=</span> time.time()</span>
<span id="cb74-18"><a href="#cb74-18" aria-hidden="true" tabindex="-1"></a>  tv_keep <span class="op">=</span> torchvision.ops.nms(boxes, scores, iou_threshold)</span>
<span id="cb74-19"><a href="#cb74-19" aria-hidden="true" tabindex="-1"></a>  elapsed[<span class="st">&#39;torchvision_cpu&#39;</span>] <span class="op">+=</span> time.time() <span class="op">-</span> tic</span>
<span id="cb74-20"><a href="#cb74-20" aria-hidden="true" tabindex="-1"></a>  intersect <span class="op">=</span> <span class="bu">len</span>(<span class="bu">set</span>(tv_keep.tolist()).intersection(my_keep.tolist()))</span>
<span id="cb74-21"><a href="#cb74-21" aria-hidden="true" tabindex="-1"></a>  intersects[<span class="st">&#39;torchvision_cpu&#39;</span>] <span class="op">+=</span> intersect <span class="op">/</span> (<span class="bu">len</span>(my_keep) <span class="op">+</span> <span class="bu">len</span>(tv_keep) <span class="op">-</span> intersect)</span>
<span id="cb74-22"><a href="#cb74-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-23"><a href="#cb74-23" aria-hidden="true" tabindex="-1"></a>  tic <span class="op">=</span> time.time()</span>
<span id="cb74-24"><a href="#cb74-24" aria-hidden="true" tabindex="-1"></a>  tv_cuda_keep <span class="op">=</span> torchvision.ops.nms(boxes.cuda(), scores.cuda(), iou_threshold).to(my_keep.device)</span>
<span id="cb74-25"><a href="#cb74-25" aria-hidden="true" tabindex="-1"></a>  torch.cuda.synchronize()</span>
<span id="cb74-26"><a href="#cb74-26" aria-hidden="true" tabindex="-1"></a>  elapsed[<span class="st">&#39;torchvision_cuda&#39;</span>] <span class="op">+=</span> time.time() <span class="op">-</span> tic</span>
<span id="cb74-27"><a href="#cb74-27" aria-hidden="true" tabindex="-1"></a>  intersect <span class="op">=</span> <span class="bu">len</span>(<span class="bu">set</span>(tv_cuda_keep.tolist()).intersection(my_keep.tolist()))</span>
<span id="cb74-28"><a href="#cb74-28" aria-hidden="true" tabindex="-1"></a>  intersects[<span class="st">&#39;torchvision_cuda&#39;</span>] <span class="op">+=</span> intersect <span class="op">/</span> (<span class="bu">len</span>(my_keep) <span class="op">+</span> <span class="bu">len</span>(tv_cuda_keep) <span class="op">-</span> intersect)</span>
<span id="cb74-29"><a href="#cb74-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-30"><a href="#cb74-30" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> key <span class="kw">in</span> intersects:</span>
<span id="cb74-31"><a href="#cb74-31" aria-hidden="true" tabindex="-1"></a>  intersects[key] <span class="op">/=</span> <span class="bu">len</span>(iou_thresholds)</span>
<span id="cb74-32"><a href="#cb74-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-33"><a href="#cb74-33" aria-hidden="true" tabindex="-1"></a><span class="co"># You should see &lt; 1% difference</span></span>
<span id="cb74-34"><a href="#cb74-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Testing NMS:&#39;</span>)</span>
<span id="cb74-35"><a href="#cb74-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Your        CPU  implementation: </span><span class="sc">%f</span><span class="st">s&#39;</span> <span class="op">%</span> elapsed[<span class="st">&#39;your_cpu&#39;</span>])</span>
<span id="cb74-36"><a href="#cb74-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;torchvision CPU  implementation: </span><span class="sc">%f</span><span class="st">s&#39;</span> <span class="op">%</span> elapsed[<span class="st">&#39;torchvision_cpu&#39;</span>])</span>
<span id="cb74-37"><a href="#cb74-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;torchvision CUDA implementation: </span><span class="sc">%f</span><span class="st">s&#39;</span> <span class="op">%</span> elapsed[<span class="st">&#39;torchvision_cuda&#39;</span>])</span>
<span id="cb74-38"><a href="#cb74-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Speedup CPU : </span><span class="sc">%f</span><span class="st">x&#39;</span> <span class="op">%</span> (elapsed[<span class="st">&#39;your_cpu&#39;</span>] <span class="op">/</span> elapsed[<span class="st">&#39;torchvision_cpu&#39;</span>]))</span>
<span id="cb74-39"><a href="#cb74-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Speedup CUDA: </span><span class="sc">%f</span><span class="st">x&#39;</span> <span class="op">%</span> (elapsed[<span class="st">&#39;your_cpu&#39;</span>] <span class="op">/</span> elapsed[<span class="st">&#39;torchvision_cuda&#39;</span>]))</span>
<span id="cb74-40"><a href="#cb74-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Difference CPU : &#39;</span>, <span class="fl">1.</span> <span class="op">-</span> intersects[<span class="st">&#39;torchvision_cpu&#39;</span>]) <span class="co"># in the order of 1e-3 or less</span></span>
<span id="cb74-41"><a href="#cb74-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Difference CUDA: &#39;</span>, <span class="fl">1.</span> <span class="op">-</span> intersects[<span class="st">&#39;torchvision_cuda&#39;</span>]) <span class="co"># in the order of 1e-3 or less</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Testing NMS:
Your        CPU  implementation: 1.724136s
torchvision CPU  implementation: 0.097128s
torchvision CUDA implementation: 0.011653s
Speedup CPU : 17.751147x
Speedup CUDA: 147.951041x
Difference CPU :  0.003150598613736566
Difference CUDA:  0.0
</code></pre>
</div>
</div>
<section id="inference" class="cell markdown" id="9JSTPMsqzEnr">
<h2>Inference</h2>
</section>
<div class="cell markdown" id="d97pmEHLSDyK">
<p>Now, implement the inference part of module
<code>SingleStageDetector</code>.</p>
</div>
<div class="cell code" data-execution_count="48" id="wqc-YGmOSG2Y">
<div class="sourceCode" id="cb76"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> detector_inference(<span class="va">self</span>, images, thresh<span class="op">=</span><span class="fl">0.5</span>, nms_thresh<span class="op">=</span><span class="fl">0.7</span>):</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a><span class="co">  Inference-time forward pass for the single stage detector.</span></span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a><span class="co">  Inputs:</span></span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a><span class="co">  - images: Input images</span></span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - thresh: Threshold value on confidence scores</span></span>
<span id="cb76-8"><a href="#cb76-8" aria-hidden="true" tabindex="-1"></a><span class="co">  - nms_thresh: Threshold value on NMS</span></span>
<span id="cb76-9"><a href="#cb76-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-10"><a href="#cb76-10" aria-hidden="true" tabindex="-1"></a><span class="co">  Outputs:</span></span>
<span id="cb76-11"><a href="#cb76-11" aria-hidden="true" tabindex="-1"></a><span class="co">  - final_proposals: Kept proposals after confidence score thresholding and NMS,</span></span>
<span id="cb76-12"><a href="#cb76-12" aria-hidden="true" tabindex="-1"></a><span class="co">                       a list of B (num_proposals x 4) tensors</span></span>
<span id="cb76-13"><a href="#cb76-13" aria-hidden="true" tabindex="-1"></a><span class="co">  - final_conf_scores: Corresponding confidence scores, a list of B (num_proposals x 1) tensors</span></span>
<span id="cb76-14"><a href="#cb76-14" aria-hidden="true" tabindex="-1"></a><span class="co">  - final_class: Corresponding class predictions, a list of B (num_proposals x 1) tensors</span></span>
<span id="cb76-15"><a href="#cb76-15" aria-hidden="true" tabindex="-1"></a><span class="co">  &quot;&quot;&quot;</span></span>
<span id="cb76-16"><a href="#cb76-16" aria-hidden="true" tabindex="-1"></a>  final_proposals, final_conf_scores, final_class <span class="op">=</span> [], [], []</span>
<span id="cb76-17"><a href="#cb76-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-18"><a href="#cb76-18" aria-hidden="true" tabindex="-1"></a>  <span class="co"># i) Extract image features from the backbone.</span></span>
<span id="cb76-19"><a href="#cb76-19" aria-hidden="true" tabindex="-1"></a>  features <span class="op">=</span> <span class="va">self</span>.feat_extractor(images)  <span class="co"># Assume shape (B, in_dim, 7, 7)</span></span>
<span id="cb76-20"><a href="#cb76-20" aria-hidden="true" tabindex="-1"></a>  B <span class="op">=</span> images.shape[<span class="dv">0</span>]</span>
<span id="cb76-21"><a href="#cb76-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-22"><a href="#cb76-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># ii) Generate grid and anchors.</span></span>
<span id="cb76-23"><a href="#cb76-23" aria-hidden="true" tabindex="-1"></a>  grid <span class="op">=</span> GenerateGrid(B, dtype<span class="op">=</span>images.dtype, device<span class="op">=</span>images.device)  <span class="co"># (B, H&#39;, W&#39;, 2)</span></span>
<span id="cb76-24"><a href="#cb76-24" aria-hidden="true" tabindex="-1"></a>  anchors <span class="op">=</span> GenerateAnchor(<span class="va">self</span>.anchor_list, grid)  <span class="co"># (B, A, H&#39;, W&#39;, 4)</span></span>
<span id="cb76-25"><a href="#cb76-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-26"><a href="#cb76-26" aria-hidden="true" tabindex="-1"></a>  <span class="co"># iii) Get predictions from the prediction network.</span></span>
<span id="cb76-27"><a href="#cb76-27" aria-hidden="true" tabindex="-1"></a>  <span class="co"># In inference mode, pred_network returns:</span></span>
<span id="cb76-28"><a href="#cb76-28" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   - conf_scores: (B, A, H&#39;, W&#39;) after sigmoid,</span></span>
<span id="cb76-29"><a href="#cb76-29" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   - offsets: (B, A, 4, H&#39;, W&#39;),</span></span>
<span id="cb76-30"><a href="#cb76-30" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   - class_scores: (B, C, H&#39;, W&#39;)</span></span>
<span id="cb76-31"><a href="#cb76-31" aria-hidden="true" tabindex="-1"></a>  conf_scores, offsets, class_scores <span class="op">=</span> <span class="va">self</span>.pred_network(features)</span>
<span id="cb76-32"><a href="#cb76-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-33"><a href="#cb76-33" aria-hidden="true" tabindex="-1"></a>  <span class="co"># iv) Generate proposals by applying predicted offsets to anchors.</span></span>
<span id="cb76-34"><a href="#cb76-34" aria-hidden="true" tabindex="-1"></a>  proposals <span class="op">=</span> GenerateProposal(anchors, offsets, method<span class="op">=</span><span class="st">&#39;FasterRCNN&#39;</span>)  <span class="co"># (B, A, H&#39;, W&#39;, 4)</span></span>
<span id="cb76-35"><a href="#cb76-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-36"><a href="#cb76-36" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Get predicted class per anchor.</span></span>
<span id="cb76-37"><a href="#cb76-37" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Permute class_scores to shape (B, H&#39;, W&#39;, C) then expand to (B, A, H&#39;, W&#39;, C)</span></span>
<span id="cb76-38"><a href="#cb76-38" aria-hidden="true" tabindex="-1"></a>  class_scores <span class="op">=</span> class_scores.permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>)  <span class="co"># Now shape: (B, H&#39;, W&#39;, C)</span></span>
<span id="cb76-39"><a href="#cb76-39" aria-hidden="true" tabindex="-1"></a>  B, A, H, W, _ <span class="op">=</span> proposals.shape  <span class="co"># H, W are H&#39; and W&#39;</span></span>
<span id="cb76-40"><a href="#cb76-40" aria-hidden="true" tabindex="-1"></a>  C <span class="op">=</span> class_scores.shape[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb76-41"><a href="#cb76-41" aria-hidden="true" tabindex="-1"></a>  per_anchor_class_scores <span class="op">=</span> class_scores.unsqueeze(<span class="dv">1</span>).expand(B, A, H, W, C)</span>
<span id="cb76-42"><a href="#cb76-42" aria-hidden="true" tabindex="-1"></a>  predicted_class <span class="op">=</span> per_anchor_class_scores.argmax(dim<span class="op">=-</span><span class="dv">1</span>)  <span class="co"># (B, A, H&#39;, W&#39;)</span></span>
<span id="cb76-43"><a href="#cb76-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-44"><a href="#cb76-44" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Flatten predictions per image.</span></span>
<span id="cb76-45"><a href="#cb76-45" aria-hidden="true" tabindex="-1"></a>  proposals <span class="op">=</span> proposals.view(B, <span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>)      <span class="co"># (B, A*H&#39;*W&#39;, 4)</span></span>
<span id="cb76-46"><a href="#cb76-46" aria-hidden="true" tabindex="-1"></a>  conf_scores <span class="op">=</span> conf_scores.view(B, <span class="op">-</span><span class="dv">1</span>)       <span class="co"># (B, A*H&#39;*W&#39;)</span></span>
<span id="cb76-47"><a href="#cb76-47" aria-hidden="true" tabindex="-1"></a>  predicted_class <span class="op">=</span> predicted_class.view(B, <span class="op">-</span><span class="dv">1</span>)  <span class="co"># (B, A*H&#39;*W&#39;)</span></span>
<span id="cb76-48"><a href="#cb76-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-49"><a href="#cb76-49" aria-hidden="true" tabindex="-1"></a>  <span class="co"># v) For each image, threshold the proposals by confidence and apply NMS.</span></span>
<span id="cb76-50"><a href="#cb76-50" aria-hidden="true" tabindex="-1"></a>  <span class="im">import</span> torchvision  <span class="co"># ensure torchvision is imported</span></span>
<span id="cb76-51"><a href="#cb76-51" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> b <span class="kw">in</span> <span class="bu">range</span>(B):</span>
<span id="cb76-52"><a href="#cb76-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Filter proposals based on confidence threshold.</span></span>
<span id="cb76-53"><a href="#cb76-53" aria-hidden="true" tabindex="-1"></a>    inds <span class="op">=</span> (conf_scores[b] <span class="op">&gt;=</span> thresh).nonzero(as_tuple<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>]</span>
<span id="cb76-54"><a href="#cb76-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> inds.numel() <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb76-55"><a href="#cb76-55" aria-hidden="true" tabindex="-1"></a>      final_proposals.append(torch.empty((<span class="dv">0</span>, <span class="dv">4</span>), device<span class="op">=</span>images.device))</span>
<span id="cb76-56"><a href="#cb76-56" aria-hidden="true" tabindex="-1"></a>      final_conf_scores.append(torch.empty((<span class="dv">0</span>, <span class="dv">1</span>), device<span class="op">=</span>images.device))</span>
<span id="cb76-57"><a href="#cb76-57" aria-hidden="true" tabindex="-1"></a>      final_class.append(torch.empty((<span class="dv">0</span>, <span class="dv">1</span>), dtype<span class="op">=</span>torch.<span class="bu">long</span>, device<span class="op">=</span>images.device))</span>
<span id="cb76-58"><a href="#cb76-58" aria-hidden="true" tabindex="-1"></a>      <span class="cf">continue</span></span>
<span id="cb76-59"><a href="#cb76-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-60"><a href="#cb76-60" aria-hidden="true" tabindex="-1"></a>    b_proposals <span class="op">=</span> proposals[b][inds]       <span class="co"># (num_filtered, 4)</span></span>
<span id="cb76-61"><a href="#cb76-61" aria-hidden="true" tabindex="-1"></a>    b_conf <span class="op">=</span> conf_scores[b][inds]            <span class="co"># (num_filtered,)</span></span>
<span id="cb76-62"><a href="#cb76-62" aria-hidden="true" tabindex="-1"></a>    b_class <span class="op">=</span> predicted_class[b][inds]       <span class="co"># (num_filtered,)</span></span>
<span id="cb76-63"><a href="#cb76-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-64"><a href="#cb76-64" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply NMS on the filtered proposals.</span></span>
<span id="cb76-65"><a href="#cb76-65" aria-hidden="true" tabindex="-1"></a>    keep_inds <span class="op">=</span> torchvision.ops.nms(b_proposals, b_conf, nms_thresh)</span>
<span id="cb76-66"><a href="#cb76-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-67"><a href="#cb76-67" aria-hidden="true" tabindex="-1"></a>    final_proposals.append(b_proposals[keep_inds])</span>
<span id="cb76-68"><a href="#cb76-68" aria-hidden="true" tabindex="-1"></a>    final_conf_scores.append(b_conf[keep_inds].unsqueeze(<span class="dv">1</span>))</span>
<span id="cb76-69"><a href="#cb76-69" aria-hidden="true" tabindex="-1"></a>    final_class.append(b_class[keep_inds].unsqueeze(<span class="dv">1</span>))</span>
<span id="cb76-70"><a href="#cb76-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-71"><a href="#cb76-71" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> final_proposals, final_conf_scores, final_class</span>
<span id="cb76-72"><a href="#cb76-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-73"><a href="#cb76-73" aria-hidden="true" tabindex="-1"></a>SingleStageDetector.inference <span class="op">=</span> detector_inference</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="49" id="M6abC15U1Wtu">
<div class="sourceCode" id="cb77"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> DetectionInference(detector, data_loader, dataset, idx_to_class, thresh<span class="op">=</span><span class="fl">0.8</span>, nms_thresh<span class="op">=</span><span class="fl">0.3</span>, output_dir<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># ship model to GPU</span></span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>  detector.to(<span class="op">**</span>to_float_cuda)</span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a>  detector.<span class="bu">eval</span>()</span>
<span id="cb77-7"><a href="#cb77-7" aria-hidden="true" tabindex="-1"></a>  start_t <span class="op">=</span> time.time()</span>
<span id="cb77-8"><a href="#cb77-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-9"><a href="#cb77-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> output_dir <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb77-10"><a href="#cb77-10" aria-hidden="true" tabindex="-1"></a>    det_dir <span class="op">=</span> <span class="st">&#39;mAP/input/detection-results&#39;</span></span>
<span id="cb77-11"><a href="#cb77-11" aria-hidden="true" tabindex="-1"></a>    gt_dir <span class="op">=</span> <span class="st">&#39;mAP/input/ground-truth&#39;</span></span>
<span id="cb77-12"><a href="#cb77-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> os.path.exists(det_dir):</span>
<span id="cb77-13"><a href="#cb77-13" aria-hidden="true" tabindex="-1"></a>      shutil.rmtree(det_dir)</span>
<span id="cb77-14"><a href="#cb77-14" aria-hidden="true" tabindex="-1"></a>    os.mkdir(det_dir)</span>
<span id="cb77-15"><a href="#cb77-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> os.path.exists(gt_dir):</span>
<span id="cb77-16"><a href="#cb77-16" aria-hidden="true" tabindex="-1"></a>      shutil.rmtree(gt_dir)</span>
<span id="cb77-17"><a href="#cb77-17" aria-hidden="true" tabindex="-1"></a>    os.mkdir(gt_dir)</span>
<span id="cb77-18"><a href="#cb77-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-19"><a href="#cb77-19" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> iter_num, data_batch <span class="kw">in</span> <span class="bu">enumerate</span>(data_loader):</span>
<span id="cb77-20"><a href="#cb77-20" aria-hidden="true" tabindex="-1"></a>    images, boxes, w_batch, h_batch, img_ids <span class="op">=</span> data_batch</span>
<span id="cb77-21"><a href="#cb77-21" aria-hidden="true" tabindex="-1"></a>    images <span class="op">=</span> images.to(<span class="op">**</span>to_float_cuda)</span>
<span id="cb77-22"><a href="#cb77-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-23"><a href="#cb77-23" aria-hidden="true" tabindex="-1"></a>    final_proposals, final_conf_scores, final_class <span class="op">=</span> detector.inference(images, thresh<span class="op">=</span>thresh, nms_thresh<span class="op">=</span>nms_thresh)</span>
<span id="cb77-24"><a href="#cb77-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-25"><a href="#cb77-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># clamp on the proposal coordinates</span></span>
<span id="cb77-26"><a href="#cb77-26" aria-hidden="true" tabindex="-1"></a>    batch_size <span class="op">=</span> <span class="bu">len</span>(images)</span>
<span id="cb77-27"><a href="#cb77-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(batch_size):</span>
<span id="cb77-28"><a href="#cb77-28" aria-hidden="true" tabindex="-1"></a>      torch.clamp_(final_proposals[idx][:, <span class="dv">0</span>::<span class="dv">2</span>], <span class="bu">min</span><span class="op">=</span><span class="dv">0</span>, <span class="bu">max</span><span class="op">=</span>w_batch[idx])</span>
<span id="cb77-29"><a href="#cb77-29" aria-hidden="true" tabindex="-1"></a>      torch.clamp_(final_proposals[idx][:, <span class="dv">1</span>::<span class="dv">2</span>], <span class="bu">min</span><span class="op">=</span><span class="dv">0</span>, <span class="bu">max</span><span class="op">=</span>h_batch[idx])</span>
<span id="cb77-30"><a href="#cb77-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-31"><a href="#cb77-31" aria-hidden="true" tabindex="-1"></a>      <span class="co"># visualization</span></span>
<span id="cb77-32"><a href="#cb77-32" aria-hidden="true" tabindex="-1"></a>      <span class="co"># get the original image</span></span>
<span id="cb77-33"><a href="#cb77-33" aria-hidden="true" tabindex="-1"></a>      <span class="co"># hack to get the original image so we don&#39;t have to load from local again...</span></span>
<span id="cb77-34"><a href="#cb77-34" aria-hidden="true" tabindex="-1"></a>      i <span class="op">=</span> batch_size<span class="op">*</span>iter_num <span class="op">+</span> idx</span>
<span id="cb77-35"><a href="#cb77-35" aria-hidden="true" tabindex="-1"></a>      img, _ <span class="op">=</span> dataset.<span class="fu">__getitem__</span>(i)</span>
<span id="cb77-36"><a href="#cb77-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-37"><a href="#cb77-37" aria-hidden="true" tabindex="-1"></a>      valid_box <span class="op">=</span> <span class="bu">sum</span>([<span class="dv">1</span> <span class="cf">if</span> j <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span> <span class="cf">else</span> <span class="dv">0</span> <span class="cf">for</span> j <span class="kw">in</span> boxes[idx][:, <span class="dv">0</span>]])</span>
<span id="cb77-38"><a href="#cb77-38" aria-hidden="true" tabindex="-1"></a>      final_all <span class="op">=</span> torch.cat((final_proposals[idx], <span class="op">\</span></span>
<span id="cb77-39"><a href="#cb77-39" aria-hidden="true" tabindex="-1"></a>        final_class[idx].<span class="bu">float</span>(), final_conf_scores[idx]), dim<span class="op">=-</span><span class="dv">1</span>).cpu()</span>
<span id="cb77-40"><a href="#cb77-40" aria-hidden="true" tabindex="-1"></a>      resized_proposals <span class="op">=</span> coord_trans(final_all, w_batch[idx], h_batch[idx])</span>
<span id="cb77-41"><a href="#cb77-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-42"><a href="#cb77-42" aria-hidden="true" tabindex="-1"></a>      <span class="co"># write results to file for evaluation (use mAP API https://github.com/Cartucho/mAP for now...)</span></span>
<span id="cb77-43"><a href="#cb77-43" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> output_dir <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb77-44"><a href="#cb77-44" aria-hidden="true" tabindex="-1"></a>        file_name <span class="op">=</span> img_ids[idx].replace(<span class="st">&#39;.jpg&#39;</span>, <span class="st">&#39;.txt&#39;</span>)</span>
<span id="cb77-45"><a href="#cb77-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="bu">open</span>(os.path.join(det_dir, file_name), <span class="st">&#39;w&#39;</span>) <span class="im">as</span> f_det, <span class="op">\</span></span>
<span id="cb77-46"><a href="#cb77-46" aria-hidden="true" tabindex="-1"></a>          <span class="bu">open</span>(os.path.join(gt_dir, file_name), <span class="st">&#39;w&#39;</span>) <span class="im">as</span> f_gt:</span>
<span id="cb77-47"><a href="#cb77-47" aria-hidden="true" tabindex="-1"></a>          <span class="bu">print</span>(<span class="st">&#39;</span><span class="sc">{}</span><span class="st">: </span><span class="sc">{}</span><span class="st"> GT bboxes and </span><span class="sc">{}</span><span class="st"> proposals&#39;</span>.<span class="bu">format</span>(img_ids[idx], valid_box, resized_proposals.shape[<span class="dv">0</span>]))</span>
<span id="cb77-48"><a href="#cb77-48" aria-hidden="true" tabindex="-1"></a>          <span class="cf">for</span> b <span class="kw">in</span> boxes[idx][:valid_box]:</span>
<span id="cb77-49"><a href="#cb77-49" aria-hidden="true" tabindex="-1"></a>            f_gt.write(<span class="st">&#39;</span><span class="sc">{}</span><span class="st"> </span><span class="sc">{:.2f}</span><span class="st"> </span><span class="sc">{:.2f}</span><span class="st"> </span><span class="sc">{:.2f}</span><span class="st"> </span><span class="sc">{:.2f}</span><span class="ch">\n</span><span class="st">&#39;</span>.<span class="bu">format</span>(idx_to_class[b[<span class="dv">4</span>].item()], b[<span class="dv">0</span>], b[<span class="dv">1</span>], b[<span class="dv">2</span>], b[<span class="dv">3</span>]))</span>
<span id="cb77-50"><a href="#cb77-50" aria-hidden="true" tabindex="-1"></a>          <span class="cf">for</span> b <span class="kw">in</span> resized_proposals:</span>
<span id="cb77-51"><a href="#cb77-51" aria-hidden="true" tabindex="-1"></a>            f_det.write(<span class="st">&#39;</span><span class="sc">{}</span><span class="st"> </span><span class="sc">{:.6f}</span><span class="st"> </span><span class="sc">{:.2f}</span><span class="st"> </span><span class="sc">{:.2f}</span><span class="st"> </span><span class="sc">{:.2f}</span><span class="st"> </span><span class="sc">{:.2f}</span><span class="ch">\n</span><span class="st">&#39;</span>.<span class="bu">format</span>(idx_to_class[b[<span class="dv">4</span>].item()], b[<span class="dv">5</span>], b[<span class="dv">0</span>], b[<span class="dv">1</span>], b[<span class="dv">2</span>], b[<span class="dv">3</span>]))</span>
<span id="cb77-52"><a href="#cb77-52" aria-hidden="true" tabindex="-1"></a>      <span class="cf">else</span>:</span>
<span id="cb77-53"><a href="#cb77-53" aria-hidden="true" tabindex="-1"></a>        data_visualizer(img, idx_to_class, boxes[idx][:valid_box], resized_proposals)</span>
<span id="cb77-54"><a href="#cb77-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-55"><a href="#cb77-55" aria-hidden="true" tabindex="-1"></a>  end_t <span class="op">=</span> time.time()</span>
<span id="cb77-56"><a href="#cb77-56" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">&#39;Total inference time: </span><span class="sc">{:.1f}</span><span class="st">s&#39;</span>.<span class="bu">format</span>(end_t<span class="op">-</span>start_t))</span></code></pre></div>
</div>
<section id="inference---overfit-small-data" class="cell markdown"
id="kG4PPW1XEDTm">
<h3>Inference - overfit small data</h3>
</section>
<div class="cell code" data-execution_count="50"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:3187}"
id="gp_Hmt-Km5bl" data-outputId="eb9329d2-9386-4475-e54d-2879646a81fe">
<div class="sourceCode" id="cb78"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize the output from the overfitted model on small dataset</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a><span class="co"># the bounding boxes should be really accurate</span></span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a>DetectionInference(detector, small_train_loader, small_dataset, idx_to_class, thresh<span class="op">=</span><span class="fl">0.8</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/4122a8f37dd6e29473620c7634674e617d41b8d2.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/cb21bbe3108668f5f2c15e61fae9a387e6c6a257.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/4a340648952931b9acb5fa388535d7f7962332ee.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/e07d81d123ee27d9f41055e91d27111bcec4664e.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/cf354a1a9ad2486b09c1f79192f195b8539230d5.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/cb279d090c778e8955f4305b5ac04ee113bfed61.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/48bdf0c8c315d11199cd0f43a084f1b6a4145549.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/ee86474cfcd647e24c8a0f9eeaffb2e94c20749e.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/97dfa569f275d37412df15cd7521480738bad6b2.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/9249e0ea30c1e3d900b2fd2aeed0d9eefecc43cb.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>Total inference time: 2.9s
</code></pre>
</div>
</div>
<section id="inference---train-a-net" class="cell markdown"
id="ifdEPmd9EMCP">
<h3>Inference - train a net</h3>
</section>
<div class="cell code" data-execution_count="51"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:3187}"
id="J7ArGiLTnHta" data-outputId="677583a3-096d-44f9-9a13-02c23a7e1a0a">
<div class="sourceCode" id="cb80"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize the same output from the model trained on the entire training set</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a><span class="co"># some bounding boxes might not make sense</span></span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a>DetectionInference(yolo_detector, small_train_loader, small_dataset, idx_to_class)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/ed5a730fb489fdbe14c643e0fabf17bc8e68f7ed.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/95691c1433dd608fa803010bee787a2fa843d96c.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/d7bc15c6f414ee04cbf46945482244bebf7de7a4.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/ec93930b63af08bacbd87cf1aa5299f36193291d.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/8d9957901e2fbd9d75d0bc179e50deb4df2cd590.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/effe8c39f8080c7d81f4d96b1c33407193011a64.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/2322f862eb87e64cbe6197dcadaad1c727d69d6e.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/91a65d15bafce2c159067b7db5b84865f0ec4c4a.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/86708d4dadd91c5b17f2d9e4ee95fa54ca7207d8.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_69f4ac665d97470a847faaa911280bd5/bd44593f79c8c5364c4028f95629910c111a9079.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>Total inference time: 2.5s
</code></pre>
</div>
</div>
<section id="evaluation" class="cell markdown" id="ETU6ev7aydIY">
<h2>Evaluation</h2>
<p>The definition of mean Average Precision (mAP) cna be seen in the
lecture slides.</p>
</section>
<div class="cell markdown" id="1fGptrealquF">
<p>Run the following to evaluate your detector on the PASCAL VOC
validation set. You should see mAP at around 11% or above.</p>
<p>The state of the art on this dataset is &gt;80% mAP! To achieve these
results we would need to use a much bigger network, and train with more
data and for much longer, but that is beyond the scope of this
assigment.</p>
<p>(Optional) If you train the model longer (e.g., 100 epochs), you
should see a better mAP. But make sure you revert the code back for
grading purposes.</p>
</div>
<div class="cell code" data-execution_count="52"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:0}"
id="_f-CsSglupB8" data-outputId="d610f33c-5183-4004-ae78-6198157f6402">
<div class="sourceCode" id="cb82"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Solve bug from mAP repo</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install matplotlib<span class="op">==</span><span class="fl">3.5.3</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: matplotlib==3.5.3 in /usr/local/lib/python3.11/dist-packages (3.5.3)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.5.3) (0.12.1)
Requirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.5.3) (4.56.0)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.5.3) (1.4.8)
Requirement already satisfied: numpy&gt;=1.17 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.5.3) (1.26.4)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.5.3) (24.2)
Requirement already satisfied: pillow&gt;=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.5.3) (11.1.0)
Requirement already satisfied: pyparsing&gt;=2.2.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.5.3) (3.2.1)
Requirement already satisfied: python-dateutil&gt;=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.5.3) (2.8.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil&gt;=2.7-&gt;matplotlib==3.5.3) (1.17.0)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="53"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:0}"
id="FvDb7uwqyhAK" data-outputId="4e3a50a1-05ab-40b3-da32-c1a8a1172816">
<div class="sourceCode" id="cb84"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>DetectionInference(yolo_detector, val_loader, val_dataset, idx_to_class, output_dir<span class="op">=</span><span class="st">&#39;mAP/input&#39;</span>, thresh<span class="op">=</span><span class="fl">0.8</span>, nms_thresh<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="co"># DetectionInference(yolo_detector, train_loader, train_dataset, idx_to_class, output_dir=&#39;mAP/input&#39;, thresh=0.8, nms_thresh=0.3) # uncomment to see training mAP</span></span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>cd mAP <span class="op">&amp;&amp;</span> python main.py</span></code></pre></div>
<div class="output stream stdout">
<pre><code>000005.jpg: 5 GT bboxes and 32 proposals
000007.jpg: 1 GT bboxes and 2 proposals
000009.jpg: 4 GT bboxes and 4 proposals
000016.jpg: 1 GT bboxes and 5 proposals
000019.jpg: 2 GT bboxes and 1 proposals
000020.jpg: 1 GT bboxes and 1 proposals
000021.jpg: 4 GT bboxes and 9 proposals
000024.jpg: 1 GT bboxes and 4 proposals
000030.jpg: 3 GT bboxes and 6 proposals
000039.jpg: 1 GT bboxes and 5 proposals
000041.jpg: 3 GT bboxes and 8 proposals
000046.jpg: 1 GT bboxes and 2 proposals
000050.jpg: 10 GT bboxes and 21 proposals
000051.jpg: 3 GT bboxes and 1 proposals
000052.jpg: 6 GT bboxes and 0 proposals
000060.jpg: 5 GT bboxes and 4 proposals
000063.jpg: 2 GT bboxes and 2 proposals
000065.jpg: 1 GT bboxes and 3 proposals
000072.jpg: 2 GT bboxes and 8 proposals
000081.jpg: 9 GT bboxes and 27 proposals
000093.jpg: 2 GT bboxes and 3 proposals
000095.jpg: 2 GT bboxes and 1 proposals
000099.jpg: 1 GT bboxes and 2 proposals
000101.jpg: 2 GT bboxes and 3 proposals
000102.jpg: 2 GT bboxes and 8 proposals
000107.jpg: 3 GT bboxes and 17 proposals
000109.jpg: 1 GT bboxes and 3 proposals
000110.jpg: 3 GT bboxes and 3 proposals
000113.jpg: 1 GT bboxes and 3 proposals
000117.jpg: 1 GT bboxes and 4 proposals
000118.jpg: 1 GT bboxes and 2 proposals
000120.jpg: 1 GT bboxes and 2 proposals
000121.jpg: 2 GT bboxes and 4 proposals
000123.jpg: 1 GT bboxes and 1 proposals
000125.jpg: 4 GT bboxes and 9 proposals
000130.jpg: 1 GT bboxes and 17 proposals
000131.jpg: 3 GT bboxes and 12 proposals
000132.jpg: 1 GT bboxes and 2 proposals
000142.jpg: 1 GT bboxes and 3 proposals
000143.jpg: 1 GT bboxes and 3 proposals
000146.jpg: 1 GT bboxes and 5 proposals
000150.jpg: 5 GT bboxes and 5 proposals
000156.jpg: 3 GT bboxes and 5 proposals
000158.jpg: 1 GT bboxes and 1 proposals
000165.jpg: 1 GT bboxes and 6 proposals
000169.jpg: 6 GT bboxes and 4 proposals
000170.jpg: 6 GT bboxes and 8 proposals
000177.jpg: 9 GT bboxes and 26 proposals
000180.jpg: 1 GT bboxes and 3 proposals
000184.jpg: 4 GT bboxes and 10 proposals
000190.jpg: 13 GT bboxes and 12 proposals
000203.jpg: 1 GT bboxes and 7 proposals
000208.jpg: 6 GT bboxes and 20 proposals
000210.jpg: 4 GT bboxes and 10 proposals
000211.jpg: 1 GT bboxes and 16 proposals
000214.jpg: 1 GT bboxes and 4 proposals
000215.jpg: 1 GT bboxes and 2 proposals
000218.jpg: 3 GT bboxes and 9 proposals
000221.jpg: 1 GT bboxes and 1 proposals
000224.jpg: 2 GT bboxes and 6 proposals
000229.jpg: 11 GT bboxes and 32 proposals
000232.jpg: 5 GT bboxes and 5 proposals
000233.jpg: 2 GT bboxes and 3 proposals
000236.jpg: 1 GT bboxes and 2 proposals
000241.jpg: 3 GT bboxes and 16 proposals
000244.jpg: 1 GT bboxes and 1 proposals
000245.jpg: 2 GT bboxes and 3 proposals
000246.jpg: 1 GT bboxes and 3 proposals
000249.jpg: 8 GT bboxes and 13 proposals
000251.jpg: 7 GT bboxes and 13 proposals
000257.jpg: 3 GT bboxes and 7 proposals
000266.jpg: 2 GT bboxes and 2 proposals
000268.jpg: 2 GT bboxes and 4 proposals
000269.jpg: 10 GT bboxes and 17 proposals
000270.jpg: 1 GT bboxes and 2 proposals
000275.jpg: 2 GT bboxes and 8 proposals
000285.jpg: 4 GT bboxes and 12 proposals
000289.jpg: 1 GT bboxes and 14 proposals
000298.jpg: 1 GT bboxes and 2 proposals
000302.jpg: 7 GT bboxes and 25 proposals
000303.jpg: 6 GT bboxes and 3 proposals
000304.jpg: 1 GT bboxes and 1 proposals
000305.jpg: 2 GT bboxes and 2 proposals
000308.jpg: 6 GT bboxes and 12 proposals
000318.jpg: 2 GT bboxes and 7 proposals
000321.jpg: 1 GT bboxes and 5 proposals
000322.jpg: 1 GT bboxes and 2 proposals
000323.jpg: 2 GT bboxes and 3 proposals
000328.jpg: 8 GT bboxes and 17 proposals
000329.jpg: 3 GT bboxes and 1 proposals
000332.jpg: 1 GT bboxes and 4 proposals
000336.jpg: 1 GT bboxes and 3 proposals
000338.jpg: 2 GT bboxes and 2 proposals
000340.jpg: 2 GT bboxes and 2 proposals
000343.jpg: 1 GT bboxes and 3 proposals
000352.jpg: 5 GT bboxes and 19 proposals
000354.jpg: 1 GT bboxes and 1 proposals
000363.jpg: 2 GT bboxes and 5 proposals
000373.jpg: 1 GT bboxes and 3 proposals
000374.jpg: 10 GT bboxes and 34 proposals
000380.jpg: 1 GT bboxes and 0 proposals
000381.jpg: 5 GT bboxes and 8 proposals
000396.jpg: 1 GT bboxes and 3 proposals
000403.jpg: 1 GT bboxes and 1 proposals
000408.jpg: 1 GT bboxes and 3 proposals
000417.jpg: 1 GT bboxes and 2 proposals
000419.jpg: 4 GT bboxes and 6 proposals
000420.jpg: 1 GT bboxes and 1 proposals
000424.jpg: 4 GT bboxes and 12 proposals
000427.jpg: 1 GT bboxes and 4 proposals
000428.jpg: 3 GT bboxes and 15 proposals
000433.jpg: 2 GT bboxes and 5 proposals
000435.jpg: 2 GT bboxes and 4 proposals
000439.jpg: 1 GT bboxes and 9 proposals
000443.jpg: 2 GT bboxes and 14 proposals
000448.jpg: 11 GT bboxes and 25 proposals
000459.jpg: 2 GT bboxes and 9 proposals
000460.jpg: 1 GT bboxes and 3 proposals
000461.jpg: 1 GT bboxes and 3 proposals
000462.jpg: 1 GT bboxes and 2 proposals
000464.jpg: 2 GT bboxes and 7 proposals
000480.jpg: 4 GT bboxes and 6 proposals
000482.jpg: 3 GT bboxes and 3 proposals
000483.jpg: 2 GT bboxes and 5 proposals
000486.jpg: 1 GT bboxes and 4 proposals
000491.jpg: 1 GT bboxes and 3 proposals
000492.jpg: 4 GT bboxes and 18 proposals
000494.jpg: 1 GT bboxes and 2 proposals
000498.jpg: 2 GT bboxes and 3 proposals
000499.jpg: 2 GT bboxes and 6 proposals
000500.jpg: 8 GT bboxes and 11 proposals
000501.jpg: 1 GT bboxes and 2 proposals
000509.jpg: 1 GT bboxes and 1 proposals
000513.jpg: 1 GT bboxes and 0 proposals
000514.jpg: 1 GT bboxes and 1 proposals
000515.jpg: 4 GT bboxes and 4 proposals
000520.jpg: 1 GT bboxes and 3 proposals
000523.jpg: 7 GT bboxes and 8 proposals
000530.jpg: 5 GT bboxes and 11 proposals
000531.jpg: 5 GT bboxes and 20 proposals
000540.jpg: 1 GT bboxes and 2 proposals
000543.jpg: 3 GT bboxes and 7 proposals
000545.jpg: 7 GT bboxes and 6 proposals
000563.jpg: 1 GT bboxes and 9 proposals
000564.jpg: 10 GT bboxes and 43 proposals
000579.jpg: 6 GT bboxes and 7 proposals
000581.jpg: 1 GT bboxes and 1 proposals
000582.jpg: 1 GT bboxes and 4 proposals
000588.jpg: 7 GT bboxes and 15 proposals
000591.jpg: 10 GT bboxes and 13 proposals
000598.jpg: 3 GT bboxes and 4 proposals
000599.jpg: 2 GT bboxes and 7 proposals
000601.jpg: 3 GT bboxes and 7 proposals
000608.jpg: 2 GT bboxes and 7 proposals
000610.jpg: 1 GT bboxes and 2 proposals
000613.jpg: 17 GT bboxes and 23 proposals
000619.jpg: 1 GT bboxes and 4 proposals
000626.jpg: 4 GT bboxes and 3 proposals
000628.jpg: 5 GT bboxes and 18 proposals
000637.jpg: 1 GT bboxes and 8 proposals
000645.jpg: 2 GT bboxes and 2 proposals
000647.jpg: 1 GT bboxes and 1 proposals
000653.jpg: 6 GT bboxes and 8 proposals
000656.jpg: 1 GT bboxes and 3 proposals
000660.jpg: 2 GT bboxes and 3 proposals
000661.jpg: 3 GT bboxes and 7 proposals
000663.jpg: 6 GT bboxes and 1 proposals
000667.jpg: 2 GT bboxes and 6 proposals
000675.jpg: 3 GT bboxes and 4 proposals
000676.jpg: 1 GT bboxes and 2 proposals
000677.jpg: 1 GT bboxes and 5 proposals
000682.jpg: 1 GT bboxes and 2 proposals
000684.jpg: 9 GT bboxes and 27 proposals
000686.jpg: 2 GT bboxes and 18 proposals
000690.jpg: 3 GT bboxes and 11 proposals
000694.jpg: 5 GT bboxes and 18 proposals
000702.jpg: 6 GT bboxes and 8 proposals
000705.jpg: 1 GT bboxes and 1 proposals
000707.jpg: 3 GT bboxes and 12 proposals
000712.jpg: 1 GT bboxes and 2 proposals
000713.jpg: 2 GT bboxes and 5 proposals
000714.jpg: 1 GT bboxes and 5 proposals
000717.jpg: 9 GT bboxes and 25 proposals
000720.jpg: 1 GT bboxes and 2 proposals
000728.jpg: 1 GT bboxes and 2 proposals
000730.jpg: 1 GT bboxes and 3 proposals
000738.jpg: 1 GT bboxes and 3 proposals
000742.jpg: 4 GT bboxes and 3 proposals
000746.jpg: 1 GT bboxes and 1 proposals
000748.jpg: 1 GT bboxes and 2 proposals
000750.jpg: 1 GT bboxes and 3 proposals
000752.jpg: 3 GT bboxes and 11 proposals
000755.jpg: 28 GT bboxes and 10 proposals
000756.jpg: 1 GT bboxes and 2 proposals
000760.jpg: 10 GT bboxes and 15 proposals
000763.jpg: 1 GT bboxes and 6 proposals
000771.jpg: 2 GT bboxes and 2 proposals
000772.jpg: 1 GT bboxes and 1 proposals
000776.jpg: 1 GT bboxes and 1 proposals
000777.jpg: 2 GT bboxes and 3 proposals
000780.jpg: 7 GT bboxes and 28 proposals
000782.jpg: 2 GT bboxes and 1 proposals
000786.jpg: 3 GT bboxes and 8 proposals
000787.jpg: 1 GT bboxes and 2 proposals
000791.jpg: 1 GT bboxes and 1 proposals
000794.jpg: 1 GT bboxes and 26 proposals
000797.jpg: 3 GT bboxes and 5 proposals
000799.jpg: 2 GT bboxes and 6 proposals
000800.jpg: 4 GT bboxes and 15 proposals
000802.jpg: 2 GT bboxes and 3 proposals
000806.jpg: 2 GT bboxes and 10 proposals
000808.jpg: 1 GT bboxes and 1 proposals
000814.jpg: 2 GT bboxes and 10 proposals
000815.jpg: 2 GT bboxes and 6 proposals
000816.jpg: 2 GT bboxes and 14 proposals
000826.jpg: 1 GT bboxes and 6 proposals
000831.jpg: 1 GT bboxes and 3 proposals
000832.jpg: 1 GT bboxes and 5 proposals
000834.jpg: 6 GT bboxes and 11 proposals
000842.jpg: 2 GT bboxes and 2 proposals
000843.jpg: 2 GT bboxes and 8 proposals
000847.jpg: 2 GT bboxes and 1 proposals
000848.jpg: 5 GT bboxes and 21 proposals
000854.jpg: 8 GT bboxes and 23 proposals
000855.jpg: 7 GT bboxes and 7 proposals
000857.jpg: 1 GT bboxes and 8 proposals
000862.jpg: 2 GT bboxes and 3 proposals
000863.jpg: 2 GT bboxes and 1 proposals
000868.jpg: 2 GT bboxes and 16 proposals
000872.jpg: 2 GT bboxes and 5 proposals
000874.jpg: 1 GT bboxes and 2 proposals
000876.jpg: 2 GT bboxes and 1 proposals
000878.jpg: 2 GT bboxes and 10 proposals
000879.jpg: 2 GT bboxes and 3 proposals
000880.jpg: 5 GT bboxes and 6 proposals
000882.jpg: 1 GT bboxes and 1 proposals
000885.jpg: 2 GT bboxes and 4 proposals
000895.jpg: 2 GT bboxes and 8 proposals
000896.jpg: 1 GT bboxes and 3 proposals
000903.jpg: 2 GT bboxes and 4 proposals
000911.jpg: 4 GT bboxes and 21 proposals
000917.jpg: 3 GT bboxes and 6 proposals
000918.jpg: 2 GT bboxes and 6 proposals
000920.jpg: 2 GT bboxes and 2 proposals
000921.jpg: 3 GT bboxes and 6 proposals
000923.jpg: 6 GT bboxes and 3 proposals
000926.jpg: 9 GT bboxes and 4 proposals
000931.jpg: 1 GT bboxes and 5 proposals
000934.jpg: 1 GT bboxes and 4 proposals
000935.jpg: 6 GT bboxes and 2 proposals
000937.jpg: 4 GT bboxes and 6 proposals
000946.jpg: 2 GT bboxes and 5 proposals
000947.jpg: 1 GT bboxes and 3 proposals
000948.jpg: 3 GT bboxes and 3 proposals
000949.jpg: 4 GT bboxes and 10 proposals
000971.jpg: 11 GT bboxes and 22 proposals
000972.jpg: 1 GT bboxes and 8 proposals
000973.jpg: 1 GT bboxes and 6 proposals
000982.jpg: 4 GT bboxes and 2 proposals
001004.jpg: 1 GT bboxes and 1 proposals
001009.jpg: 2 GT bboxes and 4 proposals
001012.jpg: 1 GT bboxes and 4 proposals
001017.jpg: 2 GT bboxes and 4 proposals
001018.jpg: 10 GT bboxes and 23 proposals
001027.jpg: 7 GT bboxes and 11 proposals
001028.jpg: 6 GT bboxes and 8 proposals
001041.jpg: 1 GT bboxes and 3 proposals
001042.jpg: 6 GT bboxes and 10 proposals
001045.jpg: 1 GT bboxes and 2 proposals
001052.jpg: 1 GT bboxes and 1 proposals
001053.jpg: 1 GT bboxes and 1 proposals
001056.jpg: 2 GT bboxes and 6 proposals
001061.jpg: 3 GT bboxes and 4 proposals
001062.jpg: 1 GT bboxes and 3 proposals
001066.jpg: 2 GT bboxes and 4 proposals
001069.jpg: 2 GT bboxes and 13 proposals
001072.jpg: 2 GT bboxes and 4 proposals
001074.jpg: 1 GT bboxes and 2 proposals
001083.jpg: 1 GT bboxes and 1 proposals
001084.jpg: 2 GT bboxes and 3 proposals
001091.jpg: 9 GT bboxes and 38 proposals
001092.jpg: 2 GT bboxes and 2 proposals
001093.jpg: 4 GT bboxes and 2 proposals
001097.jpg: 5 GT bboxes and 7 proposals
001102.jpg: 3 GT bboxes and 2 proposals
001104.jpg: 1 GT bboxes and 2 proposals
001107.jpg: 1 GT bboxes and 2 proposals
001109.jpg: 2 GT bboxes and 4 proposals
001110.jpg: 2 GT bboxes and 3 proposals
001121.jpg: 1 GT bboxes and 1 proposals
001124.jpg: 2 GT bboxes and 2 proposals
001125.jpg: 5 GT bboxes and 23 proposals
001136.jpg: 10 GT bboxes and 11 proposals
001137.jpg: 2 GT bboxes and 8 proposals
001142.jpg: 7 GT bboxes and 2 proposals
001143.jpg: 1 GT bboxes and 2 proposals
001144.jpg: 1 GT bboxes and 1 proposals
001145.jpg: 4 GT bboxes and 10 proposals
001148.jpg: 1 GT bboxes and 1 proposals
001149.jpg: 3 GT bboxes and 6 proposals
001154.jpg: 2 GT bboxes and 7 proposals
001160.jpg: 1 GT bboxes and 3 proposals
001161.jpg: 1 GT bboxes and 2 proposals
001164.jpg: 9 GT bboxes and 29 proposals
001166.jpg: 1 GT bboxes and 9 proposals
001170.jpg: 3 GT bboxes and 6 proposals
001175.jpg: 3 GT bboxes and 19 proposals
001176.jpg: 7 GT bboxes and 1 proposals
001184.jpg: 1 GT bboxes and 2 proposals
001185.jpg: 4 GT bboxes and 5 proposals
001186.jpg: 2 GT bboxes and 2 proposals
001187.jpg: 3 GT bboxes and 6 proposals
001192.jpg: 2 GT bboxes and 7 proposals
001199.jpg: 2 GT bboxes and 2 proposals
001200.jpg: 1 GT bboxes and 2 proposals
001201.jpg: 2 GT bboxes and 7 proposals
001203.jpg: 1 GT bboxes and 3 proposals
001206.jpg: 2 GT bboxes and 6 proposals
001211.jpg: 3 GT bboxes and 2 proposals
001215.jpg: 1 GT bboxes and 4 proposals
001221.jpg: 3 GT bboxes and 1 proposals
001224.jpg: 10 GT bboxes and 36 proposals
001225.jpg: 1 GT bboxes and 4 proposals
001231.jpg: 3 GT bboxes and 17 proposals
001233.jpg: 1 GT bboxes and 2 proposals
001236.jpg: 2 GT bboxes and 4 proposals
001241.jpg: 8 GT bboxes and 14 proposals
001247.jpg: 1 GT bboxes and 13 proposals
001250.jpg: 1 GT bboxes and 3 proposals
001254.jpg: 2 GT bboxes and 6 proposals
001259.jpg: 3 GT bboxes and 11 proposals
001260.jpg: 1 GT bboxes and 3 proposals
001265.jpg: 1 GT bboxes and 1 proposals
001266.jpg: 3 GT bboxes and 9 proposals
001272.jpg: 3 GT bboxes and 5 proposals
001274.jpg: 1 GT bboxes and 2 proposals
001277.jpg: 1 GT bboxes and 1 proposals
001281.jpg: 2 GT bboxes and 5 proposals
001284.jpg: 6 GT bboxes and 20 proposals
001286.jpg: 1 GT bboxes and 2 proposals
001288.jpg: 3 GT bboxes and 6 proposals
001289.jpg: 1 GT bboxes and 3 proposals
001290.jpg: 1 GT bboxes and 3 proposals
001292.jpg: 5 GT bboxes and 4 proposals
001293.jpg: 1 GT bboxes and 1 proposals
001298.jpg: 4 GT bboxes and 4 proposals
001310.jpg: 5 GT bboxes and 16 proposals
001311.jpg: 10 GT bboxes and 18 proposals
001316.jpg: 1 GT bboxes and 2 proposals
001324.jpg: 2 GT bboxes and 6 proposals
001330.jpg: 4 GT bboxes and 6 proposals
001337.jpg: 2 GT bboxes and 3 proposals
001341.jpg: 1 GT bboxes and 1 proposals
001343.jpg: 5 GT bboxes and 10 proposals
001350.jpg: 5 GT bboxes and 6 proposals
001352.jpg: 35 GT bboxes and 25 proposals
001360.jpg: 1 GT bboxes and 2 proposals
001361.jpg: 1 GT bboxes and 2 proposals
001362.jpg: 2 GT bboxes and 2 proposals
001371.jpg: 5 GT bboxes and 18 proposals
001375.jpg: 1 GT bboxes and 1 proposals
001383.jpg: 1 GT bboxes and 2 proposals
001386.jpg: 5 GT bboxes and 8 proposals
001387.jpg: 2 GT bboxes and 4 proposals
001397.jpg: 1 GT bboxes and 2 proposals
001400.jpg: 1 GT bboxes and 4 proposals
001413.jpg: 9 GT bboxes and 8 proposals
001430.jpg: 7 GT bboxes and 22 proposals
001432.jpg: 1 GT bboxes and 1 proposals
001439.jpg: 2 GT bboxes and 13 proposals
001441.jpg: 7 GT bboxes and 34 proposals
001443.jpg: 2 GT bboxes and 5 proposals
001444.jpg: 7 GT bboxes and 22 proposals
001445.jpg: 6 GT bboxes and 12 proposals
001460.jpg: 2 GT bboxes and 7 proposals
001463.jpg: 2 GT bboxes and 4 proposals
001464.jpg: 37 GT bboxes and 0 proposals
001465.jpg: 8 GT bboxes and 27 proposals
001466.jpg: 1 GT bboxes and 9 proposals
001467.jpg: 1 GT bboxes and 4 proposals
001472.jpg: 19 GT bboxes and 17 proposals
001475.jpg: 2 GT bboxes and 10 proposals
001481.jpg: 1 GT bboxes and 8 proposals
001484.jpg: 2 GT bboxes and 1 proposals
001490.jpg: 3 GT bboxes and 1 proposals
001493.jpg: 5 GT bboxes and 22 proposals
001497.jpg: 8 GT bboxes and 13 proposals
001509.jpg: 1 GT bboxes and 3 proposals
001510.jpg: 4 GT bboxes and 4 proposals
001514.jpg: 3 GT bboxes and 4 proposals
001522.jpg: 2 GT bboxes and 12 proposals
001523.jpg: 2 GT bboxes and 9 proposals
001531.jpg: 4 GT bboxes and 15 proposals
001536.jpg: 2 GT bboxes and 1 proposals
001537.jpg: 4 GT bboxes and 9 proposals
001541.jpg: 1 GT bboxes and 1 proposals
001543.jpg: 2 GT bboxes and 9 proposals
001544.jpg: 1 GT bboxes and 2 proposals
001545.jpg: 1 GT bboxes and 5 proposals
001553.jpg: 2 GT bboxes and 1 proposals
001554.jpg: 2 GT bboxes and 12 proposals
001561.jpg: 5 GT bboxes and 6 proposals
001565.jpg: 2 GT bboxes and 3 proposals
001571.jpg: 4 GT bboxes and 7 proposals
001577.jpg: 10 GT bboxes and 27 proposals
001582.jpg: 2 GT bboxes and 7 proposals
001588.jpg: 3 GT bboxes and 4 proposals
001595.jpg: 2 GT bboxes and 22 proposals
001598.jpg: 15 GT bboxes and 12 proposals
001603.jpg: 6 GT bboxes and 9 proposals
001608.jpg: 1 GT bboxes and 6 proposals
001614.jpg: 4 GT bboxes and 4 proposals
001617.jpg: 8 GT bboxes and 15 proposals
001618.jpg: 1 GT bboxes and 4 proposals
001628.jpg: 2 GT bboxes and 6 proposals
001632.jpg: 1 GT bboxes and 3 proposals
001638.jpg: 1 GT bboxes and 3 proposals
001640.jpg: 5 GT bboxes and 3 proposals
001642.jpg: 1 GT bboxes and 1 proposals
001647.jpg: 1 GT bboxes and 4 proposals
001653.jpg: 2 GT bboxes and 3 proposals
001675.jpg: 1 GT bboxes and 2 proposals
001677.jpg: 2 GT bboxes and 17 proposals
001678.jpg: 6 GT bboxes and 7 proposals
001682.jpg: 3 GT bboxes and 2 proposals
001685.jpg: 2 GT bboxes and 9 proposals
001686.jpg: 1 GT bboxes and 4 proposals
001689.jpg: 3 GT bboxes and 4 proposals
001691.jpg: 15 GT bboxes and 9 proposals
001693.jpg: 1 GT bboxes and 2 proposals
001718.jpg: 1 GT bboxes and 1 proposals
001724.jpg: 1 GT bboxes and 4 proposals
001725.jpg: 4 GT bboxes and 1 proposals
001726.jpg: 4 GT bboxes and 12 proposals
001727.jpg: 4 GT bboxes and 7 proposals
001730.jpg: 3 GT bboxes and 8 proposals
001746.jpg: 3 GT bboxes and 8 proposals
001747.jpg: 1 GT bboxes and 1 proposals
001749.jpg: 1 GT bboxes and 5 proposals
001755.jpg: 2 GT bboxes and 2 proposals
001756.jpg: 6 GT bboxes and 10 proposals
001771.jpg: 3 GT bboxes and 4 proposals
001772.jpg: 1 GT bboxes and 2 proposals
001775.jpg: 2 GT bboxes and 3 proposals
001778.jpg: 1 GT bboxes and 3 proposals
001782.jpg: 1 GT bboxes and 1 proposals
001784.jpg: 1 GT bboxes and 1 proposals
001785.jpg: 1 GT bboxes and 2 proposals
001793.jpg: 3 GT bboxes and 8 proposals
001795.jpg: 1 GT bboxes and 6 proposals
001797.jpg: 3 GT bboxes and 4 proposals
001799.jpg: 5 GT bboxes and 20 proposals
001801.jpg: 14 GT bboxes and 16 proposals
001807.jpg: 6 GT bboxes and 15 proposals
001816.jpg: 1 GT bboxes and 2 proposals
001818.jpg: 1 GT bboxes and 1 proposals
001827.jpg: 1 GT bboxes and 26 proposals
001830.jpg: 1 GT bboxes and 2 proposals
001833.jpg: 2 GT bboxes and 9 proposals
001837.jpg: 5 GT bboxes and 8 proposals
001842.jpg: 4 GT bboxes and 0 proposals
001847.jpg: 2 GT bboxes and 3 proposals
001849.jpg: 5 GT bboxes and 9 proposals
001855.jpg: 1 GT bboxes and 3 proposals
001860.jpg: 8 GT bboxes and 6 proposals
001862.jpg: 2 GT bboxes and 2 proposals
001872.jpg: 1 GT bboxes and 3 proposals
001875.jpg: 1 GT bboxes and 7 proposals
001877.jpg: 1 GT bboxes and 2 proposals
001878.jpg: 1 GT bboxes and 4 proposals
001882.jpg: 2 GT bboxes and 5 proposals
001887.jpg: 18 GT bboxes and 5 proposals
001888.jpg: 1 GT bboxes and 2 proposals
001899.jpg: 13 GT bboxes and 14 proposals
001901.jpg: 5 GT bboxes and 6 proposals
001907.jpg: 1 GT bboxes and 3 proposals
001911.jpg: 1 GT bboxes and 5 proposals
001918.jpg: 2 GT bboxes and 3 proposals
001920.jpg: 4 GT bboxes and 9 proposals
001927.jpg: 2 GT bboxes and 7 proposals
001931.jpg: 1 GT bboxes and 2 proposals
001932.jpg: 3 GT bboxes and 12 proposals
001933.jpg: 1 GT bboxes and 3 proposals
001934.jpg: 1 GT bboxes and 3 proposals
001936.jpg: 3 GT bboxes and 8 proposals
001940.jpg: 2 GT bboxes and 2 proposals
001944.jpg: 7 GT bboxes and 3 proposals
001948.jpg: 1 GT bboxes and 2 proposals
001958.jpg: 13 GT bboxes and 18 proposals
001962.jpg: 2 GT bboxes and 3 proposals
001964.jpg: 7 GT bboxes and 3 proposals
001970.jpg: 1 GT bboxes and 1 proposals
001972.jpg: 1 GT bboxes and 2 proposals
001976.jpg: 2 GT bboxes and 6 proposals
001982.jpg: 1 GT bboxes and 3 proposals
002000.jpg: 2 GT bboxes and 11 proposals
002011.jpg: 1 GT bboxes and 3 proposals
002019.jpg: 1 GT bboxes and 2 proposals
002021.jpg: 3 GT bboxes and 4 proposals
002022.jpg: 6 GT bboxes and 18 proposals
002023.jpg: 1 GT bboxes and 4 proposals
002024.jpg: 4 GT bboxes and 3 proposals
002030.jpg: 10 GT bboxes and 26 proposals
002036.jpg: 1 GT bboxes and 3 proposals
002045.jpg: 3 GT bboxes and 7 proposals
002054.jpg: 1 GT bboxes and 1 proposals
002058.jpg: 1 GT bboxes and 1 proposals
002063.jpg: 7 GT bboxes and 23 proposals
002064.jpg: 5 GT bboxes and 4 proposals
002067.jpg: 1 GT bboxes and 3 proposals
002070.jpg: 1 GT bboxes and 1 proposals
002082.jpg: 2 GT bboxes and 3 proposals
002083.jpg: 1 GT bboxes and 5 proposals
002086.jpg: 2 GT bboxes and 3 proposals
002088.jpg: 1 GT bboxes and 3 proposals
002090.jpg: 2 GT bboxes and 2 proposals
002091.jpg: 5 GT bboxes and 5 proposals
002094.jpg: 1 GT bboxes and 2 proposals
002098.jpg: 2 GT bboxes and 20 proposals
002099.jpg: 1 GT bboxes and 3 proposals
002101.jpg: 1 GT bboxes and 5 proposals
002102.jpg: 1 GT bboxes and 3 proposals
002109.jpg: 1 GT bboxes and 2 proposals
002112.jpg: 1 GT bboxes and 0 proposals
002114.jpg: 3 GT bboxes and 2 proposals
002124.jpg: 3 GT bboxes and 4 proposals
002125.jpg: 1 GT bboxes and 3 proposals
002129.jpg: 4 GT bboxes and 1 proposals
002135.jpg: 7 GT bboxes and 10 proposals
002136.jpg: 1 GT bboxes and 2 proposals
002140.jpg: 1 GT bboxes and 6 proposals
002142.jpg: 3 GT bboxes and 12 proposals
002145.jpg: 2 GT bboxes and 1 proposals
002146.jpg: 1 GT bboxes and 1 proposals
002152.jpg: 1 GT bboxes and 4 proposals
002163.jpg: 1 GT bboxes and 4 proposals
002165.jpg: 1 GT bboxes and 3 proposals
002169.jpg: 1 GT bboxes and 9 proposals
002171.jpg: 2 GT bboxes and 2 proposals
002174.jpg: 10 GT bboxes and 3 proposals
002181.jpg: 1 GT bboxes and 9 proposals
002183.jpg: 2 GT bboxes and 8 proposals
002184.jpg: 2 GT bboxes and 3 proposals
002190.jpg: 8 GT bboxes and 7 proposals
002201.jpg: 1 GT bboxes and 1 proposals
002202.jpg: 1 GT bboxes and 1 proposals
002209.jpg: 1 GT bboxes and 1 proposals
002213.jpg: 2 GT bboxes and 4 proposals
002214.jpg: 4 GT bboxes and 3 proposals
002218.jpg: 4 GT bboxes and 6 proposals
002220.jpg: 3 GT bboxes and 6 proposals
002226.jpg: 15 GT bboxes and 7 proposals
002228.jpg: 2 GT bboxes and 0 proposals
002233.jpg: 5 GT bboxes and 14 proposals
002244.jpg: 11 GT bboxes and 6 proposals
002248.jpg: 1 GT bboxes and 1 proposals
002251.jpg: 1 GT bboxes and 7 proposals
002257.jpg: 1 GT bboxes and 8 proposals
002259.jpg: 1 GT bboxes and 0 proposals
002261.jpg: 2 GT bboxes and 3 proposals
002263.jpg: 1 GT bboxes and 10 proposals
002266.jpg: 2 GT bboxes and 4 proposals
002267.jpg: 3 GT bboxes and 11 proposals
002268.jpg: 3 GT bboxes and 4 proposals
002270.jpg: 1 GT bboxes and 6 proposals
002272.jpg: 2 GT bboxes and 4 proposals
002273.jpg: 2 GT bboxes and 7 proposals
002276.jpg: 1 GT bboxes and 3 proposals
002278.jpg: 1 GT bboxes and 1 proposals
002281.jpg: 2 GT bboxes and 2 proposals
002285.jpg: 2 GT bboxes and 4 proposals
002288.jpg: 5 GT bboxes and 14 proposals
002290.jpg: 14 GT bboxes and 16 proposals
002300.jpg: 4 GT bboxes and 6 proposals
002302.jpg: 2 GT bboxes and 3 proposals
002305.jpg: 2 GT bboxes and 7 proposals
002308.jpg: 2 GT bboxes and 4 proposals
002324.jpg: 3 GT bboxes and 5 proposals
002328.jpg: 1 GT bboxes and 6 proposals
002329.jpg: 4 GT bboxes and 15 proposals
002330.jpg: 2 GT bboxes and 7 proposals
002332.jpg: 4 GT bboxes and 6 proposals
002333.jpg: 5 GT bboxes and 10 proposals
002337.jpg: 2 GT bboxes and 6 proposals
002340.jpg: 2 GT bboxes and 3 proposals
002343.jpg: 3 GT bboxes and 2 proposals
002345.jpg: 1 GT bboxes and 3 proposals
002348.jpg: 2 GT bboxes and 0 proposals
002352.jpg: 2 GT bboxes and 6 proposals
002361.jpg: 2 GT bboxes and 11 proposals
002364.jpg: 1 GT bboxes and 3 proposals
002366.jpg: 2 GT bboxes and 1 proposals
002367.jpg: 2 GT bboxes and 4 proposals
002369.jpg: 1 GT bboxes and 3 proposals
002371.jpg: 1 GT bboxes and 0 proposals
002372.jpg: 2 GT bboxes and 0 proposals
002374.jpg: 2 GT bboxes and 6 proposals
002375.jpg: 1 GT bboxes and 5 proposals
002376.jpg: 1 GT bboxes and 3 proposals
002377.jpg: 1 GT bboxes and 1 proposals
002378.jpg: 6 GT bboxes and 10 proposals
002382.jpg: 3 GT bboxes and 7 proposals
002385.jpg: 11 GT bboxes and 29 proposals
002387.jpg: 4 GT bboxes and 6 proposals
002391.jpg: 1 GT bboxes and 4 proposals
002393.jpg: 5 GT bboxes and 9 proposals
002404.jpg: 5 GT bboxes and 10 proposals
002407.jpg: 1 GT bboxes and 3 proposals
002415.jpg: 1 GT bboxes and 2 proposals
002417.jpg: 1 GT bboxes and 1 proposals
002425.jpg: 4 GT bboxes and 19 proposals
002427.jpg: 3 GT bboxes and 2 proposals
002435.jpg: 2 GT bboxes and 1 proposals
002437.jpg: 1 GT bboxes and 2 proposals
002441.jpg: 2 GT bboxes and 2 proposals
002444.jpg: 4 GT bboxes and 24 proposals
002450.jpg: 2 GT bboxes and 5 proposals
002452.jpg: 1 GT bboxes and 1 proposals
002454.jpg: 1 GT bboxes and 1 proposals
002456.jpg: 3 GT bboxes and 10 proposals
002459.jpg: 1 GT bboxes and 0 proposals
002460.jpg: 2 GT bboxes and 8 proposals
002462.jpg: 1 GT bboxes and 2 proposals
002470.jpg: 1 GT bboxes and 2 proposals
002476.jpg: 2 GT bboxes and 5 proposals
002477.jpg: 3 GT bboxes and 8 proposals
002479.jpg: 3 GT bboxes and 12 proposals
002491.jpg: 2 GT bboxes and 9 proposals
002492.jpg: 3 GT bboxes and 22 proposals
002493.jpg: 1 GT bboxes and 2 proposals
002497.jpg: 5 GT bboxes and 10 proposals
002504.jpg: 15 GT bboxes and 15 proposals
002505.jpg: 2 GT bboxes and 5 proposals
002508.jpg: 1 GT bboxes and 6 proposals
002513.jpg: 8 GT bboxes and 3 proposals
002520.jpg: 5 GT bboxes and 16 proposals
002523.jpg: 1 GT bboxes and 4 proposals
002524.jpg: 1 GT bboxes and 4 proposals
002525.jpg: 1 GT bboxes and 1 proposals
002529.jpg: 2 GT bboxes and 6 proposals
002537.jpg: 1 GT bboxes and 3 proposals
002540.jpg: 3 GT bboxes and 7 proposals
002542.jpg: 12 GT bboxes and 21 proposals
002546.jpg: 1 GT bboxes and 2 proposals
002549.jpg: 1 GT bboxes and 2 proposals
002561.jpg: 4 GT bboxes and 11 proposals
002563.jpg: 4 GT bboxes and 9 proposals
002565.jpg: 2 GT bboxes and 2 proposals
002566.jpg: 8 GT bboxes and 7 proposals
002567.jpg: 1 GT bboxes and 3 proposals
002578.jpg: 1 GT bboxes and 2 proposals
002584.jpg: 5 GT bboxes and 16 proposals
002585.jpg: 4 GT bboxes and 12 proposals
002586.jpg: 1 GT bboxes and 1 proposals
002589.jpg: 8 GT bboxes and 14 proposals
002593.jpg: 1 GT bboxes and 3 proposals
002598.jpg: 1 GT bboxes and 0 proposals
002600.jpg: 1 GT bboxes and 1 proposals
002605.jpg: 6 GT bboxes and 2 proposals
002606.jpg: 5 GT bboxes and 9 proposals
002613.jpg: 6 GT bboxes and 21 proposals
002615.jpg: 2 GT bboxes and 4 proposals
002618.jpg: 1 GT bboxes and 3 proposals
002621.jpg: 2 GT bboxes and 7 proposals
002632.jpg: 1 GT bboxes and 1 proposals
002633.jpg: 2 GT bboxes and 4 proposals
002636.jpg: 8 GT bboxes and 28 proposals
002637.jpg: 2 GT bboxes and 7 proposals
002641.jpg: 4 GT bboxes and 5 proposals
002643.jpg: 4 GT bboxes and 10 proposals
002646.jpg: 1 GT bboxes and 3 proposals
002649.jpg: 4 GT bboxes and 9 proposals
002657.jpg: 3 GT bboxes and 11 proposals
002658.jpg: 8 GT bboxes and 23 proposals
002659.jpg: 1 GT bboxes and 1 proposals
002667.jpg: 1 GT bboxes and 1 proposals
002668.jpg: 6 GT bboxes and 9 proposals
002670.jpg: 2 GT bboxes and 8 proposals
002675.jpg: 2 GT bboxes and 5 proposals
002677.jpg: 1 GT bboxes and 2 proposals
002678.jpg: 5 GT bboxes and 12 proposals
002689.jpg: 1 GT bboxes and 4 proposals
002690.jpg: 1 GT bboxes and 2 proposals
002693.jpg: 6 GT bboxes and 17 proposals
002695.jpg: 3 GT bboxes and 4 proposals
002696.jpg: 3 GT bboxes and 5 proposals
002699.jpg: 1 GT bboxes and 9 proposals
002706.jpg: 1 GT bboxes and 2 proposals
002709.jpg: 1 GT bboxes and 1 proposals
002714.jpg: 1 GT bboxes and 2 proposals
002717.jpg: 1 GT bboxes and 3 proposals
002718.jpg: 1 GT bboxes and 2 proposals
002721.jpg: 1 GT bboxes and 3 proposals
002723.jpg: 5 GT bboxes and 12 proposals
002727.jpg: 3 GT bboxes and 15 proposals
002732.jpg: 1 GT bboxes and 1 proposals
002734.jpg: 3 GT bboxes and 6 proposals
002741.jpg: 5 GT bboxes and 14 proposals
002747.jpg: 2 GT bboxes and 1 proposals
002751.jpg: 5 GT bboxes and 20 proposals
002760.jpg: 2 GT bboxes and 2 proposals
002762.jpg: 2 GT bboxes and 0 proposals
002767.jpg: 7 GT bboxes and 19 proposals
002772.jpg: 1 GT bboxes and 3 proposals
002775.jpg: 3 GT bboxes and 11 proposals
002776.jpg: 6 GT bboxes and 15 proposals
002784.jpg: 1 GT bboxes and 3 proposals
002785.jpg: 1 GT bboxes and 3 proposals
002786.jpg: 2 GT bboxes and 4 proposals
002794.jpg: 1 GT bboxes and 2 proposals
002798.jpg: 13 GT bboxes and 30 proposals
002800.jpg: 2 GT bboxes and 10 proposals
002803.jpg: 7 GT bboxes and 4 proposals
002810.jpg: 1 GT bboxes and 1 proposals
002812.jpg: 3 GT bboxes and 11 proposals
002815.jpg: 1 GT bboxes and 3 proposals
002827.jpg: 4 GT bboxes and 22 proposals
002833.jpg: 1 GT bboxes and 1 proposals
002835.jpg: 1 GT bboxes and 3 proposals
002836.jpg: 2 GT bboxes and 7 proposals
002838.jpg: 3 GT bboxes and 2 proposals
002842.jpg: 2 GT bboxes and 4 proposals
002847.jpg: 1 GT bboxes and 5 proposals
002854.jpg: 1 GT bboxes and 11 proposals
002859.jpg: 9 GT bboxes and 7 proposals
002875.jpg: 1 GT bboxes and 1 proposals
002879.jpg: 1 GT bboxes and 6 proposals
002880.jpg: 1 GT bboxes and 2 proposals
002884.jpg: 2 GT bboxes and 6 proposals
002886.jpg: 4 GT bboxes and 14 proposals
002889.jpg: 2 GT bboxes and 12 proposals
002891.jpg: 1 GT bboxes and 1 proposals
002893.jpg: 1 GT bboxes and 5 proposals
002896.jpg: 1 GT bboxes and 0 proposals
002901.jpg: 3 GT bboxes and 2 proposals
002910.jpg: 2 GT bboxes and 9 proposals
002912.jpg: 2 GT bboxes and 2 proposals
002913.jpg: 10 GT bboxes and 4 proposals
002915.jpg: 3 GT bboxes and 4 proposals
002916.jpg: 2 GT bboxes and 7 proposals
002917.jpg: 4 GT bboxes and 5 proposals
002924.jpg: 2 GT bboxes and 4 proposals
002932.jpg: 1 GT bboxes and 6 proposals
002933.jpg: 3 GT bboxes and 5 proposals
002935.jpg: 3 GT bboxes and 7 proposals
002938.jpg: 1 GT bboxes and 12 proposals
002940.jpg: 7 GT bboxes and 15 proposals
002941.jpg: 4 GT bboxes and 8 proposals
002942.jpg: 1 GT bboxes and 4 proposals
002943.jpg: 4 GT bboxes and 9 proposals
002944.jpg: 1 GT bboxes and 1 proposals
002946.jpg: 1 GT bboxes and 2 proposals
002947.jpg: 2 GT bboxes and 5 proposals
002952.jpg: 3 GT bboxes and 7 proposals
002954.jpg: 2 GT bboxes and 6 proposals
002960.jpg: 1 GT bboxes and 2 proposals
002963.jpg: 1 GT bboxes and 1 proposals
002965.jpg: 26 GT bboxes and 44 proposals
002966.jpg: 1 GT bboxes and 1 proposals
002967.jpg: 3 GT bboxes and 6 proposals
002977.jpg: 2 GT bboxes and 5 proposals
002978.jpg: 3 GT bboxes and 8 proposals
002984.jpg: 3 GT bboxes and 0 proposals
002986.jpg: 15 GT bboxes and 36 proposals
002994.jpg: 2 GT bboxes and 0 proposals
003000.jpg: 1 GT bboxes and 5 proposals
003004.jpg: 5 GT bboxes and 12 proposals
003005.jpg: 3 GT bboxes and 5 proposals
003008.jpg: 1 GT bboxes and 0 proposals
003009.jpg: 1 GT bboxes and 2 proposals
003015.jpg: 1 GT bboxes and 3 proposals
003017.jpg: 2 GT bboxes and 4 proposals
003021.jpg: 1 GT bboxes and 6 proposals
003023.jpg: 3 GT bboxes and 11 proposals
003028.jpg: 1 GT bboxes and 2 proposals
003031.jpg: 2 GT bboxes and 1 proposals
003032.jpg: 3 GT bboxes and 8 proposals
003038.jpg: 1 GT bboxes and 3 proposals
003039.jpg: 2 GT bboxes and 4 proposals
003044.jpg: 5 GT bboxes and 9 proposals
003045.jpg: 1 GT bboxes and 1 proposals
003054.jpg: 2 GT bboxes and 1 proposals
003056.jpg: 13 GT bboxes and 10 proposals
003057.jpg: 3 GT bboxes and 8 proposals
003058.jpg: 1 GT bboxes and 4 proposals
003064.jpg: 1 GT bboxes and 8 proposals
003065.jpg: 6 GT bboxes and 15 proposals
003072.jpg: 1 GT bboxes and 1 proposals
003078.jpg: 10 GT bboxes and 14 proposals
003082.jpg: 2 GT bboxes and 2 proposals
003086.jpg: 1 GT bboxes and 5 proposals
003089.jpg: 3 GT bboxes and 6 proposals
003090.jpg: 1 GT bboxes and 1 proposals
003093.jpg: 3 GT bboxes and 4 proposals
003094.jpg: 1 GT bboxes and 3 proposals
003098.jpg: 3 GT bboxes and 3 proposals
003102.jpg: 2 GT bboxes and 8 proposals
003112.jpg: 1 GT bboxes and 5 proposals
003117.jpg: 1 GT bboxes and 2 proposals
003118.jpg: 5 GT bboxes and 11 proposals
003120.jpg: 5 GT bboxes and 4 proposals
003121.jpg: 4 GT bboxes and 5 proposals
003126.jpg: 1 GT bboxes and 1 proposals
003127.jpg: 1 GT bboxes and 1 proposals
003129.jpg: 13 GT bboxes and 24 proposals
003137.jpg: 1 GT bboxes and 4 proposals
003142.jpg: 1 GT bboxes and 9 proposals
003154.jpg: 1 GT bboxes and 3 proposals
003162.jpg: 2 GT bboxes and 2 proposals
003164.jpg: 1 GT bboxes and 3 proposals
003170.jpg: 10 GT bboxes and 15 proposals
003176.jpg: 1 GT bboxes and 2 proposals
003177.jpg: 1 GT bboxes and 2 proposals
003178.jpg: 1 GT bboxes and 6 proposals
003186.jpg: 4 GT bboxes and 7 proposals
003189.jpg: 5 GT bboxes and 24 proposals
003194.jpg: 1 GT bboxes and 5 proposals
003195.jpg: 2 GT bboxes and 3 proposals
003199.jpg: 1 GT bboxes and 1 proposals
003200.jpg: 2 GT bboxes and 4 proposals
003207.jpg: 10 GT bboxes and 13 proposals
003210.jpg: 2 GT bboxes and 4 proposals
003213.jpg: 3 GT bboxes and 2 proposals
003216.jpg: 2 GT bboxes and 2 proposals
003218.jpg: 26 GT bboxes and 28 proposals
003219.jpg: 5 GT bboxes and 4 proposals
003223.jpg: 1 GT bboxes and 12 proposals
003228.jpg: 8 GT bboxes and 15 proposals
003239.jpg: 2 GT bboxes and 4 proposals
003243.jpg: 2 GT bboxes and 11 proposals
003250.jpg: 1 GT bboxes and 2 proposals
003255.jpg: 1 GT bboxes and 4 proposals
003256.jpg: 2 GT bboxes and 4 proposals
003258.jpg: 2 GT bboxes and 10 proposals
003262.jpg: 1 GT bboxes and 6 proposals
003271.jpg: 1 GT bboxes and 3 proposals
003272.jpg: 1 GT bboxes and 2 proposals
003274.jpg: 1 GT bboxes and 4 proposals
003285.jpg: 3 GT bboxes and 11 proposals
003293.jpg: 1 GT bboxes and 2 proposals
003294.jpg: 1 GT bboxes and 2 proposals
003296.jpg: 2 GT bboxes and 6 proposals
003299.jpg: 1 GT bboxes and 4 proposals
003300.jpg: 8 GT bboxes and 7 proposals
003301.jpg: 4 GT bboxes and 6 proposals
003307.jpg: 1 GT bboxes and 4 proposals
003311.jpg: 7 GT bboxes and 8 proposals
003313.jpg: 5 GT bboxes and 10 proposals
003316.jpg: 3 GT bboxes and 5 proposals
003325.jpg: 2 GT bboxes and 6 proposals
003327.jpg: 4 GT bboxes and 7 proposals
003335.jpg: 7 GT bboxes and 7 proposals
003344.jpg: 12 GT bboxes and 20 proposals
003351.jpg: 1 GT bboxes and 3 proposals
003360.jpg: 3 GT bboxes and 5 proposals
003362.jpg: 2 GT bboxes and 5 proposals
003370.jpg: 1 GT bboxes and 2 proposals
003376.jpg: 5 GT bboxes and 15 proposals
003377.jpg: 1 GT bboxes and 3 proposals
003386.jpg: 2 GT bboxes and 2 proposals
003390.jpg: 5 GT bboxes and 9 proposals
003391.jpg: 2 GT bboxes and 15 proposals
003397.jpg: 2 GT bboxes and 18 proposals
003398.jpg: 1 GT bboxes and 0 proposals
003403.jpg: 2 GT bboxes and 7 proposals
003404.jpg: 1 GT bboxes and 2 proposals
003407.jpg: 10 GT bboxes and 8 proposals
003410.jpg: 1 GT bboxes and 4 proposals
003415.jpg: 2 GT bboxes and 3 proposals
003419.jpg: 20 GT bboxes and 21 proposals
003422.jpg: 5 GT bboxes and 20 proposals
003425.jpg: 1 GT bboxes and 3 proposals
003429.jpg: 2 GT bboxes and 5 proposals
003435.jpg: 2 GT bboxes and 24 proposals
003443.jpg: 1 GT bboxes and 2 proposals
003444.jpg: 1 GT bboxes and 4 proposals
003449.jpg: 4 GT bboxes and 1 proposals
003451.jpg: 4 GT bboxes and 14 proposals
003453.jpg: 2 GT bboxes and 9 proposals
003455.jpg: 2 GT bboxes and 1 proposals
003458.jpg: 2 GT bboxes and 3 proposals
003461.jpg: 13 GT bboxes and 1 proposals
003462.jpg: 5 GT bboxes and 10 proposals
003464.jpg: 1 GT bboxes and 2 proposals
003465.jpg: 1 GT bboxes and 2 proposals
003468.jpg: 2 GT bboxes and 6 proposals
003469.jpg: 3 GT bboxes and 7 proposals
003470.jpg: 10 GT bboxes and 18 proposals
003492.jpg: 3 GT bboxes and 8 proposals
003516.jpg: 9 GT bboxes and 31 proposals
003518.jpg: 3 GT bboxes and 9 proposals
003519.jpg: 1 GT bboxes and 1 proposals
003521.jpg: 5 GT bboxes and 16 proposals
003528.jpg: 8 GT bboxes and 13 proposals
003530.jpg: 2 GT bboxes and 3 proposals
003536.jpg: 2 GT bboxes and 6 proposals
003537.jpg: 2 GT bboxes and 1 proposals
003546.jpg: 1 GT bboxes and 3 proposals
003554.jpg: 1 GT bboxes and 3 proposals
003556.jpg: 2 GT bboxes and 7 proposals
003566.jpg: 2 GT bboxes and 11 proposals
003567.jpg: 8 GT bboxes and 11 proposals
003580.jpg: 1 GT bboxes and 6 proposals
003587.jpg: 2 GT bboxes and 2 proposals
003589.jpg: 15 GT bboxes and 25 proposals
003593.jpg: 2 GT bboxes and 4 proposals
003594.jpg: 1 GT bboxes and 5 proposals
003597.jpg: 1 GT bboxes and 1 proposals
003606.jpg: 2 GT bboxes and 5 proposals
003611.jpg: 2 GT bboxes and 4 proposals
003618.jpg: 7 GT bboxes and 9 proposals
003620.jpg: 1 GT bboxes and 1 proposals
003623.jpg: 1 GT bboxes and 1 proposals
003632.jpg: 1 GT bboxes and 4 proposals
003636.jpg: 10 GT bboxes and 27 proposals
003638.jpg: 6 GT bboxes and 7 proposals
003639.jpg: 1 GT bboxes and 1 proposals
003640.jpg: 1 GT bboxes and 4 proposals
003648.jpg: 3 GT bboxes and 4 proposals
003651.jpg: 2 GT bboxes and 0 proposals
003654.jpg: 7 GT bboxes and 2 proposals
003655.jpg: 2 GT bboxes and 5 proposals
003657.jpg: 1 GT bboxes and 1 proposals
003660.jpg: 1 GT bboxes and 3 proposals
003667.jpg: 1 GT bboxes and 1 proposals
003669.jpg: 6 GT bboxes and 4 proposals
003673.jpg: 2 GT bboxes and 4 proposals
003674.jpg: 1 GT bboxes and 1 proposals
003675.jpg: 3 GT bboxes and 3 proposals
003684.jpg: 1 GT bboxes and 7 proposals
003685.jpg: 2 GT bboxes and 5 proposals
003690.jpg: 2 GT bboxes and 20 proposals
003691.jpg: 2 GT bboxes and 8 proposals
003696.jpg: 2 GT bboxes and 3 proposals
003703.jpg: 6 GT bboxes and 10 proposals
003706.jpg: 3 GT bboxes and 4 proposals
003708.jpg: 3 GT bboxes and 6 proposals
003709.jpg: 4 GT bboxes and 3 proposals
003711.jpg: 8 GT bboxes and 9 proposals
003717.jpg: 15 GT bboxes and 23 proposals
003721.jpg: 1 GT bboxes and 3 proposals
003722.jpg: 1 GT bboxes and 4 proposals
003727.jpg: 1 GT bboxes and 3 proposals
003729.jpg: 2 GT bboxes and 4 proposals
003750.jpg: 3 GT bboxes and 4 proposals
003753.jpg: 2 GT bboxes and 1 proposals
003754.jpg: 1 GT bboxes and 12 proposals
003760.jpg: 19 GT bboxes and 15 proposals
003772.jpg: 1 GT bboxes and 2 proposals
003774.jpg: 1 GT bboxes and 4 proposals
003780.jpg: 6 GT bboxes and 8 proposals
003783.jpg: 25 GT bboxes and 16 proposals
003791.jpg: 9 GT bboxes and 11 proposals
003793.jpg: 2 GT bboxes and 1 proposals
003796.jpg: 1 GT bboxes and 9 proposals
003798.jpg: 1 GT bboxes and 6 proposals
003803.jpg: 1 GT bboxes and 12 proposals
003808.jpg: 1 GT bboxes and 4 proposals
003809.jpg: 1 GT bboxes and 4 proposals
003814.jpg: 1 GT bboxes and 10 proposals
003820.jpg: 2 GT bboxes and 11 proposals
003821.jpg: 1 GT bboxes and 2 proposals
003826.jpg: 2 GT bboxes and 4 proposals
003837.jpg: 2 GT bboxes and 3 proposals
003838.jpg: 6 GT bboxes and 12 proposals
003844.jpg: 2 GT bboxes and 12 proposals
003845.jpg: 1 GT bboxes and 5 proposals
003846.jpg: 2 GT bboxes and 11 proposals
003848.jpg: 1 GT bboxes and 1 proposals
003855.jpg: 10 GT bboxes and 17 proposals
003857.jpg: 1 GT bboxes and 3 proposals
003863.jpg: 2 GT bboxes and 11 proposals
003868.jpg: 1 GT bboxes and 1 proposals
003869.jpg: 5 GT bboxes and 6 proposals
003871.jpg: 1 GT bboxes and 3 proposals
003872.jpg: 1 GT bboxes and 2 proposals
003876.jpg: 1 GT bboxes and 2 proposals
003877.jpg: 5 GT bboxes and 12 proposals
003885.jpg: 1 GT bboxes and 0 proposals
003886.jpg: 1 GT bboxes and 4 proposals
003891.jpg: 10 GT bboxes and 22 proposals
003895.jpg: 1 GT bboxes and 2 proposals
003905.jpg: 1 GT bboxes and 4 proposals
003911.jpg: 2 GT bboxes and 9 proposals
003915.jpg: 3 GT bboxes and 3 proposals
003918.jpg: 1 GT bboxes and 2 proposals
003919.jpg: 10 GT bboxes and 3 proposals
003923.jpg: 6 GT bboxes and 14 proposals
003924.jpg: 11 GT bboxes and 10 proposals
003926.jpg: 1 GT bboxes and 1 proposals
003937.jpg: 1 GT bboxes and 1 proposals
003941.jpg: 1 GT bboxes and 7 proposals
003946.jpg: 2 GT bboxes and 6 proposals
003947.jpg: 4 GT bboxes and 13 proposals
003948.jpg: 2 GT bboxes and 4 proposals
003954.jpg: 3 GT bboxes and 13 proposals
003957.jpg: 1 GT bboxes and 1 proposals
003960.jpg: 6 GT bboxes and 16 proposals
003963.jpg: 3 GT bboxes and 4 proposals
003965.jpg: 1 GT bboxes and 6 proposals
003966.jpg: 2 GT bboxes and 8 proposals
003973.jpg: 4 GT bboxes and 14 proposals
003979.jpg: 3 GT bboxes and 5 proposals
003984.jpg: 1 GT bboxes and 2 proposals
003986.jpg: 3 GT bboxes and 4 proposals
003990.jpg: 1 GT bboxes and 2 proposals
003992.jpg: 6 GT bboxes and 8 proposals
003994.jpg: 4 GT bboxes and 27 proposals
003996.jpg: 2 GT bboxes and 5 proposals
004003.jpg: 1 GT bboxes and 4 proposals
004010.jpg: 2 GT bboxes and 7 proposals
004011.jpg: 1 GT bboxes and 2 proposals
004015.jpg: 1 GT bboxes and 1 proposals
004020.jpg: 3 GT bboxes and 2 proposals
004025.jpg: 1 GT bboxes and 7 proposals
004031.jpg: 3 GT bboxes and 2 proposals
004039.jpg: 3 GT bboxes and 8 proposals
004047.jpg: 5 GT bboxes and 9 proposals
004051.jpg: 2 GT bboxes and 5 proposals
004057.jpg: 1 GT bboxes and 6 proposals
004060.jpg: 3 GT bboxes and 6 proposals
004066.jpg: 1 GT bboxes and 0 proposals
004069.jpg: 2 GT bboxes and 4 proposals
004073.jpg: 4 GT bboxes and 7 proposals
004075.jpg: 3 GT bboxes and 7 proposals
004076.jpg: 1 GT bboxes and 3 proposals
004077.jpg: 3 GT bboxes and 5 proposals
004082.jpg: 1 GT bboxes and 8 proposals
004085.jpg: 2 GT bboxes and 10 proposals
004087.jpg: 2 GT bboxes and 1 proposals
004089.jpg: 3 GT bboxes and 6 proposals
004102.jpg: 2 GT bboxes and 2 proposals
004105.jpg: 8 GT bboxes and 33 proposals
004108.jpg: 1 GT bboxes and 4 proposals
004110.jpg: 2 GT bboxes and 17 proposals
004113.jpg: 1 GT bboxes and 2 proposals
004117.jpg: 2 GT bboxes and 7 proposals
004122.jpg: 10 GT bboxes and 10 proposals
004135.jpg: 1 GT bboxes and 2 proposals
004141.jpg: 3 GT bboxes and 4 proposals
004142.jpg: 5 GT bboxes and 7 proposals
004143.jpg: 1 GT bboxes and 2 proposals
004145.jpg: 14 GT bboxes and 19 proposals
004148.jpg: 1 GT bboxes and 1 proposals
004150.jpg: 2 GT bboxes and 6 proposals
004174.jpg: 1 GT bboxes and 8 proposals
004178.jpg: 2 GT bboxes and 5 proposals
004185.jpg: 1 GT bboxes and 3 proposals
004186.jpg: 8 GT bboxes and 7 proposals
004191.jpg: 2 GT bboxes and 8 proposals
004192.jpg: 1 GT bboxes and 10 proposals
004193.jpg: 4 GT bboxes and 6 proposals
004194.jpg: 1 GT bboxes and 5 proposals
004195.jpg: 3 GT bboxes and 7 proposals
004203.jpg: 4 GT bboxes and 8 proposals
004204.jpg: 5 GT bboxes and 28 proposals
004205.jpg: 4 GT bboxes and 10 proposals
004212.jpg: 2 GT bboxes and 4 proposals
004229.jpg: 2 GT bboxes and 7 proposals
004230.jpg: 2 GT bboxes and 6 proposals
004239.jpg: 2 GT bboxes and 3 proposals
004246.jpg: 2 GT bboxes and 16 proposals
004257.jpg: 3 GT bboxes and 15 proposals
004258.jpg: 10 GT bboxes and 17 proposals
004259.jpg: 3 GT bboxes and 8 proposals
004264.jpg: 1 GT bboxes and 2 proposals
004265.jpg: 1 GT bboxes and 2 proposals
004274.jpg: 2 GT bboxes and 2 proposals
004275.jpg: 5 GT bboxes and 8 proposals
004279.jpg: 8 GT bboxes and 26 proposals
004284.jpg: 2 GT bboxes and 3 proposals
004286.jpg: 1 GT bboxes and 2 proposals
004293.jpg: 1 GT bboxes and 8 proposals
004295.jpg: 1 GT bboxes and 2 proposals
004298.jpg: 3 GT bboxes and 9 proposals
004304.jpg: 2 GT bboxes and 6 proposals
004310.jpg: 2 GT bboxes and 2 proposals
004312.jpg: 1 GT bboxes and 3 proposals
004321.jpg: 2 GT bboxes and 6 proposals
004323.jpg: 4 GT bboxes and 9 proposals
004326.jpg: 1 GT bboxes and 1 proposals
004329.jpg: 9 GT bboxes and 17 proposals
004331.jpg: 1 GT bboxes and 13 proposals
004341.jpg: 1 GT bboxes and 5 proposals
004346.jpg: 9 GT bboxes and 17 proposals
004349.jpg: 42 GT bboxes and 18 proposals
004351.jpg: 1 GT bboxes and 0 proposals
004352.jpg: 1 GT bboxes and 3 proposals
004354.jpg: 1 GT bboxes and 2 proposals
004356.jpg: 2 GT bboxes and 5 proposals
004364.jpg: 4 GT bboxes and 12 proposals
004368.jpg: 3 GT bboxes and 5 proposals
004369.jpg: 2 GT bboxes and 3 proposals
004380.jpg: 3 GT bboxes and 8 proposals
004384.jpg: 2 GT bboxes and 5 proposals
004390.jpg: 1 GT bboxes and 1 proposals
004396.jpg: 1 GT bboxes and 1 proposals
004397.jpg: 1 GT bboxes and 7 proposals
004405.jpg: 4 GT bboxes and 13 proposals
004409.jpg: 1 GT bboxes and 2 proposals
004411.jpg: 1 GT bboxes and 3 proposals
004421.jpg: 8 GT bboxes and 26 proposals
004423.jpg: 3 GT bboxes and 5 proposals
004424.jpg: 5 GT bboxes and 13 proposals
004429.jpg: 2 GT bboxes and 4 proposals
004430.jpg: 1 GT bboxes and 3 proposals
004432.jpg: 1 GT bboxes and 3 proposals
004433.jpg: 4 GT bboxes and 8 proposals
004437.jpg: 7 GT bboxes and 3 proposals
004438.jpg: 4 GT bboxes and 10 proposals
004446.jpg: 2 GT bboxes and 5 proposals
004450.jpg: 1 GT bboxes and 1 proposals
004455.jpg: 2 GT bboxes and 7 proposals
004457.jpg: 3 GT bboxes and 14 proposals
004459.jpg: 6 GT bboxes and 2 proposals
004463.jpg: 2 GT bboxes and 6 proposals
004464.jpg: 3 GT bboxes and 6 proposals
004466.jpg: 12 GT bboxes and 10 proposals
004468.jpg: 1 GT bboxes and 1 proposals
004474.jpg: 3 GT bboxes and 6 proposals
004487.jpg: 2 GT bboxes and 3 proposals
004488.jpg: 3 GT bboxes and 5 proposals
004490.jpg: 1 GT bboxes and 6 proposals
004493.jpg: 2 GT bboxes and 20 proposals
004494.jpg: 4 GT bboxes and 21 proposals
004495.jpg: 4 GT bboxes and 13 proposals
004498.jpg: 1 GT bboxes and 6 proposals
004499.jpg: 4 GT bboxes and 7 proposals
004507.jpg: 1 GT bboxes and 1 proposals
004509.jpg: 2 GT bboxes and 6 proposals
004512.jpg: 6 GT bboxes and 7 proposals
004518.jpg: 1 GT bboxes and 24 proposals
004527.jpg: 19 GT bboxes and 29 proposals
004528.jpg: 2 GT bboxes and 7 proposals
004530.jpg: 2 GT bboxes and 3 proposals
004532.jpg: 1 GT bboxes and 2 proposals
004535.jpg: 2 GT bboxes and 5 proposals
004539.jpg: 7 GT bboxes and 12 proposals
004542.jpg: 5 GT bboxes and 18 proposals
004552.jpg: 1 GT bboxes and 4 proposals
004555.jpg: 1 GT bboxes and 5 proposals
004558.jpg: 4 GT bboxes and 1 proposals
004574.jpg: 2 GT bboxes and 4 proposals
004581.jpg: 3 GT bboxes and 4 proposals
004585.jpg: 13 GT bboxes and 17 proposals
004588.jpg: 9 GT bboxes and 7 proposals
004592.jpg: 1 GT bboxes and 0 proposals
004600.jpg: 1 GT bboxes and 2 proposals
004601.jpg: 2 GT bboxes and 8 proposals
004606.jpg: 1 GT bboxes and 0 proposals
004609.jpg: 2 GT bboxes and 4 proposals
004618.jpg: 1 GT bboxes and 0 proposals
004626.jpg: 2 GT bboxes and 4 proposals
004630.jpg: 9 GT bboxes and 21 proposals
004632.jpg: 2 GT bboxes and 5 proposals
004647.jpg: 3 GT bboxes and 4 proposals
004649.jpg: 3 GT bboxes and 2 proposals
004652.jpg: 1 GT bboxes and 3 proposals
004653.jpg: 1 GT bboxes and 1 proposals
004654.jpg: 2 GT bboxes and 3 proposals
004655.jpg: 11 GT bboxes and 26 proposals
004660.jpg: 4 GT bboxes and 2 proposals
004662.jpg: 2 GT bboxes and 5 proposals
004672.jpg: 2 GT bboxes and 6 proposals
004673.jpg: 2 GT bboxes and 8 proposals
004674.jpg: 1 GT bboxes and 1 proposals
004676.jpg: 2 GT bboxes and 5 proposals
004682.jpg: 2 GT bboxes and 17 proposals
004689.jpg: 1 GT bboxes and 3 proposals
004692.jpg: 4 GT bboxes and 7 proposals
004699.jpg: 8 GT bboxes and 4 proposals
004707.jpg: 2 GT bboxes and 2 proposals
004708.jpg: 3 GT bboxes and 3 proposals
004719.jpg: 2 GT bboxes and 5 proposals
004722.jpg: 3 GT bboxes and 7 proposals
004727.jpg: 13 GT bboxes and 20 proposals
004732.jpg: 2 GT bboxes and 9 proposals
004746.jpg: 2 GT bboxes and 5 proposals
004750.jpg: 3 GT bboxes and 15 proposals
004761.jpg: 8 GT bboxes and 21 proposals
004768.jpg: 1 GT bboxes and 2 proposals
004770.jpg: 1 GT bboxes and 3 proposals
004777.jpg: 1 GT bboxes and 3 proposals
004785.jpg: 12 GT bboxes and 10 proposals
004786.jpg: 1 GT bboxes and 6 proposals
004788.jpg: 2 GT bboxes and 7 proposals
004789.jpg: 2 GT bboxes and 5 proposals
004796.jpg: 3 GT bboxes and 13 proposals
004805.jpg: 4 GT bboxes and 12 proposals
004812.jpg: 3 GT bboxes and 3 proposals
004814.jpg: 1 GT bboxes and 4 proposals
004816.jpg: 1 GT bboxes and 2 proposals
004818.jpg: 2 GT bboxes and 5 proposals
004825.jpg: 1 GT bboxes and 16 proposals
004826.jpg: 3 GT bboxes and 6 proposals
004831.jpg: 1 GT bboxes and 3 proposals
004834.jpg: 2 GT bboxes and 3 proposals
004839.jpg: 2 GT bboxes and 10 proposals
004840.jpg: 5 GT bboxes and 19 proposals
004850.jpg: 1 GT bboxes and 5 proposals
004852.jpg: 2 GT bboxes and 2 proposals
004856.jpg: 1 GT bboxes and 2 proposals
004859.jpg: 5 GT bboxes and 15 proposals
004863.jpg: 1 GT bboxes and 3 proposals
004866.jpg: 2 GT bboxes and 1 proposals
004867.jpg: 1 GT bboxes and 4 proposals
004868.jpg: 4 GT bboxes and 7 proposals
004872.jpg: 2 GT bboxes and 9 proposals
004878.jpg: 2 GT bboxes and 9 proposals
004886.jpg: 4 GT bboxes and 6 proposals
004890.jpg: 1 GT bboxes and 1 proposals
004895.jpg: 1 GT bboxes and 4 proposals
004896.jpg: 1 GT bboxes and 4 proposals
004903.jpg: 4 GT bboxes and 12 proposals
004912.jpg: 3 GT bboxes and 7 proposals
004916.jpg: 3 GT bboxes and 11 proposals
004926.jpg: 4 GT bboxes and 15 proposals
004928.jpg: 3 GT bboxes and 8 proposals
004931.jpg: 4 GT bboxes and 4 proposals
004935.jpg: 2 GT bboxes and 6 proposals
004936.jpg: 1 GT bboxes and 0 proposals
004938.jpg: 1 GT bboxes and 4 proposals
004939.jpg: 3 GT bboxes and 2 proposals
004943.jpg: 7 GT bboxes and 24 proposals
004948.jpg: 4 GT bboxes and 12 proposals
004950.jpg: 2 GT bboxes and 3 proposals
004953.jpg: 18 GT bboxes and 22 proposals
004954.jpg: 2 GT bboxes and 6 proposals
004956.jpg: 2 GT bboxes and 1 proposals
004960.jpg: 3 GT bboxes and 13 proposals
004963.jpg: 1 GT bboxes and 2 proposals
004967.jpg: 1 GT bboxes and 12 proposals
004977.jpg: 2 GT bboxes and 1 proposals
004982.jpg: 1 GT bboxes and 3 proposals
004983.jpg: 2 GT bboxes and 4 proposals
004985.jpg: 2 GT bboxes and 2 proposals
004986.jpg: 2 GT bboxes and 1 proposals
004994.jpg: 2 GT bboxes and 6 proposals
004997.jpg: 2 GT bboxes and 2 proposals
004998.jpg: 1 GT bboxes and 1 proposals
004999.jpg: 1 GT bboxes and 2 proposals
005003.jpg: 1 GT bboxes and 8 proposals
005014.jpg: 8 GT bboxes and 10 proposals
005028.jpg: 2 GT bboxes and 7 proposals
005036.jpg: 5 GT bboxes and 7 proposals
005037.jpg: 1 GT bboxes and 0 proposals
005039.jpg: 7 GT bboxes and 37 proposals
005042.jpg: 4 GT bboxes and 10 proposals
005054.jpg: 2 GT bboxes and 4 proposals
005055.jpg: 6 GT bboxes and 14 proposals
005056.jpg: 1 GT bboxes and 3 proposals
005062.jpg: 1 GT bboxes and 2 proposals
005063.jpg: 2 GT bboxes and 11 proposals
005064.jpg: 2 GT bboxes and 5 proposals
005067.jpg: 1 GT bboxes and 7 proposals
005072.jpg: 1 GT bboxes and 3 proposals
005077.jpg: 1 GT bboxes and 2 proposals
005079.jpg: 1 GT bboxes and 1 proposals
005081.jpg: 12 GT bboxes and 40 proposals
005085.jpg: 3 GT bboxes and 10 proposals
005102.jpg: 6 GT bboxes and 14 proposals
005104.jpg: 3 GT bboxes and 17 proposals
005110.jpg: 6 GT bboxes and 10 proposals
005111.jpg: 1 GT bboxes and 3 proposals
005116.jpg: 11 GT bboxes and 15 proposals
005128.jpg: 1 GT bboxes and 14 proposals
005131.jpg: 1 GT bboxes and 2 proposals
005135.jpg: 2 GT bboxes and 9 proposals
005136.jpg: 1 GT bboxes and 2 proposals
005144.jpg: 1 GT bboxes and 2 proposals
005145.jpg: 2 GT bboxes and 13 proposals
005146.jpg: 10 GT bboxes and 31 proposals
005150.jpg: 3 GT bboxes and 11 proposals
005159.jpg: 3 GT bboxes and 6 proposals
005160.jpg: 13 GT bboxes and 27 proposals
005161.jpg: 12 GT bboxes and 17 proposals
005175.jpg: 5 GT bboxes and 12 proposals
005176.jpg: 4 GT bboxes and 6 proposals
005179.jpg: 1 GT bboxes and 5 proposals
005185.jpg: 3 GT bboxes and 6 proposals
005195.jpg: 8 GT bboxes and 13 proposals
005199.jpg: 1 GT bboxes and 1 proposals
005209.jpg: 1 GT bboxes and 2 proposals
005210.jpg: 1 GT bboxes and 7 proposals
005212.jpg: 3 GT bboxes and 4 proposals
005214.jpg: 1 GT bboxes and 2 proposals
005220.jpg: 3 GT bboxes and 14 proposals
005222.jpg: 2 GT bboxes and 3 proposals
005224.jpg: 2 GT bboxes and 9 proposals
005229.jpg: 1 GT bboxes and 3 proposals
005230.jpg: 7 GT bboxes and 11 proposals
005239.jpg: 4 GT bboxes and 18 proposals
005242.jpg: 5 GT bboxes and 39 proposals
005248.jpg: 2 GT bboxes and 7 proposals
005253.jpg: 1 GT bboxes and 2 proposals
005254.jpg: 1 GT bboxes and 9 proposals
005263.jpg: 1 GT bboxes and 0 proposals
005264.jpg: 2 GT bboxes and 1 proposals
005267.jpg: 1 GT bboxes and 3 proposals
005268.jpg: 4 GT bboxes and 7 proposals
005270.jpg: 1 GT bboxes and 2 proposals
005274.jpg: 3 GT bboxes and 7 proposals
005278.jpg: 8 GT bboxes and 22 proposals
005281.jpg: 5 GT bboxes and 11 proposals
005293.jpg: 1 GT bboxes and 4 proposals
005298.jpg: 2 GT bboxes and 8 proposals
005305.jpg: 1 GT bboxes and 2 proposals
005306.jpg: 5 GT bboxes and 13 proposals
005312.jpg: 1 GT bboxes and 3 proposals
005314.jpg: 1 GT bboxes and 2 proposals
005315.jpg: 2 GT bboxes and 2 proposals
005319.jpg: 1 GT bboxes and 1 proposals
005320.jpg: 1 GT bboxes and 8 proposals
005325.jpg: 1 GT bboxes and 12 proposals
005326.jpg: 12 GT bboxes and 14 proposals
005328.jpg: 1 GT bboxes and 2 proposals
005331.jpg: 5 GT bboxes and 4 proposals
005340.jpg: 1 GT bboxes and 2 proposals
005343.jpg: 2 GT bboxes and 13 proposals
005346.jpg: 3 GT bboxes and 11 proposals
005348.jpg: 2 GT bboxes and 6 proposals
005349.jpg: 3 GT bboxes and 10 proposals
005350.jpg: 1 GT bboxes and 5 proposals
005352.jpg: 1 GT bboxes and 6 proposals
005355.jpg: 2 GT bboxes and 3 proposals
005365.jpg: 1 GT bboxes and 3 proposals
005367.jpg: 1 GT bboxes and 3 proposals
005370.jpg: 1 GT bboxes and 1 proposals
005371.jpg: 2 GT bboxes and 5 proposals
005378.jpg: 1 GT bboxes and 13 proposals
005379.jpg: 1 GT bboxes and 1 proposals
005380.jpg: 2 GT bboxes and 3 proposals
005383.jpg: 1 GT bboxes and 1 proposals
005384.jpg: 2 GT bboxes and 7 proposals
005385.jpg: 4 GT bboxes and 9 proposals
005393.jpg: 1 GT bboxes and 2 proposals
005395.jpg: 10 GT bboxes and 13 proposals
005397.jpg: 4 GT bboxes and 10 proposals
005398.jpg: 3 GT bboxes and 6 proposals
005407.jpg: 1 GT bboxes and 1 proposals
005416.jpg: 1 GT bboxes and 2 proposals
005418.jpg: 1 GT bboxes and 2 proposals
005419.jpg: 2 GT bboxes and 3 proposals
005421.jpg: 1 GT bboxes and 8 proposals
005423.jpg: 4 GT bboxes and 9 proposals
005429.jpg: 3 GT bboxes and 6 proposals
005430.jpg: 3 GT bboxes and 6 proposals
005431.jpg: 1 GT bboxes and 12 proposals
005434.jpg: 2 GT bboxes and 1 proposals
005436.jpg: 2 GT bboxes and 8 proposals
005438.jpg: 2 GT bboxes and 4 proposals
005439.jpg: 4 GT bboxes and 3 proposals
005441.jpg: 8 GT bboxes and 29 proposals
005454.jpg: 4 GT bboxes and 6 proposals
005461.jpg: 7 GT bboxes and 18 proposals
005465.jpg: 2 GT bboxes and 8 proposals
005469.jpg: 1 GT bboxes and 5 proposals
005470.jpg: 1 GT bboxes and 2 proposals
005471.jpg: 4 GT bboxes and 7 proposals
005475.jpg: 6 GT bboxes and 7 proposals
005481.jpg: 4 GT bboxes and 1 proposals
005485.jpg: 23 GT bboxes and 13 proposals
005486.jpg: 3 GT bboxes and 3 proposals
005497.jpg: 1 GT bboxes and 1 proposals
005507.jpg: 7 GT bboxes and 17 proposals
005510.jpg: 1 GT bboxes and 1 proposals
005517.jpg: 5 GT bboxes and 32 proposals
005518.jpg: 1 GT bboxes and 2 proposals
005521.jpg: 2 GT bboxes and 3 proposals
005522.jpg: 11 GT bboxes and 17 proposals
005530.jpg: 5 GT bboxes and 3 proposals
005531.jpg: 6 GT bboxes and 16 proposals
005535.jpg: 1 GT bboxes and 2 proposals
005539.jpg: 1 GT bboxes and 2 proposals
005549.jpg: 2 GT bboxes and 3 proposals
005550.jpg: 2 GT bboxes and 5 proposals
005552.jpg: 3 GT bboxes and 13 proposals
005554.jpg: 9 GT bboxes and 14 proposals
005559.jpg: 1 GT bboxes and 2 proposals
005573.jpg: 2 GT bboxes and 12 proposals
005576.jpg: 1 GT bboxes and 21 proposals
005577.jpg: 1 GT bboxes and 1 proposals
005583.jpg: 1 GT bboxes and 2 proposals
005584.jpg: 1 GT bboxes and 3 proposals
005586.jpg: 1 GT bboxes and 2 proposals
005588.jpg: 1 GT bboxes and 8 proposals
005590.jpg: 3 GT bboxes and 7 proposals
005593.jpg: 4 GT bboxes and 2 proposals
005606.jpg: 5 GT bboxes and 9 proposals
005608.jpg: 3 GT bboxes and 6 proposals
005613.jpg: 2 GT bboxes and 6 proposals
005614.jpg: 3 GT bboxes and 9 proposals
005615.jpg: 2 GT bboxes and 6 proposals
005618.jpg: 6 GT bboxes and 10 proposals
005620.jpg: 1 GT bboxes and 2 proposals
005629.jpg: 5 GT bboxes and 24 proposals
005640.jpg: 1 GT bboxes and 4 proposals
005641.jpg: 5 GT bboxes and 1 proposals
005645.jpg: 2 GT bboxes and 1 proposals
005647.jpg: 7 GT bboxes and 9 proposals
005652.jpg: 7 GT bboxes and 14 proposals
005653.jpg: 4 GT bboxes and 7 proposals
005655.jpg: 1 GT bboxes and 4 proposals
005657.jpg: 1 GT bboxes and 8 proposals
005660.jpg: 2 GT bboxes and 2 proposals
005662.jpg: 13 GT bboxes and 15 proposals
005664.jpg: 4 GT bboxes and 6 proposals
005672.jpg: 4 GT bboxes and 5 proposals
005674.jpg: 1 GT bboxes and 2 proposals
005676.jpg: 1 GT bboxes and 14 proposals
005679.jpg: 5 GT bboxes and 11 proposals
005682.jpg: 3 GT bboxes and 4 proposals
005685.jpg: 1 GT bboxes and 1 proposals
005687.jpg: 7 GT bboxes and 23 proposals
005693.jpg: 3 GT bboxes and 7 proposals
005696.jpg: 1 GT bboxes and 2 proposals
005701.jpg: 7 GT bboxes and 19 proposals
005702.jpg: 2 GT bboxes and 7 proposals
005714.jpg: 3 GT bboxes and 9 proposals
005716.jpg: 2 GT bboxes and 4 proposals
005719.jpg: 8 GT bboxes and 38 proposals
005723.jpg: 8 GT bboxes and 24 proposals
005729.jpg: 2 GT bboxes and 9 proposals
005732.jpg: 6 GT bboxes and 15 proposals
005736.jpg: 2 GT bboxes and 5 proposals
005741.jpg: 2 GT bboxes and 5 proposals
005743.jpg: 2 GT bboxes and 6 proposals
005747.jpg: 3 GT bboxes and 8 proposals
005749.jpg: 1 GT bboxes and 2 proposals
005755.jpg: 2 GT bboxes and 5 proposals
005760.jpg: 2 GT bboxes and 7 proposals
005761.jpg: 1 GT bboxes and 3 proposals
005762.jpg: 2 GT bboxes and 8 proposals
005768.jpg: 4 GT bboxes and 7 proposals
005773.jpg: 7 GT bboxes and 19 proposals
005779.jpg: 2 GT bboxes and 7 proposals
005781.jpg: 1 GT bboxes and 3 proposals
005788.jpg: 2 GT bboxes and 2 proposals
005790.jpg: 2 GT bboxes and 4 proposals
005791.jpg: 2 GT bboxes and 6 proposals
005794.jpg: 9 GT bboxes and 17 proposals
005799.jpg: 4 GT bboxes and 18 proposals
005811.jpg: 4 GT bboxes and 10 proposals
005812.jpg: 2 GT bboxes and 6 proposals
005815.jpg: 2 GT bboxes and 2 proposals
005818.jpg: 2 GT bboxes and 11 proposals
005819.jpg: 2 GT bboxes and 3 proposals
005825.jpg: 1 GT bboxes and 3 proposals
005828.jpg: 1 GT bboxes and 2 proposals
005829.jpg: 3 GT bboxes and 13 proposals
005830.jpg: 1 GT bboxes and 3 proposals
005839.jpg: 2 GT bboxes and 4 proposals
005841.jpg: 1 GT bboxes and 11 proposals
005845.jpg: 2 GT bboxes and 9 proposals
005852.jpg: 3 GT bboxes and 2 proposals
005853.jpg: 1 GT bboxes and 2 proposals
005854.jpg: 3 GT bboxes and 3 proposals
005856.jpg: 3 GT bboxes and 11 proposals
005863.jpg: 13 GT bboxes and 21 proposals
005868.jpg: 1 GT bboxes and 2 proposals
005874.jpg: 2 GT bboxes and 13 proposals
005875.jpg: 1 GT bboxes and 3 proposals
005877.jpg: 2 GT bboxes and 10 proposals
005878.jpg: 1 GT bboxes and 3 proposals
005879.jpg: 1 GT bboxes and 2 proposals
005894.jpg: 4 GT bboxes and 5 proposals
005897.jpg: 3 GT bboxes and 15 proposals
005906.jpg: 3 GT bboxes and 6 proposals
005912.jpg: 1 GT bboxes and 1 proposals
005914.jpg: 3 GT bboxes and 7 proposals
005917.jpg: 3 GT bboxes and 0 proposals
005919.jpg: 20 GT bboxes and 29 proposals
005928.jpg: 7 GT bboxes and 29 proposals
005940.jpg: 6 GT bboxes and 16 proposals
005952.jpg: 2 GT bboxes and 4 proposals
005954.jpg: 1 GT bboxes and 2 proposals
005956.jpg: 4 GT bboxes and 5 proposals
005963.jpg: 4 GT bboxes and 20 proposals
005968.jpg: 1 GT bboxes and 5 proposals
005970.jpg: 1 GT bboxes and 1 proposals
005975.jpg: 2 GT bboxes and 1 proposals
005979.jpg: 3 GT bboxes and 10 proposals
005981.jpg: 2 GT bboxes and 4 proposals
005985.jpg: 2 GT bboxes and 10 proposals
005988.jpg: 6 GT bboxes and 15 proposals
005989.jpg: 2 GT bboxes and 6 proposals
005991.jpg: 2 GT bboxes and 5 proposals
005995.jpg: 2 GT bboxes and 2 proposals
005996.jpg: 1 GT bboxes and 2 proposals
005998.jpg: 1 GT bboxes and 9 proposals
006000.jpg: 2 GT bboxes and 6 proposals
006001.jpg: 1 GT bboxes and 2 proposals
006005.jpg: 3 GT bboxes and 1 proposals
006012.jpg: 2 GT bboxes and 3 proposals
006018.jpg: 10 GT bboxes and 17 proposals
006026.jpg: 2 GT bboxes and 3 proposals
006027.jpg: 1 GT bboxes and 12 proposals
006028.jpg: 3 GT bboxes and 16 proposals
006029.jpg: 11 GT bboxes and 23 proposals
006035.jpg: 6 GT bboxes and 11 proposals
006041.jpg: 4 GT bboxes and 10 proposals
006042.jpg: 1 GT bboxes and 2 proposals
006045.jpg: 2 GT bboxes and 11 proposals
006046.jpg: 3 GT bboxes and 18 proposals
006055.jpg: 5 GT bboxes and 23 proposals
006058.jpg: 1 GT bboxes and 2 proposals
006062.jpg: 3 GT bboxes and 5 proposals
006069.jpg: 2 GT bboxes and 3 proposals
006071.jpg: 10 GT bboxes and 25 proposals
006084.jpg: 1 GT bboxes and 2 proposals
006089.jpg: 1 GT bboxes and 0 proposals
006097.jpg: 1 GT bboxes and 2 proposals
006098.jpg: 3 GT bboxes and 1 proposals
006107.jpg: 1 GT bboxes and 5 proposals
006108.jpg: 1 GT bboxes and 1 proposals
006111.jpg: 1 GT bboxes and 2 proposals
006117.jpg: 1 GT bboxes and 3 proposals
006120.jpg: 2 GT bboxes and 2 proposals
006124.jpg: 1 GT bboxes and 2 proposals
006125.jpg: 2 GT bboxes and 1 proposals
006129.jpg: 1 GT bboxes and 1 proposals
006133.jpg: 17 GT bboxes and 10 proposals
006136.jpg: 1 GT bboxes and 4 proposals
006139.jpg: 2 GT bboxes and 4 proposals
006146.jpg: 1 GT bboxes and 9 proposals
006148.jpg: 2 GT bboxes and 11 proposals
006150.jpg: 4 GT bboxes and 17 proposals
006151.jpg: 5 GT bboxes and 17 proposals
006153.jpg: 1 GT bboxes and 4 proposals
006159.jpg: 1 GT bboxes and 14 proposals
006161.jpg: 11 GT bboxes and 31 proposals
006163.jpg: 1 GT bboxes and 3 proposals
006184.jpg: 1 GT bboxes and 9 proposals
006185.jpg: 5 GT bboxes and 14 proposals
006188.jpg: 4 GT bboxes and 24 proposals
006190.jpg: 1 GT bboxes and 4 proposals
006198.jpg: 10 GT bboxes and 24 proposals
006201.jpg: 2 GT bboxes and 10 proposals
006202.jpg: 3 GT bboxes and 9 proposals
006203.jpg: 2 GT bboxes and 0 proposals
006206.jpg: 3 GT bboxes and 16 proposals
006209.jpg: 2 GT bboxes and 11 proposals
006212.jpg: 1 GT bboxes and 2 proposals
006214.jpg: 1 GT bboxes and 5 proposals
006215.jpg: 3 GT bboxes and 1 proposals
006216.jpg: 4 GT bboxes and 1 proposals
006218.jpg: 2 GT bboxes and 9 proposals
006219.jpg: 1 GT bboxes and 3 proposals
006220.jpg: 8 GT bboxes and 21 proposals
006222.jpg: 2 GT bboxes and 8 proposals
006233.jpg: 1 GT bboxes and 0 proposals
006234.jpg: 1 GT bboxes and 2 proposals
006235.jpg: 11 GT bboxes and 4 proposals
006240.jpg: 1 GT bboxes and 2 proposals
006241.jpg: 7 GT bboxes and 28 proposals
006249.jpg: 1 GT bboxes and 5 proposals
006252.jpg: 1 GT bboxes and 1 proposals
006254.jpg: 1 GT bboxes and 1 proposals
006258.jpg: 1 GT bboxes and 0 proposals
006259.jpg: 6 GT bboxes and 24 proposals
006260.jpg: 1 GT bboxes and 4 proposals
006269.jpg: 1 GT bboxes and 1 proposals
006276.jpg: 2 GT bboxes and 5 proposals
006277.jpg: 1 GT bboxes and 2 proposals
006281.jpg: 2 GT bboxes and 8 proposals
006282.jpg: 1 GT bboxes and 6 proposals
006284.jpg: 1 GT bboxes and 4 proposals
006286.jpg: 20 GT bboxes and 20 proposals
006295.jpg: 3 GT bboxes and 7 proposals
006296.jpg: 3 GT bboxes and 11 proposals
006300.jpg: 6 GT bboxes and 15 proposals
006301.jpg: 1 GT bboxes and 3 proposals
006306.jpg: 1 GT bboxes and 2 proposals
006309.jpg: 1 GT bboxes and 3 proposals
006314.jpg: 1 GT bboxes and 4 proposals
006318.jpg: 1 GT bboxes and 3 proposals
006319.jpg: 2 GT bboxes and 4 proposals
006321.jpg: 2 GT bboxes and 3 proposals
006323.jpg: 2 GT bboxes and 20 proposals
006325.jpg: 1 GT bboxes and 4 proposals
006330.jpg: 8 GT bboxes and 13 proposals
006335.jpg: 1 GT bboxes and 3 proposals
006337.jpg: 1 GT bboxes and 3 proposals
006338.jpg: 1 GT bboxes and 5 proposals
006339.jpg: 8 GT bboxes and 3 proposals
006346.jpg: 11 GT bboxes and 21 proposals
006348.jpg: 2 GT bboxes and 12 proposals
006350.jpg: 1 GT bboxes and 2 proposals
006351.jpg: 3 GT bboxes and 4 proposals
006355.jpg: 3 GT bboxes and 6 proposals
006357.jpg: 3 GT bboxes and 6 proposals
006377.jpg: 1 GT bboxes and 3 proposals
006385.jpg: 1 GT bboxes and 2 proposals
006387.jpg: 2 GT bboxes and 4 proposals
006391.jpg: 2 GT bboxes and 8 proposals
006392.jpg: 2 GT bboxes and 11 proposals
006396.jpg: 9 GT bboxes and 14 proposals
006398.jpg: 16 GT bboxes and 25 proposals
006404.jpg: 1 GT bboxes and 4 proposals
006409.jpg: 4 GT bboxes and 16 proposals
006421.jpg: 3 GT bboxes and 11 proposals
006424.jpg: 2 GT bboxes and 4 proposals
006425.jpg: 1 GT bboxes and 1 proposals
006428.jpg: 3 GT bboxes and 6 proposals
006430.jpg: 1 GT bboxes and 9 proposals
006437.jpg: 1 GT bboxes and 8 proposals
006440.jpg: 2 GT bboxes and 11 proposals
006443.jpg: 1 GT bboxes and 5 proposals
006444.jpg: 2 GT bboxes and 8 proposals
006445.jpg: 2 GT bboxes and 6 proposals
006449.jpg: 1 GT bboxes and 3 proposals
006450.jpg: 3 GT bboxes and 10 proposals
006456.jpg: 1 GT bboxes and 1 proposals
006463.jpg: 2 GT bboxes and 3 proposals
006465.jpg: 8 GT bboxes and 18 proposals
006468.jpg: 1 GT bboxes and 1 proposals
006473.jpg: 3 GT bboxes and 7 proposals
006480.jpg: 1 GT bboxes and 0 proposals
006484.jpg: 1 GT bboxes and 3 proposals
006488.jpg: 2 GT bboxes and 7 proposals
006492.jpg: 3 GT bboxes and 4 proposals
006497.jpg: 8 GT bboxes and 9 proposals
006507.jpg: 1 GT bboxes and 4 proposals
006509.jpg: 3 GT bboxes and 10 proposals
006512.jpg: 1 GT bboxes and 2 proposals
006519.jpg: 6 GT bboxes and 19 proposals
006520.jpg: 1 GT bboxes and 1 proposals
006529.jpg: 2 GT bboxes and 2 proposals
006530.jpg: 6 GT bboxes and 21 proposals
006532.jpg: 2 GT bboxes and 4 proposals
006534.jpg: 1 GT bboxes and 3 proposals
006538.jpg: 1 GT bboxes and 1 proposals
006542.jpg: 16 GT bboxes and 7 proposals
006543.jpg: 1 GT bboxes and 7 proposals
006553.jpg: 1 GT bboxes and 2 proposals
006562.jpg: 5 GT bboxes and 8 proposals
006565.jpg: 1 GT bboxes and 4 proposals
006570.jpg: 2 GT bboxes and 8 proposals
006572.jpg: 5 GT bboxes and 16 proposals
006575.jpg: 1 GT bboxes and 7 proposals
006576.jpg: 5 GT bboxes and 9 proposals
006578.jpg: 3 GT bboxes and 11 proposals
006583.jpg: 3 GT bboxes and 14 proposals
006584.jpg: 10 GT bboxes and 25 proposals
006585.jpg: 2 GT bboxes and 5 proposals
006587.jpg: 1 GT bboxes and 3 proposals
006588.jpg: 7 GT bboxes and 4 proposals
006593.jpg: 1 GT bboxes and 1 proposals
006599.jpg: 4 GT bboxes and 10 proposals
006603.jpg: 1 GT bboxes and 3 proposals
006606.jpg: 2 GT bboxes and 2 proposals
006611.jpg: 2 GT bboxes and 4 proposals
006617.jpg: 2 GT bboxes and 3 proposals
006618.jpg: 2 GT bboxes and 9 proposals
006619.jpg: 1 GT bboxes and 4 proposals
006621.jpg: 2 GT bboxes and 6 proposals
006625.jpg: 6 GT bboxes and 13 proposals
006628.jpg: 11 GT bboxes and 24 proposals
006631.jpg: 2 GT bboxes and 3 proposals
006632.jpg: 2 GT bboxes and 4 proposals
006643.jpg: 1 GT bboxes and 2 proposals
006645.jpg: 2 GT bboxes and 5 proposals
006647.jpg: 4 GT bboxes and 12 proposals
006657.jpg: 1 GT bboxes and 5 proposals
006661.jpg: 12 GT bboxes and 8 proposals
006664.jpg: 2 GT bboxes and 4 proposals
006666.jpg: 2 GT bboxes and 5 proposals
006667.jpg: 2 GT bboxes and 4 proposals
006668.jpg: 3 GT bboxes and 9 proposals
006670.jpg: 3 GT bboxes and 8 proposals
006671.jpg: 2 GT bboxes and 12 proposals
006673.jpg: 12 GT bboxes and 20 proposals
006677.jpg: 3 GT bboxes and 3 proposals
006678.jpg: 1 GT bboxes and 8 proposals
006679.jpg: 3 GT bboxes and 9 proposals
006681.jpg: 4 GT bboxes and 0 proposals
006682.jpg: 3 GT bboxes and 6 proposals
006687.jpg: 1 GT bboxes and 14 proposals
006690.jpg: 4 GT bboxes and 16 proposals
006696.jpg: 7 GT bboxes and 21 proposals
006699.jpg: 2 GT bboxes and 8 proposals
006702.jpg: 2 GT bboxes and 5 proposals
006709.jpg: 3 GT bboxes and 11 proposals
006718.jpg: 2 GT bboxes and 7 proposals
006719.jpg: 5 GT bboxes and 11 proposals
006722.jpg: 6 GT bboxes and 15 proposals
006725.jpg: 1 GT bboxes and 2 proposals
006730.jpg: 1 GT bboxes and 2 proposals
006739.jpg: 3 GT bboxes and 7 proposals
006747.jpg: 1 GT bboxes and 11 proposals
006751.jpg: 2 GT bboxes and 5 proposals
006759.jpg: 1 GT bboxes and 2 proposals
006760.jpg: 3 GT bboxes and 3 proposals
006761.jpg: 1 GT bboxes and 2 proposals
006762.jpg: 3 GT bboxes and 10 proposals
006765.jpg: 5 GT bboxes and 9 proposals
006768.jpg: 4 GT bboxes and 15 proposals
006769.jpg: 2 GT bboxes and 1 proposals
006772.jpg: 2 GT bboxes and 5 proposals
006783.jpg: 6 GT bboxes and 7 proposals
006786.jpg: 2 GT bboxes and 9 proposals
006789.jpg: 3 GT bboxes and 6 proposals
006797.jpg: 2 GT bboxes and 5 proposals
006799.jpg: 1 GT bboxes and 3 proposals
006800.jpg: 6 GT bboxes and 14 proposals
006802.jpg: 3 GT bboxes and 1 proposals
006803.jpg: 3 GT bboxes and 6 proposals
006808.jpg: 1 GT bboxes and 3 proposals
006813.jpg: 2 GT bboxes and 5 proposals
006814.jpg: 1 GT bboxes and 10 proposals
006819.jpg: 5 GT bboxes and 9 proposals
006821.jpg: 6 GT bboxes and 19 proposals
006827.jpg: 2 GT bboxes and 4 proposals
006828.jpg: 1 GT bboxes and 5 proposals
006829.jpg: 1 GT bboxes and 4 proposals
006835.jpg: 2 GT bboxes and 3 proposals
006838.jpg: 1 GT bboxes and 2 proposals
006841.jpg: 7 GT bboxes and 22 proposals
006842.jpg: 2 GT bboxes and 7 proposals
006850.jpg: 2 GT bboxes and 5 proposals
006855.jpg: 3 GT bboxes and 10 proposals
006859.jpg: 2 GT bboxes and 4 proposals
006860.jpg: 1 GT bboxes and 11 proposals
006862.jpg: 7 GT bboxes and 12 proposals
006865.jpg: 1 GT bboxes and 1 proposals
006867.jpg: 1 GT bboxes and 1 proposals
006876.jpg: 3 GT bboxes and 5 proposals
006878.jpg: 2 GT bboxes and 2 proposals
006880.jpg: 6 GT bboxes and 11 proposals
006884.jpg: 1 GT bboxes and 2 proposals
006886.jpg: 2 GT bboxes and 11 proposals
006892.jpg: 6 GT bboxes and 15 proposals
006903.jpg: 4 GT bboxes and 8 proposals
006908.jpg: 13 GT bboxes and 22 proposals
006918.jpg: 2 GT bboxes and 6 proposals
006922.jpg: 1 GT bboxes and 2 proposals
006924.jpg: 1 GT bboxes and 1 proposals
006932.jpg: 2 GT bboxes and 8 proposals
006933.jpg: 2 GT bboxes and 5 proposals
006934.jpg: 6 GT bboxes and 10 proposals
006935.jpg: 1 GT bboxes and 3 proposals
006940.jpg: 1 GT bboxes and 1 proposals
006944.jpg: 6 GT bboxes and 18 proposals
006945.jpg: 6 GT bboxes and 11 proposals
006949.jpg: 1 GT bboxes and 2 proposals
006952.jpg: 1 GT bboxes and 0 proposals
006953.jpg: 1 GT bboxes and 6 proposals
006956.jpg: 4 GT bboxes and 22 proposals
006962.jpg: 1 GT bboxes and 13 proposals
006963.jpg: 5 GT bboxes and 6 proposals
006965.jpg: 6 GT bboxes and 3 proposals
006966.jpg: 1 GT bboxes and 2 proposals
006972.jpg: 4 GT bboxes and 22 proposals
006981.jpg: 1 GT bboxes and 13 proposals
006987.jpg: 3 GT bboxes and 10 proposals
006988.jpg: 2 GT bboxes and 3 proposals
006989.jpg: 2 GT bboxes and 4 proposals
006990.jpg: 2 GT bboxes and 8 proposals
006994.jpg: 1 GT bboxes and 3 proposals
006995.jpg: 1 GT bboxes and 10 proposals
007004.jpg: 6 GT bboxes and 11 proposals
007008.jpg: 2 GT bboxes and 4 proposals
007009.jpg: 1 GT bboxes and 3 proposals
007020.jpg: 1 GT bboxes and 3 proposals
007021.jpg: 5 GT bboxes and 13 proposals
007022.jpg: 1 GT bboxes and 6 proposals
007031.jpg: 2 GT bboxes and 3 proposals
007035.jpg: 3 GT bboxes and 12 proposals
007038.jpg: 1 GT bboxes and 2 proposals
007042.jpg: 6 GT bboxes and 11 proposals
007046.jpg: 2 GT bboxes and 5 proposals
007048.jpg: 7 GT bboxes and 2 proposals
007049.jpg: 3 GT bboxes and 7 proposals
007052.jpg: 3 GT bboxes and 7 proposals
007054.jpg: 1 GT bboxes and 3 proposals
007056.jpg: 1 GT bboxes and 0 proposals
007058.jpg: 1 GT bboxes and 4 proposals
007059.jpg: 10 GT bboxes and 16 proposals
007065.jpg: 1 GT bboxes and 1 proposals
007068.jpg: 8 GT bboxes and 2 proposals
007070.jpg: 1 GT bboxes and 2 proposals
007071.jpg: 1 GT bboxes and 1 proposals
007074.jpg: 3 GT bboxes and 6 proposals
007077.jpg: 4 GT bboxes and 0 proposals
007084.jpg: 1 GT bboxes and 3 proposals
007086.jpg: 1 GT bboxes and 3 proposals
007097.jpg: 1 GT bboxes and 2 proposals
007100.jpg: 2 GT bboxes and 5 proposals
007101.jpg: 1 GT bboxes and 1 proposals
007104.jpg: 1 GT bboxes and 1 proposals
007109.jpg: 2 GT bboxes and 5 proposals
007114.jpg: 3 GT bboxes and 4 proposals
007117.jpg: 9 GT bboxes and 7 proposals
007122.jpg: 2 GT bboxes and 1 proposals
007123.jpg: 1 GT bboxes and 1 proposals
007132.jpg: 2 GT bboxes and 2 proposals
007139.jpg: 2 GT bboxes and 15 proposals
007140.jpg: 2 GT bboxes and 9 proposals
007141.jpg: 3 GT bboxes and 9 proposals
007144.jpg: 1 GT bboxes and 11 proposals
007146.jpg: 1 GT bboxes and 2 proposals
007147.jpg: 2 GT bboxes and 5 proposals
007148.jpg: 2 GT bboxes and 4 proposals
007149.jpg: 1 GT bboxes and 2 proposals
007153.jpg: 3 GT bboxes and 6 proposals
007162.jpg: 1 GT bboxes and 6 proposals
007165.jpg: 2 GT bboxes and 4 proposals
007167.jpg: 4 GT bboxes and 3 proposals
007172.jpg: 8 GT bboxes and 13 proposals
007174.jpg: 1 GT bboxes and 6 proposals
007187.jpg: 4 GT bboxes and 10 proposals
007189.jpg: 2 GT bboxes and 4 proposals
007191.jpg: 12 GT bboxes and 24 proposals
007200.jpg: 2 GT bboxes and 11 proposals
007204.jpg: 2 GT bboxes and 2 proposals
007208.jpg: 3 GT bboxes and 5 proposals
007210.jpg: 1 GT bboxes and 5 proposals
007211.jpg: 1 GT bboxes and 7 proposals
007212.jpg: 3 GT bboxes and 2 proposals
007215.jpg: 1 GT bboxes and 2 proposals
007216.jpg: 2 GT bboxes and 4 proposals
007217.jpg: 11 GT bboxes and 30 proposals
007224.jpg: 1 GT bboxes and 3 proposals
007227.jpg: 2 GT bboxes and 4 proposals
007230.jpg: 2 GT bboxes and 7 proposals
007236.jpg: 6 GT bboxes and 5 proposals
007244.jpg: 2 GT bboxes and 9 proposals
007245.jpg: 2 GT bboxes and 2 proposals
007247.jpg: 2 GT bboxes and 2 proposals
007249.jpg: 1 GT bboxes and 2 proposals
007258.jpg: 1 GT bboxes and 0 proposals
007259.jpg: 1 GT bboxes and 1 proposals
007260.jpg: 2 GT bboxes and 3 proposals
007266.jpg: 5 GT bboxes and 7 proposals
007270.jpg: 3 GT bboxes and 9 proposals
007274.jpg: 1 GT bboxes and 1 proposals
007275.jpg: 1 GT bboxes and 0 proposals
007276.jpg: 2 GT bboxes and 1 proposals
007280.jpg: 2 GT bboxes and 5 proposals
007283.jpg: 3 GT bboxes and 8 proposals
007284.jpg: 2 GT bboxes and 2 proposals
007292.jpg: 2 GT bboxes and 4 proposals
007294.jpg: 1 GT bboxes and 5 proposals
007296.jpg: 6 GT bboxes and 6 proposals
007297.jpg: 1 GT bboxes and 1 proposals
007299.jpg: 3 GT bboxes and 8 proposals
007300.jpg: 5 GT bboxes and 12 proposals
007302.jpg: 2 GT bboxes and 6 proposals
007311.jpg: 3 GT bboxes and 11 proposals
007314.jpg: 9 GT bboxes and 17 proposals
007318.jpg: 1 GT bboxes and 3 proposals
007329.jpg: 1 GT bboxes and 1 proposals
007330.jpg: 1 GT bboxes and 4 proposals
007343.jpg: 1 GT bboxes and 1 proposals
007344.jpg: 5 GT bboxes and 5 proposals
007346.jpg: 7 GT bboxes and 12 proposals
007350.jpg: 8 GT bboxes and 17 proposals
007356.jpg: 2 GT bboxes and 6 proposals
007359.jpg: 2 GT bboxes and 4 proposals
007363.jpg: 1 GT bboxes and 2 proposals
007372.jpg: 1 GT bboxes and 9 proposals
007374.jpg: 2 GT bboxes and 6 proposals
007376.jpg: 3 GT bboxes and 17 proposals
007383.jpg: 3 GT bboxes and 8 proposals
007388.jpg: 1 GT bboxes and 5 proposals
007390.jpg: 5 GT bboxes and 17 proposals
007408.jpg: 3 GT bboxes and 2 proposals
007414.jpg: 2 GT bboxes and 13 proposals
007416.jpg: 2 GT bboxes and 2 proposals
007422.jpg: 1 GT bboxes and 2 proposals
007424.jpg: 1 GT bboxes and 2 proposals
007427.jpg: 4 GT bboxes and 11 proposals
007432.jpg: 3 GT bboxes and 20 proposals
007433.jpg: 4 GT bboxes and 3 proposals
007435.jpg: 5 GT bboxes and 18 proposals
007436.jpg: 2 GT bboxes and 7 proposals
007438.jpg: 1 GT bboxes and 6 proposals
007439.jpg: 1 GT bboxes and 4 proposals
007443.jpg: 5 GT bboxes and 17 proposals
007445.jpg: 2 GT bboxes and 10 proposals
007448.jpg: 2 GT bboxes and 5 proposals
007449.jpg: 3 GT bboxes and 4 proposals
007451.jpg: 4 GT bboxes and 24 proposals
007457.jpg: 2 GT bboxes and 2 proposals
007460.jpg: 1 GT bboxes and 1 proposals
007461.jpg: 10 GT bboxes and 14 proposals
007465.jpg: 1 GT bboxes and 1 proposals
007470.jpg: 1 GT bboxes and 2 proposals
007475.jpg: 2 GT bboxes and 6 proposals
007480.jpg: 2 GT bboxes and 12 proposals
007482.jpg: 4 GT bboxes and 15 proposals
007484.jpg: 4 GT bboxes and 7 proposals
007486.jpg: 1 GT bboxes and 6 proposals
007489.jpg: 1 GT bboxes and 1 proposals
007498.jpg: 2 GT bboxes and 5 proposals
007506.jpg: 1 GT bboxes and 1 proposals
007511.jpg: 8 GT bboxes and 24 proposals
007517.jpg: 1 GT bboxes and 2 proposals
007523.jpg: 1 GT bboxes and 2 proposals
007525.jpg: 1 GT bboxes and 6 proposals
007527.jpg: 12 GT bboxes and 9 proposals
007528.jpg: 8 GT bboxes and 20 proposals
007533.jpg: 2 GT bboxes and 3 proposals
007537.jpg: 2 GT bboxes and 6 proposals
007543.jpg: 5 GT bboxes and 13 proposals
007546.jpg: 1 GT bboxes and 7 proposals
007547.jpg: 2 GT bboxes and 10 proposals
007551.jpg: 1 GT bboxes and 5 proposals
007555.jpg: 1 GT bboxes and 0 proposals
007559.jpg: 2 GT bboxes and 11 proposals
007563.jpg: 2 GT bboxes and 6 proposals
007568.jpg: 1 GT bboxes and 2 proposals
007571.jpg: 4 GT bboxes and 12 proposals
007576.jpg: 2 GT bboxes and 4 proposals
007579.jpg: 5 GT bboxes and 20 proposals
007585.jpg: 2 GT bboxes and 2 proposals
007592.jpg: 3 GT bboxes and 18 proposals
007603.jpg: 1 GT bboxes and 4 proposals
007605.jpg: 5 GT bboxes and 4 proposals
007612.jpg: 1 GT bboxes and 2 proposals
007614.jpg: 1 GT bboxes and 3 proposals
007615.jpg: 2 GT bboxes and 1 proposals
007618.jpg: 1 GT bboxes and 6 proposals
007622.jpg: 1 GT bboxes and 1 proposals
007624.jpg: 9 GT bboxes and 11 proposals
007626.jpg: 1 GT bboxes and 3 proposals
007639.jpg: 2 GT bboxes and 2 proposals
007640.jpg: 1 GT bboxes and 2 proposals
007642.jpg: 1 GT bboxes and 1 proposals
007647.jpg: 3 GT bboxes and 4 proposals
007649.jpg: 3 GT bboxes and 6 proposals
007650.jpg: 4 GT bboxes and 14 proposals
007656.jpg: 2 GT bboxes and 1 proposals
007657.jpg: 1 GT bboxes and 2 proposals
007662.jpg: 1 GT bboxes and 7 proposals
007664.jpg: 6 GT bboxes and 20 proposals
007666.jpg: 1 GT bboxes and 1 proposals
007668.jpg: 1 GT bboxes and 3 proposals
007670.jpg: 2 GT bboxes and 11 proposals
007671.jpg: 1 GT bboxes and 4 proposals
007672.jpg: 1 GT bboxes and 4 proposals
007673.jpg: 3 GT bboxes and 3 proposals
007675.jpg: 2 GT bboxes and 6 proposals
007677.jpg: 1 GT bboxes and 2 proposals
007678.jpg: 1 GT bboxes and 8 proposals
007679.jpg: 1 GT bboxes and 4 proposals
007680.jpg: 5 GT bboxes and 3 proposals
007682.jpg: 1 GT bboxes and 1 proposals
007687.jpg: 2 GT bboxes and 4 proposals
007688.jpg: 1 GT bboxes and 2 proposals
007691.jpg: 1 GT bboxes and 3 proposals
007694.jpg: 3 GT bboxes and 4 proposals
007702.jpg: 1 GT bboxes and 10 proposals
007705.jpg: 2 GT bboxes and 5 proposals
007709.jpg: 7 GT bboxes and 5 proposals
007712.jpg: 2 GT bboxes and 15 proposals
007715.jpg: 1 GT bboxes and 2 proposals
007720.jpg: 4 GT bboxes and 3 proposals
007723.jpg: 2 GT bboxes and 7 proposals
007724.jpg: 1 GT bboxes and 2 proposals
007727.jpg: 4 GT bboxes and 19 proposals
007732.jpg: 3 GT bboxes and 5 proposals
007742.jpg: 1 GT bboxes and 2 proposals
007743.jpg: 1 GT bboxes and 9 proposals
007745.jpg: 2 GT bboxes and 1 proposals
007746.jpg: 6 GT bboxes and 5 proposals
007754.jpg: 5 GT bboxes and 5 proposals
007758.jpg: 1 GT bboxes and 2 proposals
007760.jpg: 2 GT bboxes and 3 proposals
007763.jpg: 7 GT bboxes and 18 proposals
007765.jpg: 1 GT bboxes and 4 proposals
007768.jpg: 2 GT bboxes and 4 proposals
007772.jpg: 1 GT bboxes and 4 proposals
007773.jpg: 1 GT bboxes and 4 proposals
007776.jpg: 5 GT bboxes and 1 proposals
007779.jpg: 3 GT bboxes and 6 proposals
007786.jpg: 4 GT bboxes and 15 proposals
007793.jpg: 5 GT bboxes and 12 proposals
007798.jpg: 1 GT bboxes and 1 proposals
007799.jpg: 16 GT bboxes and 24 proposals
007812.jpg: 2 GT bboxes and 16 proposals
007813.jpg: 3 GT bboxes and 11 proposals
007815.jpg: 3 GT bboxes and 3 proposals
007824.jpg: 1 GT bboxes and 1 proposals
007826.jpg: 7 GT bboxes and 17 proposals
007833.jpg: 2 GT bboxes and 4 proposals
007834.jpg: 1 GT bboxes and 1 proposals
007841.jpg: 3 GT bboxes and 4 proposals
007843.jpg: 1 GT bboxes and 4 proposals
007845.jpg: 2 GT bboxes and 4 proposals
007855.jpg: 2 GT bboxes and 16 proposals
007856.jpg: 12 GT bboxes and 9 proposals
007857.jpg: 1 GT bboxes and 3 proposals
007865.jpg: 5 GT bboxes and 2 proposals
007868.jpg: 1 GT bboxes and 1 proposals
007869.jpg: 1 GT bboxes and 4 proposals
007873.jpg: 1 GT bboxes and 7 proposals
007886.jpg: 1 GT bboxes and 4 proposals
007889.jpg: 1 GT bboxes and 4 proposals
007890.jpg: 2 GT bboxes and 13 proposals
007897.jpg: 12 GT bboxes and 1 proposals
007899.jpg: 1 GT bboxes and 7 proposals
007902.jpg: 4 GT bboxes and 6 proposals
007909.jpg: 6 GT bboxes and 15 proposals
007916.jpg: 1 GT bboxes and 4 proposals
007919.jpg: 2 GT bboxes and 5 proposals
007920.jpg: 6 GT bboxes and 4 proposals
007921.jpg: 1 GT bboxes and 6 proposals
007924.jpg: 2 GT bboxes and 11 proposals
007928.jpg: 11 GT bboxes and 20 proposals
007931.jpg: 6 GT bboxes and 6 proposals
007933.jpg: 1 GT bboxes and 3 proposals
007935.jpg: 2 GT bboxes and 3 proposals
007943.jpg: 3 GT bboxes and 19 proposals
007946.jpg: 2 GT bboxes and 6 proposals
007947.jpg: 1 GT bboxes and 5 proposals
007950.jpg: 5 GT bboxes and 8 proposals
007954.jpg: 1 GT bboxes and 2 proposals
007956.jpg: 3 GT bboxes and 30 proposals
007958.jpg: 2 GT bboxes and 2 proposals
007970.jpg: 3 GT bboxes and 10 proposals
007971.jpg: 2 GT bboxes and 3 proposals
007979.jpg: 3 GT bboxes and 8 proposals
007984.jpg: 9 GT bboxes and 20 proposals
007987.jpg: 3 GT bboxes and 13 proposals
007997.jpg: 2 GT bboxes and 4 proposals
007998.jpg: 2 GT bboxes and 9 proposals
007999.jpg: 4 GT bboxes and 10 proposals
008002.jpg: 6 GT bboxes and 20 proposals
008009.jpg: 1 GT bboxes and 1 proposals
008023.jpg: 5 GT bboxes and 6 proposals
008024.jpg: 2 GT bboxes and 4 proposals
008029.jpg: 1 GT bboxes and 3 proposals
008031.jpg: 1 GT bboxes and 1 proposals
008032.jpg: 1 GT bboxes and 3 proposals
008033.jpg: 2 GT bboxes and 4 proposals
008036.jpg: 1 GT bboxes and 3 proposals
008048.jpg: 5 GT bboxes and 29 proposals
008057.jpg: 1 GT bboxes and 10 proposals
008060.jpg: 1 GT bboxes and 3 proposals
008061.jpg: 5 GT bboxes and 24 proposals
008068.jpg: 1 GT bboxes and 2 proposals
008069.jpg: 16 GT bboxes and 23 proposals
008085.jpg: 1 GT bboxes and 4 proposals
008086.jpg: 2 GT bboxes and 1 proposals
008087.jpg: 1 GT bboxes and 2 proposals
008091.jpg: 3 GT bboxes and 4 proposals
008100.jpg: 1 GT bboxes and 2 proposals
008101.jpg: 2 GT bboxes and 2 proposals
008103.jpg: 2 GT bboxes and 7 proposals
008105.jpg: 23 GT bboxes and 16 proposals
008107.jpg: 1 GT bboxes and 2 proposals
008112.jpg: 2 GT bboxes and 4 proposals
008115.jpg: 6 GT bboxes and 14 proposals
008122.jpg: 6 GT bboxes and 30 proposals
008125.jpg: 3 GT bboxes and 7 proposals
008132.jpg: 6 GT bboxes and 8 proposals
008138.jpg: 1 GT bboxes and 3 proposals
008140.jpg: 3 GT bboxes and 12 proposals
008141.jpg: 2 GT bboxes and 1 proposals
008144.jpg: 1 GT bboxes and 2 proposals
008151.jpg: 3 GT bboxes and 7 proposals
008159.jpg: 2 GT bboxes and 11 proposals
008160.jpg: 4 GT bboxes and 10 proposals
008168.jpg: 1 GT bboxes and 2 proposals
008171.jpg: 6 GT bboxes and 10 proposals
008173.jpg: 1 GT bboxes and 5 proposals
008175.jpg: 3 GT bboxes and 7 proposals
008177.jpg: 2 GT bboxes and 5 proposals
008180.jpg: 5 GT bboxes and 8 proposals
008189.jpg: 2 GT bboxes and 5 proposals
008190.jpg: 9 GT bboxes and 19 proposals
008191.jpg: 1 GT bboxes and 6 proposals
008200.jpg: 1 GT bboxes and 3 proposals
008208.jpg: 2 GT bboxes and 3 proposals
008209.jpg: 3 GT bboxes and 10 proposals
008220.jpg: 2 GT bboxes and 6 proposals
008222.jpg: 1 GT bboxes and 2 proposals
008224.jpg: 7 GT bboxes and 21 proposals
008225.jpg: 4 GT bboxes and 9 proposals
008229.jpg: 2 GT bboxes and 6 proposals
008236.jpg: 2 GT bboxes and 7 proposals
008241.jpg: 6 GT bboxes and 12 proposals
008244.jpg: 1 GT bboxes and 1 proposals
008251.jpg: 1 GT bboxes and 11 proposals
008258.jpg: 1 GT bboxes and 1 proposals
008268.jpg: 3 GT bboxes and 2 proposals
008275.jpg: 1 GT bboxes and 4 proposals
008279.jpg: 7 GT bboxes and 3 proposals
008281.jpg: 2 GT bboxes and 6 proposals
008284.jpg: 3 GT bboxes and 8 proposals
008285.jpg: 2 GT bboxes and 5 proposals
008292.jpg: 6 GT bboxes and 3 proposals
008293.jpg: 4 GT bboxes and 16 proposals
008294.jpg: 5 GT bboxes and 6 proposals
008295.jpg: 1 GT bboxes and 2 proposals
008297.jpg: 1 GT bboxes and 3 proposals
008299.jpg: 1 GT bboxes and 3 proposals
008300.jpg: 1 GT bboxes and 2 proposals
008306.jpg: 2 GT bboxes and 1 proposals
008307.jpg: 2 GT bboxes and 5 proposals
008318.jpg: 2 GT bboxes and 3 proposals
008319.jpg: 28 GT bboxes and 39 proposals
008320.jpg: 1 GT bboxes and 1 proposals
008323.jpg: 1 GT bboxes and 5 proposals
008326.jpg: 1 GT bboxes and 2 proposals
008327.jpg: 2 GT bboxes and 9 proposals
008329.jpg: 1 GT bboxes and 5 proposals
008335.jpg: 1 GT bboxes and 2 proposals
008345.jpg: 3 GT bboxes and 4 proposals
008349.jpg: 1 GT bboxes and 3 proposals
008355.jpg: 1 GT bboxes and 2 proposals
008359.jpg: 4 GT bboxes and 13 proposals
008364.jpg: 2 GT bboxes and 2 proposals
008365.jpg: 3 GT bboxes and 11 proposals
008368.jpg: 2 GT bboxes and 5 proposals
008370.jpg: 1 GT bboxes and 2 proposals
008376.jpg: 5 GT bboxes and 8 proposals
008386.jpg: 3 GT bboxes and 13 proposals
008387.jpg: 10 GT bboxes and 18 proposals
008390.jpg: 3 GT bboxes and 4 proposals
008410.jpg: 6 GT bboxes and 19 proposals
008413.jpg: 4 GT bboxes and 7 proposals
008415.jpg: 2 GT bboxes and 4 proposals
008416.jpg: 2 GT bboxes and 7 proposals
008423.jpg: 1 GT bboxes and 2 proposals
008424.jpg: 6 GT bboxes and 12 proposals
008429.jpg: 1 GT bboxes and 3 proposals
008430.jpg: 1 GT bboxes and 2 proposals
008433.jpg: 6 GT bboxes and 15 proposals
008434.jpg: 1 GT bboxes and 6 proposals
008438.jpg: 1 GT bboxes and 2 proposals
008444.jpg: 15 GT bboxes and 29 proposals
008450.jpg: 1 GT bboxes and 3 proposals
008454.jpg: 1 GT bboxes and 0 proposals
008461.jpg: 3 GT bboxes and 4 proposals
008472.jpg: 1 GT bboxes and 1 proposals
008484.jpg: 1 GT bboxes and 4 proposals
008485.jpg: 2 GT bboxes and 3 proposals
008492.jpg: 1 GT bboxes and 4 proposals
008494.jpg: 1 GT bboxes and 6 proposals
008498.jpg: 1 GT bboxes and 8 proposals
008499.jpg: 1 GT bboxes and 4 proposals
008502.jpg: 1 GT bboxes and 2 proposals
008503.jpg: 14 GT bboxes and 9 proposals
008509.jpg: 5 GT bboxes and 22 proposals
008512.jpg: 1 GT bboxes and 5 proposals
008513.jpg: 1 GT bboxes and 4 proposals
008514.jpg: 15 GT bboxes and 2 proposals
008518.jpg: 1 GT bboxes and 2 proposals
008519.jpg: 1 GT bboxes and 3 proposals
008521.jpg: 1 GT bboxes and 3 proposals
008522.jpg: 1 GT bboxes and 5 proposals
008524.jpg: 2 GT bboxes and 10 proposals
008526.jpg: 5 GT bboxes and 21 proposals
008534.jpg: 1 GT bboxes and 1 proposals
008535.jpg: 2 GT bboxes and 4 proposals
008541.jpg: 5 GT bboxes and 16 proposals
008542.jpg: 2 GT bboxes and 5 proposals
008553.jpg: 1 GT bboxes and 4 proposals
008556.jpg: 1 GT bboxes and 8 proposals
008557.jpg: 10 GT bboxes and 5 proposals
008562.jpg: 8 GT bboxes and 8 proposals
008564.jpg: 2 GT bboxes and 10 proposals
008572.jpg: 2 GT bboxes and 7 proposals
008573.jpg: 2 GT bboxes and 5 proposals
008576.jpg: 4 GT bboxes and 6 proposals
008582.jpg: 2 GT bboxes and 6 proposals
008584.jpg: 1 GT bboxes and 0 proposals
008586.jpg: 1 GT bboxes and 2 proposals
008592.jpg: 8 GT bboxes and 14 proposals
008601.jpg: 4 GT bboxes and 12 proposals
008604.jpg: 8 GT bboxes and 11 proposals
008606.jpg: 1 GT bboxes and 5 proposals
008607.jpg: 2 GT bboxes and 4 proposals
008608.jpg: 1 GT bboxes and 2 proposals
008612.jpg: 2 GT bboxes and 6 proposals
008620.jpg: 1 GT bboxes and 2 proposals
008621.jpg: 1 GT bboxes and 1 proposals
008624.jpg: 6 GT bboxes and 27 proposals
008635.jpg: 1 GT bboxes and 3 proposals
008636.jpg: 3 GT bboxes and 3 proposals
008638.jpg: 3 GT bboxes and 1 proposals
008639.jpg: 3 GT bboxes and 15 proposals
008644.jpg: 5 GT bboxes and 0 proposals
008647.jpg: 1 GT bboxes and 3 proposals
008653.jpg: 1 GT bboxes and 1 proposals
008654.jpg: 1 GT bboxes and 3 proposals
008667.jpg: 1 GT bboxes and 1 proposals
008680.jpg: 5 GT bboxes and 23 proposals
008683.jpg: 1 GT bboxes and 1 proposals
008687.jpg: 1 GT bboxes and 2 proposals
008692.jpg: 5 GT bboxes and 10 proposals
008695.jpg: 2 GT bboxes and 10 proposals
008698.jpg: 1 GT bboxes and 2 proposals
008701.jpg: 3 GT bboxes and 7 proposals
008709.jpg: 1 GT bboxes and 6 proposals
008713.jpg: 1 GT bboxes and 8 proposals
008716.jpg: 1 GT bboxes and 5 proposals
008717.jpg: 7 GT bboxes and 20 proposals
008718.jpg: 4 GT bboxes and 3 proposals
008722.jpg: 1 GT bboxes and 3 proposals
008728.jpg: 3 GT bboxes and 7 proposals
008730.jpg: 5 GT bboxes and 19 proposals
008733.jpg: 6 GT bboxes and 18 proposals
008739.jpg: 8 GT bboxes and 7 proposals
008742.jpg: 5 GT bboxes and 9 proposals
008747.jpg: 2 GT bboxes and 14 proposals
008749.jpg: 1 GT bboxes and 11 proposals
008752.jpg: 6 GT bboxes and 9 proposals
008753.jpg: 1 GT bboxes and 1 proposals
008759.jpg: 1 GT bboxes and 1 proposals
008766.jpg: 2 GT bboxes and 1 proposals
008769.jpg: 2 GT bboxes and 5 proposals
008772.jpg: 1 GT bboxes and 3 proposals
008773.jpg: 1 GT bboxes and 2 proposals
008775.jpg: 12 GT bboxes and 15 proposals
008793.jpg: 3 GT bboxes and 8 proposals
008796.jpg: 1 GT bboxes and 5 proposals
008799.jpg: 2 GT bboxes and 7 proposals
008801.jpg: 5 GT bboxes and 12 proposals
008805.jpg: 2 GT bboxes and 3 proposals
008810.jpg: 3 GT bboxes and 1 proposals
008817.jpg: 2 GT bboxes and 17 proposals
008822.jpg: 1 GT bboxes and 1 proposals
008823.jpg: 1 GT bboxes and 9 proposals
008826.jpg: 1 GT bboxes and 0 proposals
008831.jpg: 2 GT bboxes and 6 proposals
008833.jpg: 2 GT bboxes and 17 proposals
008835.jpg: 7 GT bboxes and 2 proposals
008836.jpg: 15 GT bboxes and 23 proposals
008837.jpg: 2 GT bboxes and 1 proposals
008843.jpg: 1 GT bboxes and 1 proposals
008848.jpg: 4 GT bboxes and 13 proposals
008849.jpg: 2 GT bboxes and 1 proposals
008854.jpg: 1 GT bboxes and 1 proposals
008858.jpg: 1 GT bboxes and 2 proposals
008859.jpg: 2 GT bboxes and 7 proposals
008867.jpg: 2 GT bboxes and 4 proposals
008871.jpg: 1 GT bboxes and 3 proposals
008873.jpg: 1 GT bboxes and 4 proposals
008874.jpg: 3 GT bboxes and 5 proposals
008876.jpg: 2 GT bboxes and 5 proposals
008880.jpg: 1 GT bboxes and 1 proposals
008884.jpg: 3 GT bboxes and 5 proposals
008888.jpg: 3 GT bboxes and 2 proposals
008890.jpg: 1 GT bboxes and 6 proposals
008892.jpg: 8 GT bboxes and 19 proposals
008911.jpg: 12 GT bboxes and 5 proposals
008913.jpg: 2 GT bboxes and 7 proposals
008914.jpg: 1 GT bboxes and 2 proposals
008917.jpg: 1 GT bboxes and 1 proposals
008919.jpg: 1 GT bboxes and 1 proposals
008921.jpg: 1 GT bboxes and 5 proposals
008927.jpg: 1 GT bboxes and 3 proposals
008931.jpg: 8 GT bboxes and 21 proposals
008940.jpg: 1 GT bboxes and 1 proposals
008942.jpg: 9 GT bboxes and 21 proposals
008943.jpg: 15 GT bboxes and 13 proposals
008951.jpg: 1 GT bboxes and 2 proposals
008953.jpg: 2 GT bboxes and 5 proposals
008955.jpg: 1 GT bboxes and 5 proposals
008965.jpg: 1 GT bboxes and 1 proposals
008976.jpg: 2 GT bboxes and 2 proposals
008982.jpg: 2 GT bboxes and 2 proposals
008983.jpg: 8 GT bboxes and 18 proposals
008997.jpg: 11 GT bboxes and 23 proposals
009002.jpg: 1 GT bboxes and 1 proposals
009006.jpg: 4 GT bboxes and 2 proposals
009007.jpg: 1 GT bboxes and 11 proposals
009015.jpg: 6 GT bboxes and 11 proposals
009019.jpg: 2 GT bboxes and 3 proposals
009022.jpg: 2 GT bboxes and 4 proposals
009024.jpg: 2 GT bboxes and 3 proposals
009034.jpg: 15 GT bboxes and 27 proposals
009035.jpg: 1 GT bboxes and 1 proposals
009037.jpg: 1 GT bboxes and 7 proposals
009039.jpg: 2 GT bboxes and 1 proposals
009048.jpg: 2 GT bboxes and 7 proposals
009051.jpg: 6 GT bboxes and 13 proposals
009053.jpg: 1 GT bboxes and 2 proposals
009060.jpg: 2 GT bboxes and 3 proposals
009064.jpg: 9 GT bboxes and 19 proposals
009072.jpg: 1 GT bboxes and 12 proposals
009079.jpg: 4 GT bboxes and 7 proposals
009085.jpg: 6 GT bboxes and 10 proposals
009087.jpg: 8 GT bboxes and 22 proposals
009089.jpg: 1 GT bboxes and 5 proposals
009091.jpg: 11 GT bboxes and 20 proposals
009094.jpg: 1 GT bboxes and 3 proposals
009105.jpg: 1 GT bboxes and 2 proposals
009112.jpg: 1 GT bboxes and 1 proposals
009113.jpg: 7 GT bboxes and 2 proposals
009116.jpg: 1 GT bboxes and 2 proposals
009126.jpg: 1 GT bboxes and 10 proposals
009128.jpg: 1 GT bboxes and 2 proposals
009129.jpg: 1 GT bboxes and 5 proposals
009131.jpg: 1 GT bboxes and 8 proposals
009133.jpg: 1 GT bboxes and 2 proposals
009138.jpg: 1 GT bboxes and 1 proposals
009141.jpg: 6 GT bboxes and 14 proposals
009147.jpg: 1 GT bboxes and 2 proposals
009150.jpg: 1 GT bboxes and 2 proposals
009151.jpg: 4 GT bboxes and 9 proposals
009155.jpg: 1 GT bboxes and 3 proposals
009157.jpg: 4 GT bboxes and 7 proposals
009159.jpg: 1 GT bboxes and 0 proposals
009162.jpg: 1 GT bboxes and 3 proposals
009163.jpg: 4 GT bboxes and 19 proposals
009168.jpg: 1 GT bboxes and 1 proposals
009174.jpg: 9 GT bboxes and 3 proposals
009177.jpg: 4 GT bboxes and 13 proposals
009178.jpg: 1 GT bboxes and 3 proposals
009179.jpg: 4 GT bboxes and 10 proposals
009180.jpg: 5 GT bboxes and 14 proposals
009186.jpg: 2 GT bboxes and 6 proposals
009187.jpg: 1 GT bboxes and 2 proposals
009189.jpg: 6 GT bboxes and 18 proposals
009192.jpg: 1 GT bboxes and 2 proposals
009193.jpg: 4 GT bboxes and 4 proposals
009194.jpg: 1 GT bboxes and 12 proposals
009195.jpg: 1 GT bboxes and 2 proposals
009202.jpg: 2 GT bboxes and 5 proposals
009212.jpg: 1 GT bboxes and 4 proposals
009213.jpg: 1 GT bboxes and 1 proposals
009221.jpg: 1 GT bboxes and 3 proposals
009224.jpg: 5 GT bboxes and 6 proposals
009236.jpg: 2 GT bboxes and 5 proposals
009239.jpg: 3 GT bboxes and 11 proposals
009244.jpg: 1 GT bboxes and 1 proposals
009246.jpg: 1 GT bboxes and 9 proposals
009247.jpg: 5 GT bboxes and 40 proposals
009249.jpg: 3 GT bboxes and 8 proposals
009250.jpg: 1 GT bboxes and 2 proposals
009254.jpg: 4 GT bboxes and 5 proposals
009268.jpg: 1 GT bboxes and 5 proposals
009273.jpg: 6 GT bboxes and 2 proposals
009278.jpg: 1 GT bboxes and 3 proposals
009279.jpg: 4 GT bboxes and 11 proposals
009281.jpg: 1 GT bboxes and 4 proposals
009282.jpg: 1 GT bboxes and 3 proposals
009286.jpg: 8 GT bboxes and 17 proposals
009291.jpg: 5 GT bboxes and 13 proposals
009303.jpg: 7 GT bboxes and 22 proposals
009309.jpg: 1 GT bboxes and 1 proposals
009312.jpg: 2 GT bboxes and 16 proposals
009315.jpg: 2 GT bboxes and 11 proposals
009323.jpg: 3 GT bboxes and 7 proposals
009326.jpg: 1 GT bboxes and 9 proposals
009330.jpg: 2 GT bboxes and 5 proposals
009331.jpg: 5 GT bboxes and 9 proposals
009334.jpg: 1 GT bboxes and 2 proposals
009337.jpg: 1 GT bboxes and 1 proposals
009347.jpg: 2 GT bboxes and 4 proposals
009348.jpg: 1 GT bboxes and 6 proposals
009349.jpg: 6 GT bboxes and 29 proposals
009350.jpg: 1 GT bboxes and 12 proposals
009351.jpg: 1 GT bboxes and 1 proposals
009354.jpg: 1 GT bboxes and 2 proposals
009368.jpg: 16 GT bboxes and 20 proposals
009371.jpg: 1 GT bboxes and 3 proposals
009373.jpg: 2 GT bboxes and 9 proposals
009374.jpg: 2 GT bboxes and 1 proposals
009375.jpg: 3 GT bboxes and 3 proposals
009378.jpg: 1 GT bboxes and 1 proposals
009382.jpg: 3 GT bboxes and 8 proposals
009401.jpg: 1 GT bboxes and 1 proposals
009405.jpg: 1 GT bboxes and 2 proposals
009408.jpg: 1 GT bboxes and 5 proposals
009412.jpg: 3 GT bboxes and 4 proposals
009414.jpg: 4 GT bboxes and 3 proposals
009433.jpg: 7 GT bboxes and 1 proposals
009437.jpg: 4 GT bboxes and 27 proposals
009438.jpg: 1 GT bboxes and 4 proposals
009439.jpg: 1 GT bboxes and 1 proposals
009440.jpg: 2 GT bboxes and 9 proposals
009443.jpg: 3 GT bboxes and 2 proposals
009445.jpg: 1 GT bboxes and 4 proposals
009448.jpg: 7 GT bboxes and 7 proposals
009454.jpg: 2 GT bboxes and 24 proposals
009455.jpg: 1 GT bboxes and 2 proposals
009456.jpg: 6 GT bboxes and 20 proposals
009457.jpg: 1 GT bboxes and 4 proposals
009459.jpg: 1 GT bboxes and 2 proposals
009461.jpg: 2 GT bboxes and 5 proposals
009464.jpg: 1 GT bboxes and 2 proposals
009468.jpg: 2 GT bboxes and 8 proposals
009470.jpg: 3 GT bboxes and 3 proposals
009472.jpg: 1 GT bboxes and 5 proposals
009477.jpg: 4 GT bboxes and 11 proposals
009479.jpg: 3 GT bboxes and 4 proposals
009480.jpg: 3 GT bboxes and 3 proposals
009481.jpg: 12 GT bboxes and 17 proposals
009484.jpg: 3 GT bboxes and 3 proposals
009494.jpg: 2 GT bboxes and 7 proposals
009500.jpg: 4 GT bboxes and 12 proposals
009502.jpg: 1 GT bboxes and 3 proposals
009507.jpg: 4 GT bboxes and 7 proposals
009517.jpg: 3 GT bboxes and 14 proposals
009519.jpg: 4 GT bboxes and 13 proposals
009527.jpg: 3 GT bboxes and 3 proposals
009531.jpg: 1 GT bboxes and 0 proposals
009532.jpg: 6 GT bboxes and 17 proposals
009533.jpg: 2 GT bboxes and 14 proposals
009540.jpg: 2 GT bboxes and 6 proposals
009543.jpg: 6 GT bboxes and 18 proposals
009546.jpg: 3 GT bboxes and 5 proposals
009550.jpg: 10 GT bboxes and 18 proposals
009558.jpg: 10 GT bboxes and 2 proposals
009560.jpg: 1 GT bboxes and 3 proposals
009565.jpg: 2 GT bboxes and 7 proposals
009567.jpg: 2 GT bboxes and 5 proposals
009568.jpg: 2 GT bboxes and 4 proposals
009571.jpg: 1 GT bboxes and 2 proposals
009580.jpg: 1 GT bboxes and 2 proposals
009586.jpg: 1 GT bboxes and 6 proposals
009588.jpg: 1 GT bboxes and 3 proposals
009591.jpg: 4 GT bboxes and 7 proposals
009597.jpg: 1 GT bboxes and 2 proposals
009598.jpg: 2 GT bboxes and 5 proposals
009603.jpg: 2 GT bboxes and 6 proposals
009611.jpg: 2 GT bboxes and 0 proposals
009617.jpg: 24 GT bboxes and 35 proposals
009619.jpg: 1 GT bboxes and 2 proposals
009620.jpg: 2 GT bboxes and 2 proposals
009627.jpg: 1 GT bboxes and 3 proposals
009636.jpg: 1 GT bboxes and 10 proposals
009641.jpg: 5 GT bboxes and 10 proposals
009647.jpg: 9 GT bboxes and 13 proposals
009649.jpg: 9 GT bboxes and 19 proposals
009655.jpg: 2 GT bboxes and 1 proposals
009658.jpg: 1 GT bboxes and 3 proposals
009667.jpg: 1 GT bboxes and 3 proposals
009670.jpg: 2 GT bboxes and 5 proposals
009676.jpg: 3 GT bboxes and 5 proposals
009678.jpg: 1 GT bboxes and 8 proposals
009681.jpg: 1 GT bboxes and 1 proposals
009685.jpg: 1 GT bboxes and 11 proposals
009686.jpg: 8 GT bboxes and 9 proposals
009687.jpg: 4 GT bboxes and 14 proposals
009692.jpg: 2 GT bboxes and 5 proposals
009695.jpg: 1 GT bboxes and 8 proposals
009698.jpg: 4 GT bboxes and 6 proposals
009699.jpg: 4 GT bboxes and 15 proposals
009700.jpg: 1 GT bboxes and 1 proposals
009706.jpg: 1 GT bboxes and 7 proposals
009710.jpg: 1 GT bboxes and 4 proposals
009711.jpg: 6 GT bboxes and 14 proposals
009712.jpg: 2 GT bboxes and 2 proposals
009719.jpg: 2 GT bboxes and 4 proposals
009724.jpg: 1 GT bboxes and 1 proposals
009726.jpg: 8 GT bboxes and 23 proposals
009732.jpg: 2 GT bboxes and 6 proposals
009737.jpg: 2 GT bboxes and 8 proposals
009738.jpg: 1 GT bboxes and 3 proposals
009743.jpg: 1 GT bboxes and 2 proposals
009745.jpg: 2 GT bboxes and 7 proposals
009746.jpg: 3 GT bboxes and 2 proposals
009747.jpg: 3 GT bboxes and 6 proposals
009748.jpg: 1 GT bboxes and 1 proposals
009754.jpg: 1 GT bboxes and 6 proposals
009758.jpg: 20 GT bboxes and 33 proposals
009761.jpg: 1 GT bboxes and 2 proposals
009764.jpg: 2 GT bboxes and 5 proposals
009767.jpg: 2 GT bboxes and 7 proposals
009772.jpg: 1 GT bboxes and 2 proposals
009773.jpg: 4 GT bboxes and 15 proposals
009778.jpg: 1 GT bboxes and 2 proposals
009780.jpg: 3 GT bboxes and 6 proposals
009781.jpg: 2 GT bboxes and 3 proposals
009785.jpg: 1 GT bboxes and 1 proposals
009794.jpg: 1 GT bboxes and 1 proposals
009796.jpg: 4 GT bboxes and 17 proposals
009801.jpg: 4 GT bboxes and 7 proposals
009809.jpg: 1 GT bboxes and 1 proposals
009816.jpg: 9 GT bboxes and 14 proposals
009819.jpg: 3 GT bboxes and 2 proposals
009822.jpg: 34 GT bboxes and 29 proposals
009823.jpg: 1 GT bboxes and 6 proposals
009831.jpg: 2 GT bboxes and 5 proposals
009833.jpg: 9 GT bboxes and 31 proposals
009836.jpg: 1 GT bboxes and 3 proposals
009841.jpg: 2 GT bboxes and 8 proposals
009858.jpg: 1 GT bboxes and 6 proposals
009862.jpg: 1 GT bboxes and 2 proposals
009863.jpg: 2 GT bboxes and 3 proposals
009865.jpg: 4 GT bboxes and 13 proposals
009870.jpg: 2 GT bboxes and 7 proposals
009880.jpg: 5 GT bboxes and 8 proposals
009881.jpg: 3 GT bboxes and 7 proposals
009886.jpg: 1 GT bboxes and 1 proposals
009894.jpg: 1 GT bboxes and 4 proposals
009897.jpg: 2 GT bboxes and 4 proposals
009898.jpg: 1 GT bboxes and 1 proposals
009900.jpg: 5 GT bboxes and 7 proposals
009902.jpg: 6 GT bboxes and 18 proposals
009905.jpg: 2 GT bboxes and 3 proposals
009908.jpg: 5 GT bboxes and 5 proposals
009913.jpg: 1 GT bboxes and 4 proposals
009917.jpg: 6 GT bboxes and 17 proposals
009923.jpg: 1 GT bboxes and 3 proposals
009932.jpg: 1 GT bboxes and 4 proposals
009935.jpg: 11 GT bboxes and 25 proposals
009939.jpg: 2 GT bboxes and 6 proposals
009946.jpg: 4 GT bboxes and 7 proposals
009947.jpg: 2 GT bboxes and 7 proposals
009950.jpg: 2 GT bboxes and 2 proposals
009954.jpg: 2 GT bboxes and 5 proposals
009955.jpg: 2 GT bboxes and 10 proposals
009958.jpg: 5 GT bboxes and 37 proposals
Total inference time: 29.3s
19.79% = aeroplane AP 
/content/mAP/main.py:704: MatplotlibDeprecationWarning: 
The set_window_title function was deprecated in Matplotlib 3.4 and will be removed two minor releases later. Use `.FigureManagerBase.set_window_title` or GUI-specific methods instead.
  fig.canvas.set_window_title(&#39;AP &#39; + class_name)
4.29% = bicycle AP 
13.57% = bird AP 
0.62% = boat AP 
0.30% = bottle AP 
7.63% = bus AP 
12.65% = car AP 
45.23% = cat AP 
1.47% = chair AP 
9.70% = cow AP 
4.72% = diningtable AP 
25.44% = dog AP 
24.05% = horse AP 
15.12% = motorbike AP 
14.59% = person AP 
0.67% = pottedplant AP 
1.07% = sheep AP 
9.14% = sofa AP 
28.44% = train AP 
8.55% = tvmonitor AP 
mAP = 12.35%
/content/mAP/main.py:298: MatplotlibDeprecationWarning: 
The set_window_title function was deprecated in Matplotlib 3.4 and will be removed two minor releases later. Use `.FigureManagerBase.set_window_title` or GUI-specific methods instead.
  fig.canvas.set_window_title(window_title)
Figure(640x480)
</code></pre>
</div>
</div>
</body>
</html>
